{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38fb5a200ce04d6696d88177e8f888db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3f5cdc233c7d43569e573f85eb85f80d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51dd5cb389024ee9bbf6ce4b84c876f7",
              "IPY_MODEL_191828746e3a412581bdf8b951c5ae6e"
            ]
          }
        },
        "3f5cdc233c7d43569e573f85eb85f80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51dd5cb389024ee9bbf6ce4b84c876f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae54799cc3304078a3dbd4a3a84d19f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26621fce34e74e6f96785b2a22a3c354"
          }
        },
        "191828746e3a412581bdf8b951c5ae6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_067eec452d444fb68cc6af5f1a014d90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:19&lt;00:00, 47573178.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac33ff1ff68f4adb814e286dc30cc280"
          }
        },
        "ae54799cc3304078a3dbd4a3a84d19f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26621fce34e74e6f96785b2a22a3c354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "067eec452d444fb68cc6af5f1a014d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac33ff1ff68f4adb814e286dc30cc280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosminnedescu/ProjectMLDL/blob/main/baselines/FineTuning-group.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJimWkPdQu6y"
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blqZpJkQgn5c",
        "outputId": "b8c3f81f-29ee-448c-c331-e9bae5e73791"
      },
      "source": [
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJRs-JrVsd8j",
        "outputId": "3cd0e688-fb57-41a1-f4e0-1dda2b1cfb3d"
      },
      "source": [
        "%cd content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Wvze6xh3-9"
      },
      "source": [
        "!rm -rf ProjectMLDL"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQQd0qWVgue_",
        "outputId": "931244e3-db98-4be1-b6e5-f2c84506f5cc"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjntw1jZQ7Lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3979d650-06a9-447a-ed41-c245a0f9161c"
      },
      "source": [
        "if not os.path.isdir('/content/ProjectMLDL'):\n",
        "  !git clone https://github.com/cosminnedescu/ProjectMLDL.git\n",
        "  %cd /content/ProjectMLDL\n",
        "  !rm -rf LICENSE README.md"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ProjectMLDL'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 74 (delta 22), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n",
            "/content/ProjectMLDL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvkF4W62dSp8"
      },
      "source": [
        "from data.cifar100 import CIFAR100\n",
        "from model.resnet32 import resnet32\n",
        "import data.utils\n",
        "from model.trainer import Trainer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwomFTtQo1x-"
      },
      "source": [
        "# True mean and std of Cifar100 dataset (src=\"https://gist.github.com/weiaicunzai/e623931921efefd4c331622c344d8151\")\n",
        "mean = [0.5071, 0.4867, 0.4408]\n",
        "std = [0.2675, 0.2565, 0.2761]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), \n",
        "     transforms.Normalize(mean, std),\n",
        "     ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "38fb5a200ce04d6696d88177e8f888db",
            "3f5cdc233c7d43569e573f85eb85f80d",
            "51dd5cb389024ee9bbf6ce4b84c876f7",
            "191828746e3a412581bdf8b951c5ae6e",
            "ae54799cc3304078a3dbd4a3a84d19f1",
            "26621fce34e74e6f96785b2a22a3c354",
            "067eec452d444fb68cc6af5f1a014d90",
            "ac33ff1ff68f4adb814e286dc30cc280"
          ]
        },
        "id": "BCz7GGfdpRiL",
        "outputId": "638f54bf-27ee-46cd-a179-e437afe8259a"
      },
      "source": [
        "train_data = CIFAR100(\"dataset\", train=True, transform=train_transform, download=True)\n",
        "test_data = CIFAR100(\"dataset\", train=False, transform=test_transform, download=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to dataset/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38fb5a200ce04d6696d88177e8f888db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting dataset/cifar-100-python.tar.gz to dataset\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "cGlVf385aUDd",
        "outputId": "e820d5a5-682a-4988-eac5-011f17ad47e3"
      },
      "source": [
        "#check images and labels after shuffle\n",
        "#https://github.com/keras-team/keras/issues/2653#issuecomment-450133996\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_data.data[6])\n",
        "print(\"classe: {}\".format(train_data.targets[6]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classe: 90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfQUlEQVR4nO2dWWxc55Xn/6cWFilSIkVqtRZrtWWNLckKrbZjO3HSceL2pNv2LEb8EPghaDUGHWAC9DwYGWCSAeYhPZgkyMMgA2VitNNIZ5nOYqfHSXtJbI/diWxa1mYttixRC0WRkiiS4lKs7cxDladlz/f/SJFiUcn9/wBBxe/Ud++5t+6pW/X965xj7g4hxB8+qbl2QAhRHxTsQiQEBbsQCUHBLkRCULALkRAU7EIkhMxMJpvZAwC+BSAN4H+6+9eiO8tmPdeQY9ui8661PJhKpyNG7gfDIv6VS+Wr3t5MMOZ/5LC8XIltcZqOkH1FXsrUNM59dZuRjdZRWfbIzhoam6gtkwnfcwuFfGxnQfLjeRQmCsETOe1gN7M0gP8O4H4AZwC8YWbPuPshNifXkMOmW7cEbQ0p7kqpWAyOV5xfHBa5SOe1t1IbcllqSpEznC7zgB7sv8i3F3mDiwZnJCgaGsNvpqkMD+jx4XFqS8UukUiQWSb8hlqq8HPVkAv7Xt0gP+YKuT5qO+Q2uiu+r7Lz7VVQoLbVN91Kbe1L5wfHu08cpXNS5Ny//tLrfA61TM4OAMfc/bi7FwD8EMBDM9ieEGIWmUmwrwBw+oq/z9TGhBDXITP6zj4VzGwngJ0A0NDQMNu7E0IQZnJn7wGw6oq/V9bGPoC773L3TnfvzGT492EhxOwyk2B/A8BGM1trZg0APgfgmWvjlhDiWjPtj/HuXjKzLwL4R1Sltyfd/e3YHDNDNhu+uzdm+Uf8sVIpbMhw93MRqaOhsZHalqxYzv0YHg6OD5ztpXNSMeknqjRFlIYUf49mX5UaW/lKd36CnF8AyPPV51TED+ZjOiZAxFbBI4pHJSIdMg9j+4rZYlJehlzbAJCJXKvMFpPyKpWr1xRn9J3d3Z8F8OxMtiGEqA/6BZ0QCUHBLkRCULALkRAU7EIkBAW7EAlh1n9B9/9RDksGmSbuSioVlpPKmUiWUTOXmkoFnrDQ3NxMbYMXLgTH0xEJKpZhV0YkSSMmUUVUF5aBl0rz85smmYgAUI5kXkXykFAhcmlMMCpX+OuCmNRU4efRiYw2/UzKSPJPJEEptr9SIZzIUxzlCT4VYqqQ+AJ0ZxciMSjYhUgICnYhEoKCXYiEoGAXIiHUdTW+UnEUJsLLiN7MVxGzuXDiSq6ZJx40NvBkFzee+BErZ9VEEmispYXOGRsdpbZMJPmHJQwBQCFS2slJOahKpDxTbAW3EisHFSnRxBKAYkrCdMvdxRJyKmSlPjonsnKeJecXAFIZfgDpFJ9XKYZ9jK3Gm5HQjdX44yYhxB8SCnYhEoKCXYiEoGAXIiEo2IVICAp2IRJCXaW3lvkt+Og9dwdtI8O8c8rZ/oHgeKwTyMIG/j42muKyXEx6Y62cypFEjHQkASXWqyQVkXjmt4Q7iAAAiByWiRyXF7kUmbKYRBU5gmnkmcSSRWK2dKydV6yeHNte5Jhj9f8yWf5ax6TUcinS0Yb5MQ2dUnd2IRKCgl2IhKBgFyIhKNiFSAgKdiESgoJdiIQwI+nNzLoBXAZQBlBy987Y89va2vCn//pfBW35y+H6bgBw+tz54Pixt/bQOeUJLuWNDPJaZ7E2Q0zsaEhH5Kkyl7UqzueNDF2mtsworwvX0dEeHG+INNVMR4rJZRv5JVKYiGTSReRIOicir0VbTUXbNYW3Ga0XF9ENy5GMw1QpJoddvS12LdLaehHfr4XO/gl355EqhLgu0Md4IRLCTIPdATxnZm+a2c5r4ZAQYnaY6cf4e9y9x8yWAHjezI64+ytXPqH2JrATAJYsXTrD3QkhpsuM7uzu3lP7vx/AzwDsCDxnl7t3untna2vbTHYnhJgB0w52M2s2s/nvPwbwaQAHr5VjQohry0w+xi8F8LOa7JEB8Hfu/qvYhNGxEezuei1oW9jGM7nW3XRzcHzrpk10zuDFHmp769AxarsYKfI33hCWr1LOT+PEgnnUVmZFA8Ez7ABEM8qam8IZfa2LOuic0Ug7rLHxcMYhAGQiUlOpSGyRipOxRLmGeTxTsYkUJAV4wc9imb/OmQaeRReT+YoRKbIYez1JL6fYvtKkuGVMhZx2sLv7cQBbpztfCFFfJL0JkRAU7EIkBAW7EAlBwS5EQlCwC5EQ6lpwEnCkPZyxNXh+jM767cVw1tuihSvpnG233Uptf7r+Nmo7cqKb2o61h3u6jV04R+cUI4Uvi5HMsEwkS61S5ttkWW/ZJi4B5pqbqa1QnOC2Es/MyzXlguP5iMwXSURDMVJcNEd68AFAS3v4h1zFAj8uM/66jER693klIsuVePZjaSIcE6lp9NmLJA7qzi5EUlCwC5EQFOxCJAQFuxAJQcEuREKo62q8l4qYGOgL2hrmL6LzFraEV5JPnThO5wxcCK/gA8D69WupbdmKVdT2yJ89FBw/39NN57z06svUdvz4u9SWy/GXZmQ4skKeHw6Ol4vhcQBoSvOadtmFTdRWHOUKSsuC1uD4KFFWACAVqdMWa/E0Psb9yEyE56Uy/D7X3MKPORXxY3hghNryeX6O86PhebFWU9HWWwTd2YVICAp2IRKCgl2IhKBgFyIhKNiFSAgKdiESQl2lt1waWB9WZPBe/xk6L58PJ3csXLiQzkmVuRxz6O291Haql7eNuveObcHxVWvX0TmPrVxNbcfeOUxtb+z/J2rrPvEOtVV8PDjeMY8nwpTGhqhtpMTvB/PbuAyVHw0nyViJS0YxWcsqPMOjFGmTVMwTmTJym3Pn22toaKC2+S3hRCkAyEaO7fJEODkobdzJWMILQ3d2IRKCgl2IhKBgFyIhKNiFSAgKdiESgoJdiIQwqfRmZk8C+CyAfne/tTbWDuBHANYA6AbwqLtfmmxbpUoFl0bCNbzWLltA572x/2hwvG+cyxlbtvMadK1NXD7J5/lhPPfy88HxNau49Pbxu++lts986l9S27ZO3myna08Xte17a09wfPDcaTpn8BLPyJrwSGulcV4XrjAeltjSMcmozGW5ckR6ixWvyzaGa+HF2iSVIvXuxiIZdqjw67G5g3cwntcUzrIbHuOZijC+L8ZU7ux/A+CBD409AeBFd98I4MXa30KI65hJg73Wb/3D3f0eAvBU7fFTAB6+xn4JIa4x0/3OvtTde2uPz6Ha0VUIcR0z4wU6d3dEuu2a2U4z6zKzrtFR/t1QCDG7TDfY+8xsOQDU/u9nT3T3Xe7e6e6dzc18sUcIMbtMN9ifAfB47fHjAJ6+Nu4IIWaLqUhvPwBwH4BFZnYGwFcAfA3Aj83sCwBOAnh0SjvLptGxIiyxnT/LZYYWC2dyXRwLjwPAvq791HbXHbdT2+LF86ltpBSWZHrP9dA5f/t336O2T33ik9T2ka1bqO3BT/wZtd22MXxsL/3mV3TOwCXekqn7NC8QOUbkNQBIO9G2IpqXx1K5IraoKpcJS1QZMj7ZvlKRIpDFIs+Wm842LVKAM5MNtwezyPmdNNjd/TFi+uPJ5gohrh/0CzohEoKCXYiEoGAXIiEo2IVICAp2IRJCXQtOpjNpLGgPS29e5pLB8XfDxSgbU7wnV/kyLxzZ9fob1HbnfVxkWLqkLTieM76vY6cHqe3pF56jtt7z9HdK+KNt4cKXALCwLVyE8/77eYbdunWbqO2fdvNz9fqbPPvufG/Y/3RUuipRWxwua5VLRA6L9EpLRaLCKxG5Mc2PLZXm13epFD5uj8ho7FzF1Evd2YVICAp2IRKCgl2IhKBgFyIhKNiFSAgKdiESQl2lt3x+Au8cfS9oa1+0mM6b1x7uU3a2j/coa2vihzY6zotonDjTR20pkii1pJlnUK1fwvvRnRoifcgAvPq731HbCCnaCQDbbwtnyy1ZFO6XBwAfveseatu8mRfu3HI7L4q57823guMH9x+gc86c4dmDhQIvAhm9Y1XC0lu0VRrJKKua+HVVLvCst4kCz9AsFMLXgbPMQQAVItdFs+uoRQjxB4WCXYiEoGAXIiEo2IVICAp2IRJCXVfjJyaKePdEeLV7bZq7smlLuL3SyMhxOmfsAl+pX5Dj7Z9yxlfIDx46HBxfvbiVzrlt043UlknxVkJvj364L8c/c+ESb1H1+sFw7b0FC3htvY9v30FtyxYvorb7P3YftXVuCSfrHDkSbuUFAC/8+gVq69oTbmsFAOOjXJ0ok4QRlnwCxOvMRbpGoWI8SWZsnL/WhUK4BmAlltUyDXRnFyIhKNiFSAgKdiESgoJdiISgYBciISjYhUgIU2n/9CSAzwLod/dba2NfBfDnAN7vDfRld3920r2lDBUie53s4UkQW7beFhx/5NGwJAcAr7/wGrV1H+c149rn81OSKYcTHXZ3hZM+AKB5QTiJBwBu33gTtQ0OXaY2S3EB6NxA+Ni63tpH5wyc51Lex++9i9o2rFpNbR3t4cSbu+/+KJ2z6bZbqO2V116htud/yVtbdb8XlmfHxrhMVonUmQO5BoB4+6qU8ftqhWyzHNkXba8VYSp39r8B8EBg/Jvuvq32b/JAF0LMKZMGu7u/AoD/wkMI8XvBTL6zf9HM9pvZk2bGk7aFENcF0w32bwNYD2AbgF4AX2dPNLOdZtZlZl3j47w1sBBidplWsLt7n7uX3b0C4DsA6I+r3X2Xu3e6e2dTE/9NuhBidplWsJvZ8iv+fATAwWvjjhBitrCYXAAAZvYDAPcBWASgD8BXan9vQ7WUVzeAv3D33sl2tnhpmz/y2MeCtuIYrwt389qO4PiDn/4TOqch8o3h5V//ltp6Sy3UtqwpXAdt355DfHvjvD7dv304JHJUWTyfZ6mdHuAZVOcmwgd+6vQ5OidWkW3p8hXUdu+dXEbbcevm4HhTpDagsSJ/QLS22pGj71Dbz3/+8+D4vr176ZxLA1yKHB3jteQqETksneWfakv5cKZlucwlQNYZ6sjhgxgdHQlaJ9XZ3f2xwPB3J5snhLi+0C/ohEgICnYhEoKCXYiEoGAXIiEo2IVICJNKb9eS9o4F/qkH7wjaSnn+vrO0PSx5feKe7XTOpx8IiQhVhi7xAoXPvsyzw3rf7gqOzyvzDLXufi6TDZa5HPPAZz5JbUsX81ZZx8+EFdC+Ua5Fnh/k/iOVo6bGLLdtvTWcqXjvXeHXHwBWLlpAbSNjvP1ThelQACby4fO/dw/PVPztazxjcs9bXLIbiGQq5hr4a50n7bwqsdAkh3z40AEqvenOLkRCULALkRAU7EIkBAW7EAlBwS5EQlCwC5EQ6trrLZs13HBDeJfjo5ECeoWwBvH2wQN0yo3ruCy3edunqG3DRp7V1HckLLsUx/mctcuaqW3POxeo7en//SK1PfLwZ/n+Voez1DJnzwfHASA/xmW5Uo7733eGFwndvTecsdU/yCW0ezo3UdvKJbznnDsvzNjWGs4evPvuu+mcTTfxQqBbt3Hp7cWXeFHM944do7a8ha+fTKSwaDobjiOLyJC6swuREBTsQiQEBbsQCUHBLkRCULALkRDquhqfShuaW7JBW1OO/+q/72T4Pelsb7h2FwDseYvXmWtdxNtGLV/Ga651/tGdwfGul35B5wyMjlDb6sV8pfvcEF9hPnSQ17y75fZ/Ed7XSn5cE6MlartY4au7Aw388sllw6/ZoWPv0TmDI0PU9pHNG6it8za+ep5ltd/S/Hprmc8Tcnbs4Ik8q1avorYXXuBNk958Lay8lMrhWAGAkUK4Xp9W44UQCnYhkoKCXYiEoGAXIiEo2IVICAp2IRLCpNKbma0C8D0AS1HtE7TL3b9lZu0AfgRgDaotoB51d943B0DFHePFcIKE5Xirm2I6LA2ly9z90z2nqe31t16itk2beZLMmps3Bsd7ji2jc/Yd4FJTLsXln62kfRIALLppG7W98I+/Dm9ve7gmHACsX8Mlo9aLPIFmZJhLVJmWtuB4YfgsnTMWSYZ6aTev7zY8zs/jR25ZHhw/fpjXoHuji0ubw0PD1LZ2fTu1bdywmtqOH2kMjo9G6u6VhsLXfiR3Zkp39hKAv3L3zQDuBPCXZrYZwBMAXnT3jQBerP0thLhOmTTY3b3X3ffUHl8GcBjACgAPAXiq9rSnADw8W04KIWbOVX1nN7M1AG4HsBvA0is6t55D9WO+EOI6ZcrBbmYtAH4C4Evu/oEvLl4tPh/84mRmO82sy8y6xiNFEoQQs8uUgt3MsqgG+vfd/ae14T4zW16zLwfQH5rr7rvcvdPdO5vm8UL5QojZZdJgt+ov678L4LC7f+MK0zMAHq89fhzA09fePSHEtWIqWW93A/g8gANm9n4Bri8D+BqAH5vZFwCcBPDoZBtKpRxNTWE5odQyj85rWRR2c16eSxNe4rae093UdmnkZWrbuiEssd20icsqPecuUtv4BJcbc0u5HLbqZi69VX7xy+D4L599js6578HPUNvWm8JZdABww9Db1FawsBzWnwvLTADQkOHnY3Sc286c55mFxdFwy67dL/6czjl8mNfWq0SyAE+e5hLgltt4zbtL403B8bHY9V0My9Gxdm6TBru7vwraWQp/PNl8IcT1gX5BJ0RCULALkRAU7EIkBAW7EAlBwS5EQqhrwUkvAyWS2VSISCvFYlhOKDXw96obWrmUlx/mbZdOnh2jtjXzw360pPgvA1tbuY8+Hm5NBAD5iMQzeuEUta1bHS5iaRf4D5pGLvKMsj1Hj1Nba/sSals4Hj4n7amwzAQAuQb+ml0a4y22GlN5ahsbHAyOnz49QOekypGijRYu9AgAA+e57DVymftfLoT3d7GPS28NpBZlJSK96c4uREJQsAuREBTsQiQEBbsQCUHBLkRCULALkRDqKr2VikDf2bA0kC9xyQvpsCw3r5X3wmrM8PexdKQq34JI9t3KheECixlwCe2euzqo7d2zPFvrTB+v3Xmh5yi1LV0S9jHVzCWvHXfdRW3vdndT2+nePmrbuCHcf21ZRGJtoPlWQLE9XMASALKNXG7ysXDPvGKB+xGr2hhpb4fRcd4zrxzJcMwS973C55hd/X1ad3YhEoKCXYiEoGAXIiEo2IVICAp2IRJCfRNhHCiTVdDCaHjVFADSFraNR5ISepwnd3S08TpozU3hxAkAGBsLJ9CsWL2GzlkAvro/UuCJDhORVeuWRp54M6+9NTh++hxP/jl06Ai1bdrK21AVj/AadKdOnQiOt7TyVlntRZ7Qsi7DE3kyzfw6GCRtkioVPmdhWziZCAAWtnLb0eO85Vgqxe+rC5rCPjZn+ZzCNGrQ6c4uREJQsAuREBTsQiQEBbsQCUHBLkRCULALkRAmld7MbBWA76HaktkB7HL3b5nZVwH8OYDztad+2d2fjW0rnQbawsoQPFJzrVwKvycNX+ZyXSUiXRUibXUWrONJLae6D4a3V+Qtnqyco7bBQe7H7bfcSm1NmfPUduBQ2JcT3byl0Ynj3JayCWrbsr2T2vYfPhYcP9vXGxwHgI6N66jNh7iUiois2FwJS1TrFy/kcxq4zNfWwmXblpVcVlw1j0t95Wz4OpgfSeYqIby9tPE4morOXgLwV+6+x8zmA3jTzJ6v2b7p7v9tCtsQQswxU+n11gugt/b4spkdBrBith0TQlxbruo7u5mtAXA7gN21oS+a2X4ze9LM+OciIcScM+VgN7MWAD8B8CV3HwbwbQDrAWxD9c7/dTJvp5l1mVnXOKklLoSYfaYU7GaWRTXQv+/uPwUAd+9z97K7VwB8B8CO0Fx33+Xune7e2dTEFz6EELPLpMFuZgbguwAOu/s3rhhffsXTHgEQXqoWQlwXTGU1/m4AnwdwwMz21sa+DOAxM9uGqhzXDeAvJttQyoB55OZuRJIDgCGSEVcu8wyffIFLHQXj9dj6h7gctrCJ1DM7cYbOGRzk8mCxxDPi2uZxW24pr3VWnAjX8rs0yNsdVUr8XO199TVqmzef14W7a8f24Pirr+0OjgPAO8fCch0ALL9xA7UtrvDXc17+bHD8wTu20DntHbytVa6ZS2/5Er928s7rDd6wLNwayif4nJN94esqUj5vSqvxrwLBSoBRTV0IcX2hX9AJkRAU7EIkBAW7EAlBwS5EQlCwC5EQ6lpwMgWgkUgDuZZIho+HJ5lx9y8P8qy3waGw1AEAly7yLK/lHeH9LWnlc5DmstDSG3iGXTrNf204MMylt9Vrw7LRnZt5q6a97wxRW98F3obqN7/6BbUVRsL+p0r8uHrf3UdtuWYu863cxmW0G3OrguOZCr8Gbtm2ldpQ4ddp96luauu70E9t53rCkuO9OxbTOYuPDgfH9xzmMqru7EIkBAW7EAlBwS5EQlCwC5EQFOxCJAQFuxAJoa7SW8Ud+WI4W8cqPIMtmw276ZH3qlwTl94mRqkJLU1cDkMl7PtApPBlWyv3o6MjS21jpXD2GgDctPFmamtpDZ+r/pOn6JyRUS5D7T/BbUMDYfkHAPb/9h+C46kyl4bOnOVFJdNpngW4sJ2/ZsXmcMHPEskOBICJxogkGino+Pb+Lmo7GcnoG+wOvzaLmviFumlDOE20sZHHhO7sQiQEBbsQCUHBLkRCULALkRAU7EIkBAW7EAmhrtJbseQ43R/OEGtbwGWopsawbSxShr4hx9/H5md50cB1N0R6XXg42+zcRZ4Zlsvx8tkZ43LjSJFn0g2Pc8mrfeX64PgtH9nG91U4QG2XR/lJ7j7Hs+/KpPbi8g4uU/YOcFnrxJHD1JaJnOPdJNtsZJjLWrd0hotlAsCipbwY5dHdr1LbwJlw4UsA6GgKX49jGV7Acmg0nKk4OsbPr+7sQiQEBbsQCUHBLkRCULALkRAU7EIkhElX482sEcArAHK15/+9u3/FzNYC+CGADgBvAvi8u0fbtFbcMFEI73LoMl+ZXtgUXo0fmuAr1tksXyle0MYPe0EbX6kvTYRXRxeWmumcTJqrDMUCP103b76V2tpvCK+4A0BDYzhBYjlJnACADecvUtv5s9w2mucr2mP58PmvGF85v+OmBdT2f45wBeLku+9QW4F0Di6V+Kr18aN8e6ND/JiHLnFbJZLoVSyEbakSv3YGJ8Jzyvyyn9KdfQLAJ919K6rtmR8wszsB/DWAb7r7BgCXAHxhCtsSQswRkwa7V3m/w1y29s8BfBLA39fGnwLw8Kx4KIS4Jky1P3u61sG1H8DzAN4DMOj+/35lcgbAitlxUQhxLZhSsLt72d23AVgJYAeATVPdgZntNLMuM+uaIN95hRCzz1Wtxrv7IIDfALgLQJv9c5eGlQB6yJxd7t7p7p25HF9wEELMLpMGu5ktNrO22uMmAPcDOIxq0P+b2tMeB/D0bDkphJg5U0mEWQ7gKTNLo/rm8GN3/wczOwTgh2b2XwC8BeC7k23IK44CkRnyIzwJYqwl/PG/kas4qERqhY2WuWR38gKXmjwf3mYlonec6+etlZrC5dEAADfP5wk5BW+htgs94TZPTQu4PDivlctyHYu4FLkmIpdmyYe4Fct5Lbll8/j2Uhn+ev7uEK9dVyZ1Ay3F93Wx5wy1jfXxNk7FCr8OWiKRNgFWl5HX62tIMemQH9ekwe7u+wHcHhg/jur3dyHE7wH6BZ0QCUHBLkRCULALkRAU7EIkBAW7EAnB3PlS/TXfmdl5ACdrfy4CcKFuO+fIjw8iPz7I75sfN7r74pChrsH+gR2bdbl755zsXH7IjwT6oY/xQiQEBbsQCWEug33XHO77SuTHB5EfH+QPxo85+84uhKgv+hgvREKYk2A3swfM7KiZHTOzJ+bCh5of3WZ2wMz2mllXHff7pJn1m9nBK8bazex5M3u39n+kD9Ws+vFVM+upnZO9ZvZgHfxYZWa/MbNDZva2mf372nhdz0nEj7qeEzNrNLPXzWxfzY//XBtfa2a7a3HzI7NI9c4Q7l7XfwDSqJa1WgegAcA+AJvr7UfNl24Ai+Zgvx8DsB3AwSvG/iuAJ2qPnwDw13Pkx1cB/Ic6n4/lALbXHs8H8A6AzfU+JxE/6npOABiAltrjLIDdAO4E8GMAn6uN/w8A/+5qtjsXd/YdAI65+3Gvlp7+IYCH5sCPOcPdXwEw8KHhh1At3AnUqYAn8aPuuHuvu++pPb6ManGUFajzOYn4UVe8yjUv8joXwb4CwOkr/p7LYpUO4Dkze9PMds6RD++z1N17a4/PAVg6h7580cz21z7mz/rXiSsxszWo1k/YjTk8Jx/yA6jzOZmNIq9JX6C7x923A/gTAH9pZh+ba4eA6js7YiVHZpdvA1iPao+AXgBfr9eOzawFwE8AfMndP9AVop7nJOBH3c+Jz6DIK2Mugr0HwKor/qbFKmcbd++p/d8P4GeY28o7fWa2HABq//P6R7OIu/fVLrQKgO+gTufEzLKoBtj33f2nteG6n5OQH3N1Tmr7vuoir4y5CPY3AGysrSw2APgcgGfq7YSZNZvZ/PcfA/g0gIPxWbPKM6gW7gTmsIDn+8FV4xHU4ZyYmaFaw/Cwu3/jClNdzwnzo97nZNaKvNZrhfFDq40PorrS+R6A/zhHPqxDVQnYB+DtevoB4Aeofhwsovrd6wuo9sx7EcC7AF4A0D5HfvwtgAMA9qMabMvr4Mc9qH5E3w9gb+3fg/U+JxE/6npOAGxBtYjrflTfWP7TFdfs6wCOAfhfAHJXs139gk6IhJD0BTohEoOCXYiEoGAXIiEo2IVICAp2IRKCgl2IhKBgFyIhKNiFSAj/F1U5f8KjgXVLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmEo_9lnwyBk"
      },
      "source": [
        "RANDOM_SEED = [42,13,10]\n",
        "# Settings\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "NUM_CLASSES = 100       # Total number of classes\n",
        "\n",
        "VAL_SIZE = 0.1          # Proportion of validation set with respect to training set (between 0 and 1)\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 128        # Batch size\n",
        "LR = 2               # Initial learning rate\n",
        "                       \n",
        "MOMENTUM = 0.9          # Momentum for stochastic gradient descent (SGD)\n",
        "WEIGHT_DECAY = 1e-5     # Weight decay from iCaRL\n",
        "\n",
        "NUM_RUNS = 3            # Number of runs of every method\n",
        "                        # Note: this should be at least 3 to have a fair benchmark\n",
        "\n",
        "NUM_EPOCHS = 70         # Total number of training epochs\n",
        "MILESTONES = [49, 63]   # Step down policy from iCaRL (MultiStepLR)\n",
        "                        # Decrease the learning rate by gamma at each milestone\n",
        "GAMMA = 0.2             # Gamma factor from iCaRL"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mr8mBkBx7BV"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efcfUm_jEOVh"
      },
      "source": [
        "## Training Larocca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hNLpdJTWSR1"
      },
      "source": [
        "class FineTuning(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(FineTuning, self).__init__()\n",
        "    self.feature_extractor = resnet32()\n",
        "    self.n_classes = n_classes\n",
        "    self.n_known = 0\n",
        "    self.p = self.parameters()\n",
        "    self.fc = nn.Linear(10, n_classes, bias = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.feature_extractor(x)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def increment_classes(self, n):\n",
        "    in_features = self.feature_extractor.in_features\n",
        "    out_features = self.fc.out_features\n",
        "    weight = self.fc.weight.data\n",
        "    bias = self.fc.bias.data\n",
        "\n",
        "    self.fc = nn.Linear(in_features, out_features+n, bias=True)\n",
        "    self.fc.weight.data[:out_features] = weight\n",
        "    self.fc.bias.data[:out_features] = bias\n",
        "    self.n_classes += n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvbNmnd_WWH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "c2b2e021-debe-4b6d-c558-249ca444473b"
      },
      "source": [
        "train_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "test_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "\n",
        "best_acc = []\n",
        "tot_matrix = []\n",
        "tot_labe = []\n",
        "\n",
        "#net = FineTuning(10)\n",
        "net = resnet32()\n",
        "\n",
        "\n",
        "for run_i in range(len(RANDOM_SEED)):\n",
        "  random_state = RANDOM_SEED[run_i]\n",
        "  subset_train = []\n",
        "  subset_test = []\n",
        "\n",
        "  train_data.__shuffle_seed__(RANDOM_SEED[run_i])\n",
        "  test_data.__shuffle_seed__(RANDOM_SEED[run_i])\n",
        "\n",
        "  indexes_train_data = train_data.__incremental_indexes__(True)\n",
        "  indexes_test_data = test_data.__incremental_indexes__(False)\n",
        "\n",
        "  train_dataloader = []\n",
        "  test_dataloader = []\n",
        "\n",
        "  for i in range(10):\n",
        "    train_dataset = Subset(train_data, indexes_train_data[i])\n",
        "    subset_train.append(train_dataset) #[[train0],[train1],...]\n",
        "    train_dataloader=DataLoader(subset_train[i],\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True)\n",
        "    \n",
        "    test_dataset = Subset(test_data, indexes_test_data[i])\n",
        "    subset_test.append(test_dataset) #[[train0],[train1],...]\n",
        "    test_dataloader=DataLoader(subset_test[i],\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True)\n",
        "    net.cuda()\n",
        "    if(i!=0):\n",
        "      net.addOutputNodes(10)\n",
        "      \n",
        "    net.train()\n",
        "    \n",
        "    p = net.parameters()\n",
        "    optimizer = optim.SGD(p, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA)\n",
        "\n",
        "    matrix = []\n",
        "    labe = []    \n",
        "    b_ac = 0\n",
        "    #Training\n",
        "\n",
        "    for epoch in range(0, NUM_EPOCHS):\n",
        "      running_corrects = 0\n",
        "      total = 0\n",
        "\n",
        "      for indices, images, labels in train_dataloader:\n",
        "        images = Variable(images).cuda()\n",
        "        labels = Variable(labels).cuda()\n",
        "        indices = indices.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        g = net(images)\n",
        "        #print(g)\n",
        "        #g = net.forward(images)\n",
        "        _, preds = torch.max(g, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "\n",
        "        #Loss\n",
        "        g.cuda()\n",
        "        #print(\"Loss1 : {}\".format(loss))\n",
        "        loss = criterion(g, labels)\n",
        "        #print(\"Loss2 : {}\".format(loss))\n",
        "        loss.backward()\n",
        "        #print(\"Loss3 : {}\".format(loss))\n",
        "        optimizer.step()\n",
        "\n",
        "      accuracy = running_corrects / float(total)\n",
        "      scheduler.step()\n",
        "      print ('Epoch (%d/%d), Loss: %.4f, Accuracy: %.2f' %(epoch+1, NUM_EPOCHS, loss, accuracy))\n",
        "\n",
        "      #test\n",
        "      m = []\n",
        "      l = []\n",
        "      #net.train(False)\n",
        "      net.eval()  #per spegnere i layer di dropout\n",
        "      total = 0.0\n",
        "      running_corrects = 0\n",
        "      for indices, images, labels in test_dataloader:\n",
        "        images = Variable(images).cuda()\n",
        "        labels = Variable(labels).cuda()\n",
        "        indices = indices.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        g = net(images)\n",
        "        #g = net.forward(images)\n",
        "        _, preds = torch.max(g, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        m.extend(preds)\n",
        "        l.extend(labels)\n",
        "\n",
        "      matrix.append(m)\n",
        "      labe.append(l)\n",
        "\n",
        "      accuracy = float(running_corrects / float(total))\n",
        "      print('Test Accuracy', accuracy)\n",
        "\n",
        "      if(b_ac < accuracy):\n",
        "        b_ac = accuracy\n",
        "      \n",
        "  tot_matrix.append(matrix)\n",
        "  tot_labe.append(labe)\n",
        "  best_acc.append(b_ac)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/70), Loss: 2.3369, Accuracy: 0.11\n",
            "Test Accuracy 0.007612179487179487\n",
            "Epoch (2/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.010016025641025642\n",
            "Epoch (3/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.010016025641025642\n",
            "Epoch (4/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.010016025641025642\n",
            "Epoch (5/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.009915865384615384\n",
            "Epoch (6/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.010016025641025642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-cd76b8fac94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZOt-s7ZEVfC"
      },
      "source": [
        "## Training Montagna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hajNZJmbcui9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8154f817-3ce5-46ac-f459-b77f6f3633a6"
      },
      "source": [
        "train_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "val_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "test_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "\n",
        "\n",
        "for run_i in range(len(RANDOM_SEED)):\n",
        "  random_state = RANDOM_SEED[run_i]\n",
        "  \n",
        "\n",
        "  train_data.__shuffle_seed__(RANDOM_SEED[run_i])\n",
        "  test_data.__shuffle_seed__(RANDOM_SEED[run_i])\n",
        "  \n",
        "\n",
        "  indexes_train_data = train_data.__incremental_indexes__(True)\n",
        "  indexes_test_data = test_data.__incremental_indexes__(False)\n",
        "\n",
        "  for i in range(10):\n",
        "    train_dataset = Subset(train_data, indexes_train_data[i])\n",
        "    train_set, val_set = torch.utils.data.random_split(train_dataset, [int(0.8*len(indexes_train_data[i])), int(0.2*len(indexes_train_data[i]))])\n",
        "    #subset_train.append(train_set) #[[train0],[train1],...]\n",
        "    #subset_val.append(val_set) \n",
        "    train_dataloader[run_i].append(DataLoader(train_set,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True))\n",
        "    val_dataloader[run_i].append(DataLoader(val_set,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True))\n",
        "    \n",
        "    test_dataset = Subset(test_data, indexes_test_data[i])\n",
        "    #subset_test.append(test_dataset) #[[train0],[train1],...]\n",
        "    test_dataloader[run_i].append(DataLoader(test_dataset,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True))\n",
        "    "
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUYTSpVYfCMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "657ea9e7-4082-49b9-e5b0-28b396826041"
      },
      "source": [
        "from data.utils_plot import check_cifar100_dataloader\n",
        "check_cifar100_dataloader(val_dataloader)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sea\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flMwPsCIbQIp"
      },
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdRGb-VIEY-e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b5d4cc3-ed34-4807-ecd4-850d15cc4499"
      },
      "source": [
        "logs = [[] for _ in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    net = resnet32()\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    for split_i in range(10):\n",
        "        print(f\"## Split {split_i} of run {run_i} ##\")\n",
        "\n",
        "        parameters_to_optimize = net.parameters()\n",
        "        optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA)\n",
        "\n",
        "        manager = Trainer(DEVICE, net, criterion, optimizer, scheduler,\n",
        "                          train_dataloader[run_i][split_i],\n",
        "                          val_dataloader[run_i][split_i],\n",
        "                          test_dataloader[run_i][split_i])\n",
        "\n",
        "        scores = manager.train(NUM_EPOCHS)  # train the model\n",
        "\n",
        "        logs[run_i].append({})\n",
        "\n",
        "        # score[i] = dictionary with key:epoch, value: score\n",
        "        logs[run_i][split_i]['train_loss'] = scores[0]\n",
        "        logs[run_i][split_i]['train_accuracy'] = scores[1]\n",
        "        logs[run_i][split_i]['val_loss'] = scores[2]\n",
        "        logs[run_i][split_i]['val_accuracy'] = scores[3]\n",
        "\n",
        "        # Test the model on classes seen until now\n",
        "        test_accuracy, all_targets, all_preds = manager.test()\n",
        "\n",
        "        logs[run_i][split_i]['test_accuracy'] = test_accuracy\n",
        "        logs[run_i][split_i]['conf_mat'] = confusion_matrix(all_targets.to('cpu'), all_preds.to('cpu'))\n",
        "\n",
        "        # Add 10 nodes to last FC layer\n",
        "        manager.increment_classes(n=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Split 0 of run 0 ##\n",
            "Epoch: 1, LR: [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "output: tensor([[ 0.9194, -0.9590,  0.7439, -0.9826, -0.2627, -1.0050,  0.7887,  0.6696,\n",
            "          2.1407,  0.1130],\n",
            "        [ 0.3057, -0.9949,  0.1400, -0.2803, -0.0398, -0.2558,  0.2307,  0.8007,\n",
            "          1.3077,  0.1453],\n",
            "        [ 0.1413, -1.0062,  0.2902, -0.3347, -0.1481, -0.2450,  0.2323,  0.6183,\n",
            "          1.4084,  0.2393],\n",
            "        [ 0.2985, -0.8117,  0.1122, -0.5369, -0.1188, -0.2595,  0.1364,  0.7010,\n",
            "          1.1449,  0.2312],\n",
            "        [ 0.3061, -0.9256,  0.3193, -0.3967, -0.1577, -0.2140,  0.3303,  0.6258,\n",
            "          1.3368,  0.0913],\n",
            "        [ 0.8168, -0.7340,  0.3187, -0.7376, -0.0913, -0.7567,  0.5063,  0.5420,\n",
            "          1.8608,  0.1010],\n",
            "        [ 0.1215, -0.9279,  0.2693, -0.1525,  0.0083, -0.2568,  0.2589,  0.7401,\n",
            "          1.2438,  0.2118],\n",
            "        [ 0.2736, -0.9361,  0.2965, -0.3977, -0.0612, -0.0936,  0.3126,  0.5906,\n",
            "          1.3916,  0.2055],\n",
            "        [ 0.7158, -0.6735,  0.2820, -0.7241, -0.1995, -0.7049,  0.4589,  0.5945,\n",
            "          1.4419,  0.0591],\n",
            "        [ 0.2400, -0.9475,  0.1855, -0.3869, -0.1161, -0.0982,  0.1674,  0.6950,\n",
            "          1.2177,  0.2393],\n",
            "        [ 0.3405, -0.7803,  0.1672, -0.2846, -0.0081, -0.3051,  0.1672,  0.6840,\n",
            "          1.2259,  0.1646],\n",
            "        [ 0.2304, -1.0393,  0.3870, -0.4284, -0.1268, -0.1732,  0.2675,  0.4967,\n",
            "          1.3846, -0.0236],\n",
            "        [ 0.4087, -0.8776,  0.1852, -0.5431, -0.1300, -0.0651,  0.2970,  0.6132,\n",
            "          1.4215,  0.1029],\n",
            "        [ 0.1836, -0.9316,  0.3525, -0.2124, -0.0914, -0.3093,  0.2578,  0.6856,\n",
            "          1.2368,  0.1998],\n",
            "        [ 0.3224, -0.9449,  0.2804, -0.3153, -0.1859, -0.3187,  0.1465,  0.6378,\n",
            "          1.3153,  0.0707],\n",
            "        [ 0.3422, -1.0581,  0.4221, -0.3026, -0.2231, -0.2775,  0.4311,  0.4891,\n",
            "          1.4631,  0.0542],\n",
            "        [ 0.3428, -0.9148,  0.3220, -0.3349, -0.1529, -0.1243,  0.3452,  0.6074,\n",
            "          1.2536,  0.1093],\n",
            "        [ 0.3369, -1.2069,  0.3248, -0.5166, -0.1924, -0.4117,  0.4641,  0.5540,\n",
            "          1.6962, -0.0545],\n",
            "        [ 0.9667, -1.0301,  0.5076, -0.7223, -0.1177, -1.3557,  1.0401,  0.8539,\n",
            "          2.4369,  0.0280],\n",
            "        [ 0.2646, -0.7637,  0.2365, -0.1650,  0.0058, -0.2910,  0.3291,  0.6008,\n",
            "          0.9930,  0.0979],\n",
            "        [ 0.3867, -0.8117,  0.1853, -0.3658, -0.1783, -0.2019,  0.3309,  0.6678,\n",
            "          1.2945,  0.1160],\n",
            "        [ 0.2204, -1.0599,  0.2241, -0.3405, -0.1049, -0.2864,  0.2178,  0.6609,\n",
            "          1.1963,  0.1985],\n",
            "        [ 0.6794, -0.9302,  0.3275, -0.3912,  0.0168, -0.7939,  0.8397,  0.6014,\n",
            "          1.6909,  0.0947],\n",
            "        [ 0.3004, -0.7937,  0.2642, -0.3583, -0.0242, -0.3672,  0.1974,  0.6330,\n",
            "          1.2559,  0.1439],\n",
            "        [ 0.2058, -0.9612,  0.2363, -0.4329, -0.0703, -0.1683,  0.2610,  0.6955,\n",
            "          1.2109,  0.3228],\n",
            "        [ 0.4451, -0.7960,  0.2506, -0.3819, -0.1312, -0.4205,  0.3221,  0.6596,\n",
            "          1.2338,  0.0733],\n",
            "        [ 0.1163, -0.8387,  0.2847, -0.2974, -0.0193, -0.1038,  0.0760,  0.6445,\n",
            "          1.2418,  0.3100],\n",
            "        [ 0.5844, -0.6037,  0.1366, -0.2920, -0.1429, -0.4356,  0.2383,  0.7941,\n",
            "          1.3113,  0.2180],\n",
            "        [ 0.2698, -0.8572,  0.2370, -0.3059, -0.0882, -0.1262,  0.1012,  0.6530,\n",
            "          1.1955,  0.3711],\n",
            "        [ 0.2149, -0.9229,  0.2267, -0.3405, -0.0753, -0.3064,  0.0486,  0.6662,\n",
            "          1.1039,  0.0587],\n",
            "        [ 0.2781, -0.9712,  0.3015, -0.3343, -0.0186, -0.3832,  0.3652,  0.5859,\n",
            "          1.5284,  0.1103],\n",
            "        [ 1.3304, -0.7731,  0.5079, -1.2609, -0.2397, -1.1681,  1.0908,  0.9013,\n",
            "          2.3661,  0.1409],\n",
            "        [ 0.3755, -1.0965,  0.4126, -0.2835, -0.2413, -0.3554,  0.5511,  0.4572,\n",
            "          1.4230, -0.0545],\n",
            "        [ 1.1287, -0.9221,  0.5649, -0.5008,  0.1786, -1.2089,  1.2462,  0.8387,\n",
            "          2.3525, -0.1489],\n",
            "        [ 0.2341, -0.9859,  0.2893, -0.3288, -0.1106, -0.2095,  0.2963,  0.6527,\n",
            "          1.2279,  0.0549],\n",
            "        [ 0.6138, -1.2445,  0.4893, -0.4318, -0.2422, -0.9219,  1.0228,  0.5895,\n",
            "          2.0000, -0.2030],\n",
            "        [ 1.1851, -1.2030,  0.5422, -0.7523,  0.1048, -1.4714,  1.1396,  0.7729,\n",
            "          2.4715, -0.3508],\n",
            "        [ 0.4596, -0.7203,  0.1942, -0.5413, -0.0671, -0.2949,  0.3281,  0.6777,\n",
            "          1.4021,  0.1995],\n",
            "        [ 0.3953, -1.0437,  0.3803, -0.4457, -0.0293, -0.3674,  0.6116,  0.6516,\n",
            "          1.5311,  0.0285],\n",
            "        [ 0.4481, -0.8259,  0.2838, -0.4711,  0.0157, -0.2727,  0.3769,  0.6529,\n",
            "          1.2943,  0.0780],\n",
            "        [ 0.5617, -0.7516,  0.4204, -0.5638, -0.1439, -0.4183,  0.4256,  0.6260,\n",
            "          1.4879,  0.1770],\n",
            "        [ 0.1275, -0.7189,  0.2301, -0.3350,  0.0552, -0.2205,  0.2645,  0.6145,\n",
            "          1.3703,  0.0917],\n",
            "        [ 0.5073, -1.1565,  0.3929, -0.0821, -0.1287, -0.7451,  0.7887,  0.5863,\n",
            "          1.8723,  0.0363],\n",
            "        [ 0.1796, -1.0322,  0.3891, -0.3407, -0.0813, -0.2725,  0.3230,  0.6118,\n",
            "          1.2570,  0.2967],\n",
            "        [ 0.1548, -0.9891,  0.1313, -0.3515,  0.0037, -0.1625,  0.3525,  0.7327,\n",
            "          1.3942,  0.1871],\n",
            "        [ 0.5120, -0.7945,  0.1894, -0.3400, -0.0882, -0.3040,  0.3008,  0.6322,\n",
            "          1.2234,  0.1583],\n",
            "        [ 1.1766, -0.5762,  0.5684, -0.8576, -0.0268, -1.3894,  0.8423,  0.7828,\n",
            "          2.0010,  0.2362],\n",
            "        [ 0.1927, -0.8853,  0.1771, -0.3813, -0.0866, -0.1861,  0.1548,  0.6989,\n",
            "          1.3113,  0.1634],\n",
            "        [ 0.5145, -1.0241,  0.3487, -0.2895, -0.0486, -0.4593,  0.6425,  0.4887,\n",
            "          1.5469,  0.1030],\n",
            "        [ 0.2975, -0.8864,  0.4167, -0.4800, -0.0420, -0.4632,  0.2845,  0.7270,\n",
            "          1.2270,  0.1333],\n",
            "        [ 0.1740, -1.0177,  0.2244, -0.2477, -0.0307, -0.0475,  0.1373,  0.6074,\n",
            "          0.9945,  0.0809],\n",
            "        [ 0.3910, -0.8503,  0.3767, -0.3334, -0.1352, -0.3086,  0.3581,  0.5551,\n",
            "          1.5706,  0.0340],\n",
            "        [ 0.3865, -0.6562,  0.2575, -0.3144, -0.0052, -0.4535,  0.1992,  0.7732,\n",
            "          1.3047,  0.1812],\n",
            "        [ 0.2396, -1.0868,  0.4706, -0.3873,  0.0733, -0.7235,  0.4931,  0.6149,\n",
            "          1.7060, -0.0225],\n",
            "        [ 0.1433, -0.9328,  0.2324, -0.2836, -0.0397, -0.0667,  0.2253,  0.6993,\n",
            "          1.2594,  0.2824],\n",
            "        [ 0.1765, -0.8549,  0.2586, -0.2337, -0.0652, -0.1442,  0.2288,  0.5985,\n",
            "          1.2942,  0.2896],\n",
            "        [ 0.3168, -0.9708,  0.2126, -0.3280, -0.0456, -0.4656,  0.2929,  0.7441,\n",
            "          1.3884,  0.1740],\n",
            "        [ 0.1628, -0.9576,  0.4615, -0.2560, -0.0342,  0.0046,  0.3133,  0.4830,\n",
            "          1.1722,  0.1861],\n",
            "        [ 0.3616, -0.9015,  0.1140, -0.1532, -0.1137, -0.2754,  0.2327,  0.8425,\n",
            "          1.0546,  0.1535],\n",
            "        [ 0.6530, -1.0201,  0.2602, -0.3452, -0.2494, -0.4239,  0.6233,  0.4724,\n",
            "          1.7493, -0.0248],\n",
            "        [ 0.4511, -0.8355,  0.1697, -0.4928, -0.0883, -0.2585,  0.2324,  0.5123,\n",
            "          1.5209,  0.2089],\n",
            "        [ 0.8221, -0.9016,  0.5529, -0.6504, -0.1689, -0.9937,  0.8284,  0.6588,\n",
            "          2.1435,  0.1530],\n",
            "        [ 0.6916, -0.9835,  0.2868, -0.5458, -0.1932, -0.7279,  0.3577,  0.7096,\n",
            "          1.8585,  0.1691],\n",
            "        [ 0.5391, -0.9949,  0.3153, -0.4601, -0.2192, -0.4165,  0.5696,  0.5983,\n",
            "          1.7063,  0.0699]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "labels: tensor([73, 72, 74, 58, 35, 20, 19, 80, 28, 90, 17, 35, 27, 18, 38, 11, 65, 36,\n",
            "         2, 40, 10, 34, 80, 13, 15, 16, 67, 10, 60, 41, 64, 67, 64, 24, 61, 72,\n",
            "        35, 67, 33,  5, 86,  3, 38, 92,  4, 43, 24, 80, 20, 25, 71, 65, 26, 70,\n",
            "         8, 34, 21, 96, 10, 82,  4,  5, 34, 81], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-01fc5fce8ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                           test_dataloader[run_i][split_i])\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ProjectMLDL/model/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Run an epoch (start counting form 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Validate after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ProjectMLDL/model/trainer.py\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(self, current_epoch)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ProjectMLDL/model/trainer.py\u001b[0m in \u001b[0;36mdo_batch\u001b[0;34m(self, batch, labels)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m#loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1048\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2386\u001b[0m         )\n\u001b[1;32m   2387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:115"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkw52To1iUwt",
        "outputId": "a228c3b4-5369-4347-c3d5-623c80ecae17"
      },
      "source": [
        "list = [73, 72, 74, 58, 35, 20, 19, 80, 28, 90, 17, 35, 27, 18, 38, 11, 65, 36,\n",
        "         2, 40, 10, 34, 80, 13, 15, 16, 67, 10, 60, 41, 64, 67, 64, 24, 61, 72,\n",
        "        35, 67, 33,  5, 86,  3, 38, 92,  4, 43, 24, 80, 20, 25, 71, 65, 26, 70,\n",
        "         8, 34, 21, 96, 10, 82,  4,  5, 34, 81]\n",
        "\n",
        "ins = set(list)\n",
        "len(ins)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX-EdN4znF2Z",
        "outputId": "a50eb5ed-7c80-4283-e441-2f85b142767b"
      },
      "source": [
        "tot = set([])\n",
        "for k in range(1):\n",
        "  for i in range(5000):\n",
        "    idx = indexes_train_data[k][i]\n",
        "    lbl = train_data.__getitem__(idx)[2]\n",
        "    tot.add(lbl)\n",
        "\n",
        "tot"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5arFUoICJDW",
        "outputId": "929f51c1-67b4-42a0-c2d8-8dd0fe4b4caa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(next(iter(test_dataloader[0][9]))[2])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4pEBuFdCpqM",
        "outputId": "b2973de0-023a-4510-923b-98017579a3a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442, tensor([[[-0.7082, -0.2978,  0.1860,  ..., -0.6496, -0.6789, -1.8957],\n",
              "          [-0.7229, -0.3857,  0.0687,  ..., -0.6203, -0.6203, -1.8957],\n",
              "          [-0.7082, -0.4737, -0.0632,  ..., -0.6203, -0.5177, -1.8957],\n",
              "          ...,\n",
              "          [-0.4150, -0.1951, -0.0339,  ..., -0.2391, -0.1512, -1.8957],\n",
              "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
              "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
              " \n",
              "         [[-0.7967, -0.0781,  0.6252,  ..., -1.0107, -0.9954, -1.8975],\n",
              "          [-0.8273, -0.2004,  0.5029,  ..., -1.0107, -0.8884, -1.8975],\n",
              "          [-0.8578, -0.3227,  0.3653,  ..., -0.9801, -0.6132, -1.8975],\n",
              "          ...,\n",
              "          [ 0.1512,  0.2124,  0.1971,  ...,  0.5029,  0.3806, -1.8975],\n",
              "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
              "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
              " \n",
              "         [[-0.8437, -0.8864, -0.4318,  ..., -0.9432, -0.9432, -1.5965],\n",
              "          [-0.8011, -0.9432, -0.6023,  ..., -0.9006, -0.9006, -1.5965],\n",
              "          [-0.7727, -0.9716, -0.7869,  ..., -0.8864, -0.8295, -1.5965],\n",
              "          ...,\n",
              "          [-1.4261, -1.0852, -0.6875,  ...,  0.3209,  0.0369, -1.5965],\n",
              "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
              "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]]), 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDg2IZdaReFH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRoS-R_sRhHT"
      },
      "source": [
        "## Antonio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb_MRBMLSLW1"
      },
      "source": [
        "  train_data.__shuffle_seed__(RANDOM_SEED[0])\n",
        "  test_data.__shuffle_seed__(RANDOM_SEED[0])\n",
        "  \n",
        "\n",
        "  indexes_train_data = train_data.__incremental_indexes__(True)\n",
        "  indexes_test_data = test_data.__incremental_indexes__(False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVh61C63FECy",
        "outputId": "6f66a16a-09a8-4e15-f3a3-889ab9acb509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset = Subset(train_data, indexes_train_data[0])\n",
        "train_set, val_set = torch.utils.data.random_split(train_dataset, [int(0.8*len(indexes_train_data[0])), int(0.2*len(indexes_train_data[0]))])\n",
        "train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          drop_last=True)\n",
        "val_dataloader = DataLoader(val_set, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgRtxN8N-09b",
        "outputId": "f7b7a37f-a460-4d61-c599-d6681e52efed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_dataset = Subset(test_data, indexes_test_data[0])\n",
        "#subset_test.append(test_dataset) #[[train0],[train1],...]\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvRuvlH3Syf1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.backends import cudnn\n",
        "from copy import deepcopy"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad1QQmI5vJjy"
      },
      "source": [
        "def to_onehot(net, targets, device): \n",
        "  '''\n",
        "  Args:\n",
        "  targets : dataloader.dataset.targets of the new task images\n",
        "  '''\n",
        "  num_classes = net.fc.out_features\n",
        "  one_hot_targets = torch.eye(num_classes)[targets]\n",
        "\n",
        "  return one_hot_targets.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKiy8o9YgaXC"
      },
      "source": [
        "def train(net, criterion, optimizer, train_dl, device):\n",
        "  net.train()\n",
        "\n",
        "  running_loss = 0\n",
        "\n",
        "  for batch in train_dl:\n",
        "    labels = batch[2]\n",
        "    images = batch[1]\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    one_hot_labels = to_onehot(net, labels, device) \n",
        "\n",
        "    output = net(images)\n",
        "    loss = criterion(output, one_hot_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    epoch_loss = running_loss/len(train_dl)\n",
        "  return epoch_loss\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk8THneNZ97U"
      },
      "source": [
        "#### VALIDATION\n",
        "\n",
        "def validate(net, criterion, optimizer, validation_dl, device):\n",
        "  net.train(False)\n",
        "  running_loss=0\n",
        "  running_corrects = 0\n",
        "  total = 0\n",
        "  for batch in validation_dl:\n",
        "    labels = batch[2]\n",
        "    images = batch[1]\n",
        "    total += labels.size(0)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    one_hot_labels = to_onehot(net, labels, device) \n",
        "\n",
        "    output = net(images)\n",
        "    loss = criterion(output, one_hot_labels)\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    _, preds = torch.max(output.data, 1)\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "  else:\n",
        "    val_loss = running_loss/len(validation_dl)\n",
        "    \n",
        "\n",
        "  val_accuracy = running_corrects / float(total)\n",
        "  \n",
        "\n",
        "  return val_loss, val_accuracy"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoKj6zF9AkEn"
      },
      "source": [
        "def test(best_net, test_dl, device):\n",
        "  \"\"\"Test the model.\n",
        "  Returns:\n",
        "      accuracy (float): accuracy of the model on the test set\n",
        "  \"\"\"\n",
        "\n",
        "  best_net.train(False)  # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  total = 0\n",
        "\n",
        "  all_preds = torch.tensor([]) # to store all predictions\n",
        "  all_preds = all_preds.type(torch.LongTensor)\n",
        "  all_targets = torch.tensor([])\n",
        "  all_targets = all_targets.type(torch.LongTensor)\n",
        "\n",
        "  for _, images, labels in test_dl:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      total += labels.size(0)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = best_net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # Append batch predictions and labels\n",
        "      all_targets = torch.cat(\n",
        "          (all_targets.to(device), labels.to(device)), dim=0\n",
        "      )\n",
        "      all_preds = torch.cat(\n",
        "          (all_preds.to(device), preds.to(device)), dim=0\n",
        "      )\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = running_corrects / float(total)  \n",
        "\n",
        "  print(f\"Test accuracy: {accuracy}\")\n",
        "\n",
        "  return accuracy, all_targets, all_preds"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNPwfXa2tqpV",
        "outputId": "c86e72d7-63cf-4a18-9f26-5ce94d9b7243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net = resnet32()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA)\n",
        "\n",
        "\n",
        "net.to(DEVICE)\n",
        "cudnn.benchmark\n",
        "num_epochs = 80\n",
        "\n",
        "epoch_losses = []\n",
        "best_acc = 0\n",
        "best_net = deepcopy(net)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  e_loss = train(net, criterion, optimizer, train_dataloader, DEVICE)\n",
        "  epoch_losses.append(e_loss)\n",
        "  print(f\"Epoch[{epoch}] loss: {e_loss} LR: {scheduler.get_last_lr()}\")\n",
        "  validate_loss, validate_acc = validate(net, criterion, optimizer, val_dataloader, DEVICE)\n",
        "  print(f\"val loss: {validate_loss}\")\n",
        "  print(f\"val acc: {validate_acc}\")\n",
        "  scheduler.step()\n",
        "  if validate_acc > best_acc:\n",
        "    best_acc = validate_acc\n",
        "    best_net = deepcopy(net)\n",
        "    best_epoch = epoch\n",
        "    print(\"Best model updated\")\n",
        "  print(\"\")\n",
        "\n",
        "print(\"Finished!\")\n",
        "print(f\"Best model at epoch {best_epoch}, best accuracy: {best_acc:.2f}\")\n",
        "print(\"\")\n",
        "acc_all, all_targets, all_preds = test(best_net, test_dataloader, DEVICE)\n",
        "print(f\"Testing classes seen so far, accuracy: {acc_all}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch[0] loss: 0.43969313463857096 LR: [2]\n",
            "val loss: 0.3518076922212328\n",
            "val acc: 0.11830357142857142\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.32527960404273004 LR: [2]\n",
            "val loss: 0.3207168068204607\n",
            "val acc: 0.1328125\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.32076531456362817 LR: [2]\n",
            "val loss: 0.31926160199301584\n",
            "val acc: 0.13392857142857142\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.3171304012498548 LR: [2]\n",
            "val loss: 0.315190532377788\n",
            "val acc: 0.15178571428571427\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.313697442893059 LR: [2]\n",
            "val loss: 0.3105091708047049\n",
            "val acc: 0.15959821428571427\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.30919758542891473 LR: [2]\n",
            "val loss: 0.30457161579813274\n",
            "val acc: 0.1953125\n",
            "Best model updated\n",
            "\n",
            "Epoch[6] loss: 0.3046097380499686 LR: [2]\n",
            "val loss: 0.30410794275147573\n",
            "val acc: 0.18973214285714285\n",
            "\n",
            "Epoch[7] loss: 0.2988329750876273 LR: [2]\n",
            "val loss: 0.2972491042954581\n",
            "val acc: 0.22209821428571427\n",
            "Best model updated\n",
            "\n",
            "Epoch[8] loss: 0.29645234250253244 LR: [2]\n",
            "val loss: 0.29514925820486887\n",
            "val acc: 0.203125\n",
            "\n",
            "Epoch[9] loss: 0.28950555574509407 LR: [2]\n",
            "val loss: 0.28937407050813946\n",
            "val acc: 0.28013392857142855\n",
            "Best model updated\n",
            "\n",
            "Epoch[10] loss: 0.28658372067636056 LR: [2]\n",
            "val loss: 0.2888167074748448\n",
            "val acc: 0.27455357142857145\n",
            "\n",
            "Epoch[11] loss: 0.2838673053249236 LR: [2]\n",
            "val loss: 0.29714849165507723\n",
            "val acc: 0.2578125\n",
            "\n",
            "Epoch[12] loss: 0.2788159818418564 LR: [2]\n",
            "val loss: 0.28629311067717417\n",
            "val acc: 0.30357142857142855\n",
            "Best model updated\n",
            "\n",
            "Epoch[13] loss: 0.2748642717638323 LR: [2]\n",
            "val loss: 0.27655480589185444\n",
            "val acc: 0.35379464285714285\n",
            "Best model updated\n",
            "\n",
            "Epoch[14] loss: 0.2681544971081518 LR: [2]\n",
            "val loss: 0.2691164825643812\n",
            "val acc: 0.3325892857142857\n",
            "\n",
            "Epoch[15] loss: 0.26471622913114484 LR: [2]\n",
            "val loss: 0.26843042033059256\n",
            "val acc: 0.36049107142857145\n",
            "Best model updated\n",
            "\n",
            "Epoch[16] loss: 0.2590427004521893 LR: [2]\n",
            "val loss: 0.2621629812887737\n",
            "val acc: 0.3716517857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[17] loss: 0.25752815892619474 LR: [2]\n",
            "val loss: 0.28511270029204233\n",
            "val acc: 0.34933035714285715\n",
            "\n",
            "Epoch[18] loss: 0.25161942262803355 LR: [2]\n",
            "val loss: 0.2704379217965262\n",
            "val acc: 0.39285714285714285\n",
            "Best model updated\n",
            "\n",
            "Epoch[19] loss: 0.25087503175581655 LR: [2]\n",
            "val loss: 0.262129796402795\n",
            "val acc: 0.40736607142857145\n",
            "Best model updated\n",
            "\n",
            "Epoch[20] loss: 0.24548053645318554 LR: [2]\n",
            "val loss: 0.2445134392806462\n",
            "val acc: 0.4408482142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[21] loss: 0.24405593449069607 LR: [2]\n",
            "val loss: 0.2517063788005284\n",
            "val acc: 0.44308035714285715\n",
            "Best model updated\n",
            "\n",
            "Epoch[22] loss: 0.24228942682666163 LR: [2]\n",
            "val loss: 0.2514010965824127\n",
            "val acc: 0.43080357142857145\n",
            "\n",
            "Epoch[23] loss: 0.23915796606771408 LR: [2]\n",
            "val loss: 0.24712360543864115\n",
            "val acc: 0.44754464285714285\n",
            "Best model updated\n",
            "\n",
            "Epoch[24] loss: 0.23715436602792433 LR: [2]\n",
            "val loss: 0.24998054121221816\n",
            "val acc: 0.4263392857142857\n",
            "\n",
            "Epoch[25] loss: 0.23330977078407042 LR: [2]\n",
            "val loss: 0.25306248877729687\n",
            "val acc: 0.44419642857142855\n",
            "\n",
            "Epoch[26] loss: 0.2304564651943022 LR: [2]\n",
            "val loss: 0.2511004720415388\n",
            "val acc: 0.44419642857142855\n",
            "\n",
            "Epoch[27] loss: 0.22564629152897867 LR: [2]\n",
            "val loss: 0.25087687373161316\n",
            "val acc: 0.4497767857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[28] loss: 0.22952358520800067 LR: [2]\n",
            "val loss: 0.25415987840720583\n",
            "val acc: 0.4453125\n",
            "\n",
            "Epoch[29] loss: 0.222500630444096 LR: [2]\n",
            "val loss: 0.26521363854408264\n",
            "val acc: 0.40401785714285715\n",
            "\n",
            "Epoch[30] loss: 0.22047014630609943 LR: [2]\n",
            "val loss: 0.24551006087235042\n",
            "val acc: 0.4486607142857143\n",
            "\n",
            "Epoch[31] loss: 0.21575641391738767 LR: [2]\n",
            "val loss: 0.23128723672458104\n",
            "val acc: 0.5111607142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[32] loss: 0.21028201618502218 LR: [2]\n",
            "val loss: 0.2294355652162007\n",
            "val acc: 0.4955357142857143\n",
            "\n",
            "Epoch[33] loss: 0.21184808015823364 LR: [2]\n",
            "val loss: 0.2604758398873465\n",
            "val acc: 0.45089285714285715\n",
            "\n",
            "Epoch[34] loss: 0.20633848732517612 LR: [2]\n",
            "val loss: 0.21404199302196503\n",
            "val acc: 0.5435267857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[35] loss: 0.20109870885649034 LR: [2]\n",
            "val loss: 0.29177558422088623\n",
            "val acc: 0.39285714285714285\n",
            "\n",
            "Epoch[36] loss: 0.20062795714024576 LR: [2]\n",
            "val loss: 0.22850273336683\n",
            "val acc: 0.5256696428571429\n",
            "\n",
            "Epoch[37] loss: 0.19731273285804257 LR: [2]\n",
            "val loss: 0.23294740489551\n",
            "val acc: 0.5167410714285714\n",
            "\n",
            "Epoch[38] loss: 0.19539880416085642 LR: [2]\n",
            "val loss: 0.21312681691987173\n",
            "val acc: 0.5390625\n",
            "\n",
            "Epoch[39] loss: 0.18963228550649458 LR: [2]\n",
            "val loss: 0.22363443672657013\n",
            "val acc: 0.5167410714285714\n",
            "\n",
            "Epoch[40] loss: 0.18313154434004136 LR: [2]\n",
            "val loss: 0.2455441185406276\n",
            "val acc: 0.5234375\n",
            "\n",
            "Epoch[41] loss: 0.1802533196826135 LR: [2]\n",
            "val loss: 0.2104941883257457\n",
            "val acc: 0.5591517857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[42] loss: 0.18156114076414415 LR: [2]\n",
            "val loss: 0.21286151451723917\n",
            "val acc: 0.5625\n",
            "Best model updated\n",
            "\n",
            "Epoch[43] loss: 0.1763532325144737 LR: [2]\n",
            "val loss: 0.22014265188149043\n",
            "val acc: 0.5535714285714286\n",
            "\n",
            "Epoch[44] loss: 0.16924802766692254 LR: [2]\n",
            "val loss: 0.21319121760981424\n",
            "val acc: 0.5691964285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[45] loss: 0.16459226608276367 LR: [2]\n",
            "val loss: 0.21735846996307373\n",
            "val acc: 0.5513392857142857\n",
            "\n",
            "Epoch[46] loss: 0.17010024622563394 LR: [2]\n",
            "val loss: 0.19399702974728175\n",
            "val acc: 0.5904017857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[47] loss: 0.16052431396899686 LR: [2]\n",
            "val loss: 0.19221928077084677\n",
            "val acc: 0.6015625\n",
            "Best model updated\n",
            "\n",
            "Epoch[48] loss: 0.1569661139961212 LR: [2]\n",
            "val loss: 0.19486416663442338\n",
            "val acc: 0.6194196428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[49] loss: 0.14155164625375502 LR: [0.4]\n",
            "val loss: 0.15829165492738997\n",
            "val acc: 0.6863839285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.1300666007784105 LR: [0.4]\n",
            "val loss: 0.15209846837180002\n",
            "val acc: 0.703125\n",
            "Best model updated\n",
            "\n",
            "Epoch[51] loss: 0.12871673895466712 LR: [0.4]\n",
            "val loss: 0.15306105784007482\n",
            "val acc: 0.6941964285714286\n",
            "\n",
            "Epoch[52] loss: 0.12521432219974457 LR: [0.4]\n",
            "val loss: 0.15342490481478827\n",
            "val acc: 0.6886160714285714\n",
            "\n",
            "Epoch[53] loss: 0.12039279745471093 LR: [0.4]\n",
            "val loss: 0.15139836072921753\n",
            "val acc: 0.7020089285714286\n",
            "\n",
            "Epoch[54] loss: 0.12097218536561535 LR: [0.4]\n",
            "val loss: 0.16206759001527513\n",
            "val acc: 0.6763392857142857\n",
            "\n",
            "Epoch[55] loss: 0.11782545356019851 LR: [0.4]\n",
            "val loss: 0.16187311389616557\n",
            "val acc: 0.6886160714285714\n",
            "\n",
            "Epoch[56] loss: 0.11459489046565947 LR: [0.4]\n",
            "val loss: 0.1540157518216542\n",
            "val acc: 0.6930803571428571\n",
            "\n",
            "Epoch[57] loss: 0.11402558967951805 LR: [0.4]\n",
            "val loss: 0.17041783673422678\n",
            "val acc: 0.6785714285714286\n",
            "\n",
            "Epoch[58] loss: 0.11202958610750013 LR: [0.4]\n",
            "val loss: 0.15390804622854506\n",
            "val acc: 0.6841517857142857\n",
            "\n",
            "Epoch[59] loss: 0.10997300426806172 LR: [0.4]\n",
            "val loss: 0.15036867346082414\n",
            "val acc: 0.6941964285714286\n",
            "\n",
            "Epoch[60] loss: 0.10789447758466966 LR: [0.4]\n",
            "val loss: 0.16091563871928624\n",
            "val acc: 0.7131696428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[61] loss: 0.10788304190481862 LR: [0.4]\n",
            "val loss: 0.163287843976702\n",
            "val acc: 0.6752232142857143\n",
            "\n",
            "Epoch[62] loss: 0.1047133154446079 LR: [0.4]\n",
            "val loss: 0.16055599812950408\n",
            "val acc: 0.6752232142857143\n",
            "\n",
            "Epoch[63] loss: 0.09689194636960183 LR: [0.08000000000000002]\n",
            "val loss: 0.15084700286388397\n",
            "val acc: 0.7176339285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[64] loss: 0.09446008551505304 LR: [0.08000000000000002]\n",
            "val loss: 0.14460918733051845\n",
            "val acc: 0.7098214285714286\n",
            "\n",
            "Epoch[65] loss: 0.09125476835235473 LR: [0.08000000000000002]\n",
            "val loss: 0.145234220794269\n",
            "val acc: 0.7120535714285714\n",
            "\n",
            "Epoch[66] loss: 0.09280608858793013 LR: [0.08000000000000002]\n",
            "val loss: 0.14538205095699855\n",
            "val acc: 0.7087053571428571\n",
            "\n",
            "Epoch[67] loss: 0.09117283984538048 LR: [0.08000000000000002]\n",
            "val loss: 0.14638367188828333\n",
            "val acc: 0.7232142857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[68] loss: 0.09012633634190406 LR: [0.08000000000000002]\n",
            "val loss: 0.14528923162392207\n",
            "val acc: 0.7232142857142857\n",
            "\n",
            "Epoch[69] loss: 0.08999756795744743 LR: [0.08000000000000002]\n",
            "val loss: 0.15307978647095816\n",
            "val acc: 0.7276785714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[70] loss: 0.08894938350685182 LR: [0.08000000000000002]\n",
            "val loss: 0.14683957078627177\n",
            "val acc: 0.7120535714285714\n",
            "\n",
            "Epoch[71] loss: 0.08711841173710362 LR: [0.08000000000000002]\n",
            "val loss: 0.1437119288103921\n",
            "val acc: 0.7165178571428571\n",
            "\n",
            "Epoch[72] loss: 0.08755352011611385 LR: [0.08000000000000002]\n",
            "val loss: 0.15165275228875025\n",
            "val acc: 0.7176339285714286\n",
            "\n",
            "Epoch[73] loss: 0.08776969558769657 LR: [0.08000000000000002]\n",
            "val loss: 0.15532563413892472\n",
            "val acc: 0.703125\n",
            "\n",
            "Epoch[74] loss: 0.08642017588980737 LR: [0.08000000000000002]\n",
            "val loss: 0.14686707832983562\n",
            "val acc: 0.7287946428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[75] loss: 0.08627490867530146 LR: [0.08000000000000002]\n",
            "val loss: 0.1476867294737271\n",
            "val acc: 0.7332589285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[76] loss: 0.0858528301600487 LR: [0.08000000000000002]\n",
            "val loss: 0.14876848884991237\n",
            "val acc: 0.7209821428571429\n",
            "\n",
            "Epoch[77] loss: 0.0860916308818325 LR: [0.08000000000000002]\n",
            "val loss: 0.15493224667651312\n",
            "val acc: 0.7120535714285714\n",
            "\n",
            "Epoch[78] loss: 0.08268032054747304 LR: [0.08000000000000002]\n",
            "val loss: 0.1491036287375859\n",
            "val acc: 0.7209821428571429\n",
            "\n",
            "Epoch[79] loss: 0.08287313268069298 LR: [0.08000000000000002]\n",
            "val loss: 0.14890060680253164\n",
            "val acc: 0.7399553571428571\n",
            "Best model updated\n",
            "\n",
            "Finished!\n",
            "Best model at epoch 79, best accuracy: 0.74\n",
            "\n",
            "Test accuracy: 0.7421875\n",
            "Testing classes seen so far, accuracy: 0.7421875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy2O60X8BBYT",
        "outputId": "2e5b8072-88c3-429a-99eb-fc5a0eb26c28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.07832532051282051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.07832532051282051,\n",
              " tensor([34, 26, 20,  ..., 26, 13, 67], device='cuda:0'),\n",
              " tensor([5, 4, 2,  ..., 6, 2, 4], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}