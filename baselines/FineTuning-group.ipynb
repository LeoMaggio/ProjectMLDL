{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "396e4a872e054e4b8033c9b177667a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e9dd3aa38f24874b9f9a7cb2fcf52e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_655f4cc8530b42458baf1a83ecb3dcc8",
              "IPY_MODEL_31cb86cf25934a299f02471fdd9a4825"
            ]
          }
        },
        "2e9dd3aa38f24874b9f9a7cb2fcf52e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "655f4cc8530b42458baf1a83ecb3dcc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d63272be68f24fd7b94876264b6371a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c80c36093f824c7796ef5d2b9195fc76"
          }
        },
        "31cb86cf25934a299f02471fdd9a4825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b792e2e289ce4706a3f8dfd6bdedb21c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:19&lt;00:00, 54339485.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6649a8e1d28495791939d6a40982907"
          }
        },
        "d63272be68f24fd7b94876264b6371a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c80c36093f824c7796ef5d2b9195fc76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b792e2e289ce4706a3f8dfd6bdedb21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6649a8e1d28495791939d6a40982907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosminnedescu/ProjectMLDL/blob/main/baselines/FineTuning-group.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJimWkPdQu6y"
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blqZpJkQgn5c",
        "outputId": "b8c3f81f-29ee-448c-c331-e9bae5e73791"
      },
      "source": [
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJRs-JrVsd8j",
        "outputId": "3cd0e688-fb57-41a1-f4e0-1dda2b1cfb3d"
      },
      "source": [
        "%cd content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Wvze6xh3-9"
      },
      "source": [
        "!rm -rf ProjectMLDL"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQQd0qWVgue_",
        "outputId": "931244e3-db98-4be1-b6e5-f2c84506f5cc"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjntw1jZQ7Lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dab5cc-a06a-4668-8cb9-46d839b75923"
      },
      "source": [
        "if not os.path.isdir('/content/ProjectMLDL'):\n",
        "  !git clone https://github.com/cosminnedescu/ProjectMLDL.git\n",
        "  %cd /content/ProjectMLDL\n",
        "  !rm -rf LICENSE README.md"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ProjectMLDL'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 78 (delta 23), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (78/78), done.\n",
            "/content/ProjectMLDL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvkF4W62dSp8"
      },
      "source": [
        "from data.cifar100 import CIFAR100\n",
        "from model.resnet32 import resnet32\n",
        "import data.utils\n",
        "from model.trainer import Trainer\n",
        "from copy import copy"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwomFTtQo1x-"
      },
      "source": [
        "# True mean and std of Cifar100 dataset (src=\"https://gist.github.com/weiaicunzai/e623931921efefd4c331622c344d8151\")\n",
        "mean = [0.5071, 0.4867, 0.4408]\n",
        "std = [0.2675, 0.2565, 0.2761]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), \n",
        "     transforms.Normalize(mean, std),\n",
        "     ])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "396e4a872e054e4b8033c9b177667a58",
            "2e9dd3aa38f24874b9f9a7cb2fcf52e4",
            "655f4cc8530b42458baf1a83ecb3dcc8",
            "31cb86cf25934a299f02471fdd9a4825",
            "d63272be68f24fd7b94876264b6371a0",
            "c80c36093f824c7796ef5d2b9195fc76",
            "b792e2e289ce4706a3f8dfd6bdedb21c",
            "f6649a8e1d28495791939d6a40982907"
          ]
        },
        "id": "BCz7GGfdpRiL",
        "outputId": "33adbd2c-aec0-4116-8871-3883f0f9a5de"
      },
      "source": [
        "train_data = CIFAR100(\"dataset\", train=True, transform=train_transform, download=True)\n",
        "test_data = CIFAR100(\"dataset\", train=False, transform=test_transform, download=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to dataset/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "396e4a872e054e4b8033c9b177667a58",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting dataset/cifar-100-python.tar.gz to dataset\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "cGlVf385aUDd",
        "outputId": "e820d5a5-682a-4988-eac5-011f17ad47e3"
      },
      "source": [
        "#check images and labels after shuffle\n",
        "#https://github.com/keras-team/keras/issues/2653#issuecomment-450133996\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_data.data[6])\n",
        "print(\"classe: {}\".format(train_data.targets[6]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classe: 90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfQUlEQVR4nO2dWWxc55Xn/6cWFilSIkVqtRZrtWWNLckKrbZjO3HSceL2pNv2LEb8EPghaDUGHWAC9DwYGWCSAeYhPZgkyMMgA2VitNNIZ5nOYqfHSXtJbI/diWxa1mYttixRC0WRkiiS4lKs7cxDladlz/f/SJFiUcn9/wBBxe/Ud++5t+6pW/X965xj7g4hxB8+qbl2QAhRHxTsQiQEBbsQCUHBLkRCULALkRAU7EIkhMxMJpvZAwC+BSAN4H+6+9eiO8tmPdeQY9ui8661PJhKpyNG7gfDIv6VS+Wr3t5MMOZ/5LC8XIltcZqOkH1FXsrUNM59dZuRjdZRWfbIzhoam6gtkwnfcwuFfGxnQfLjeRQmCsETOe1gN7M0gP8O4H4AZwC8YWbPuPshNifXkMOmW7cEbQ0p7kqpWAyOV5xfHBa5SOe1t1IbcllqSpEznC7zgB7sv8i3F3mDiwZnJCgaGsNvpqkMD+jx4XFqS8UukUiQWSb8hlqq8HPVkAv7Xt0gP+YKuT5qO+Q2uiu+r7Lz7VVQoLbVN91Kbe1L5wfHu08cpXNS5Ny//tLrfA61TM4OAMfc/bi7FwD8EMBDM9ieEGIWmUmwrwBw+oq/z9TGhBDXITP6zj4VzGwngJ0A0NDQMNu7E0IQZnJn7wGw6oq/V9bGPoC773L3TnfvzGT492EhxOwyk2B/A8BGM1trZg0APgfgmWvjlhDiWjPtj/HuXjKzLwL4R1Sltyfd/e3YHDNDNhu+uzdm+Uf8sVIpbMhw93MRqaOhsZHalqxYzv0YHg6OD5ztpXNSMeknqjRFlIYUf49mX5UaW/lKd36CnF8AyPPV51TED+ZjOiZAxFbBI4pHJSIdMg9j+4rZYlJehlzbAJCJXKvMFpPyKpWr1xRn9J3d3Z8F8OxMtiGEqA/6BZ0QCUHBLkRCULALkRAU7EIkBAW7EAlh1n9B9/9RDksGmSbuSioVlpPKmUiWUTOXmkoFnrDQ3NxMbYMXLgTH0xEJKpZhV0YkSSMmUUVUF5aBl0rz85smmYgAUI5kXkXykFAhcmlMMCpX+OuCmNRU4efRiYw2/UzKSPJPJEEptr9SIZzIUxzlCT4VYqqQ+AJ0ZxciMSjYhUgICnYhEoKCXYiEoGAXIiHUdTW+UnEUJsLLiN7MVxGzuXDiSq6ZJx40NvBkFzee+BErZ9VEEmispYXOGRsdpbZMJPmHJQwBQCFS2slJOahKpDxTbAW3EisHFSnRxBKAYkrCdMvdxRJyKmSlPjonsnKeJecXAFIZfgDpFJ9XKYZ9jK3Gm5HQjdX44yYhxB8SCnYhEoKCXYiEoGAXIiEo2IVICAp2IRJCXaW3lvkt+Og9dwdtI8O8c8rZ/oHgeKwTyMIG/j42muKyXEx6Y62cypFEjHQkASXWqyQVkXjmt4Q7iAAAiByWiRyXF7kUmbKYRBU5gmnkmcSSRWK2dKydV6yeHNte5Jhj9f8yWf5ax6TUcinS0Yb5MQ2dUnd2IRKCgl2IhKBgFyIhKNiFSAgKdiESgoJdiIQwI+nNzLoBXAZQBlBy987Y89va2vCn//pfBW35y+H6bgBw+tz54Pixt/bQOeUJLuWNDPJaZ7E2Q0zsaEhH5Kkyl7UqzueNDF2mtsworwvX0dEeHG+INNVMR4rJZRv5JVKYiGTSReRIOicir0VbTUXbNYW3Ga0XF9ENy5GMw1QpJoddvS12LdLaehHfr4XO/gl355EqhLgu0Md4IRLCTIPdATxnZm+a2c5r4ZAQYnaY6cf4e9y9x8yWAHjezI64+ytXPqH2JrATAJYsXTrD3QkhpsuM7uzu3lP7vx/AzwDsCDxnl7t3untna2vbTHYnhJgB0w52M2s2s/nvPwbwaQAHr5VjQohry0w+xi8F8LOa7JEB8Hfu/qvYhNGxEezuei1oW9jGM7nW3XRzcHzrpk10zuDFHmp769AxarsYKfI33hCWr1LOT+PEgnnUVmZFA8Ez7ABEM8qam8IZfa2LOuic0Ug7rLHxcMYhAGQiUlOpSGyRipOxRLmGeTxTsYkUJAV4wc9imb/OmQaeRReT+YoRKbIYez1JL6fYvtKkuGVMhZx2sLv7cQBbpztfCFFfJL0JkRAU7EIkBAW7EAlBwS5EQlCwC5EQ6lpwEnCkPZyxNXh+jM767cVw1tuihSvpnG233Uptf7r+Nmo7cqKb2o61h3u6jV04R+cUI4Uvi5HMsEwkS61S5ttkWW/ZJi4B5pqbqa1QnOC2Es/MyzXlguP5iMwXSURDMVJcNEd68AFAS3v4h1zFAj8uM/66jER693klIsuVePZjaSIcE6lp9NmLJA7qzi5EUlCwC5EQFOxCJAQFuxAJQcEuREKo62q8l4qYGOgL2hrmL6LzFraEV5JPnThO5wxcCK/gA8D69WupbdmKVdT2yJ89FBw/39NN57z06svUdvz4u9SWy/GXZmQ4skKeHw6Ol4vhcQBoSvOadtmFTdRWHOUKSsuC1uD4KFFWACAVqdMWa/E0Psb9yEyE56Uy/D7X3MKPORXxY3hghNryeX6O86PhebFWU9HWWwTd2YVICAp2IRKCgl2IhKBgFyIhKNiFSAgKdiESQl2lt1waWB9WZPBe/xk6L58PJ3csXLiQzkmVuRxz6O291Haql7eNuveObcHxVWvX0TmPrVxNbcfeOUxtb+z/J2rrPvEOtVV8PDjeMY8nwpTGhqhtpMTvB/PbuAyVHw0nyViJS0YxWcsqPMOjFGmTVMwTmTJym3Pn22toaKC2+S3hRCkAyEaO7fJEODkobdzJWMILQ3d2IRKCgl2IhKBgFyIhKNiFSAgKdiESgoJdiIQwqfRmZk8C+CyAfne/tTbWDuBHANYA6AbwqLtfmmxbpUoFl0bCNbzWLltA572x/2hwvG+cyxlbtvMadK1NXD7J5/lhPPfy88HxNau49Pbxu++lts986l9S27ZO3myna08Xte17a09wfPDcaTpn8BLPyJrwSGulcV4XrjAeltjSMcmozGW5ckR6ixWvyzaGa+HF2iSVIvXuxiIZdqjw67G5g3cwntcUzrIbHuOZijC+L8ZU7ux/A+CBD409AeBFd98I4MXa30KI65hJg73Wb/3D3f0eAvBU7fFTAB6+xn4JIa4x0/3OvtTde2uPz6Ha0VUIcR0z4wU6d3dEuu2a2U4z6zKzrtFR/t1QCDG7TDfY+8xsOQDU/u9nT3T3Xe7e6e6dzc18sUcIMbtMN9ifAfB47fHjAJ6+Nu4IIWaLqUhvPwBwH4BFZnYGwFcAfA3Aj83sCwBOAnh0SjvLptGxIiyxnT/LZYYWC2dyXRwLjwPAvq791HbXHbdT2+LF86ltpBSWZHrP9dA5f/t336O2T33ik9T2ka1bqO3BT/wZtd22MXxsL/3mV3TOwCXekqn7NC8QOUbkNQBIO9G2IpqXx1K5IraoKpcJS1QZMj7ZvlKRIpDFIs+Wm842LVKAM5MNtwezyPmdNNjd/TFi+uPJ5gohrh/0CzohEoKCXYiEoGAXIiEo2IVICAp2IRJCXQtOpjNpLGgPS29e5pLB8XfDxSgbU7wnV/kyLxzZ9fob1HbnfVxkWLqkLTieM76vY6cHqe3pF56jtt7z9HdK+KNt4cKXALCwLVyE8/77eYbdunWbqO2fdvNz9fqbPPvufG/Y/3RUuipRWxwua5VLRA6L9EpLRaLCKxG5Mc2PLZXm13epFD5uj8ho7FzF1Evd2YVICAp2IRKCgl2IhKBgFyIhKNiFSAgKdiESQl2lt3x+Au8cfS9oa1+0mM6b1x7uU3a2j/coa2vihzY6zotonDjTR20pkii1pJlnUK1fwvvRnRoifcgAvPq731HbCCnaCQDbbwtnyy1ZFO6XBwAfveseatu8mRfu3HI7L4q57823guMH9x+gc86c4dmDhQIvAhm9Y1XC0lu0VRrJKKua+HVVLvCst4kCz9AsFMLXgbPMQQAVItdFs+uoRQjxB4WCXYiEoGAXIiEo2IVICAp2IRJCXVfjJyaKePdEeLV7bZq7smlLuL3SyMhxOmfsAl+pX5Dj7Z9yxlfIDx46HBxfvbiVzrlt043UlknxVkJvj364L8c/c+ESb1H1+sFw7b0FC3htvY9v30FtyxYvorb7P3YftXVuCSfrHDkSbuUFAC/8+gVq69oTbmsFAOOjXJ0ok4QRlnwCxOvMRbpGoWI8SWZsnL/WhUK4BmAlltUyDXRnFyIhKNiFSAgKdiESgoJdiISgYBciISjYhUgIU2n/9CSAzwLod/dba2NfBfDnAN7vDfRld3920r2lDBUie53s4UkQW7beFhx/5NGwJAcAr7/wGrV1H+c149rn81OSKYcTHXZ3hZM+AKB5QTiJBwBu33gTtQ0OXaY2S3EB6NxA+Ni63tpH5wyc51Lex++9i9o2rFpNbR3t4cSbu+/+KJ2z6bZbqO2V116htud/yVtbdb8XlmfHxrhMVonUmQO5BoB4+6qU8ftqhWyzHNkXba8VYSp39r8B8EBg/Jvuvq32b/JAF0LMKZMGu7u/AoD/wkMI8XvBTL6zf9HM9pvZk2bGk7aFENcF0w32bwNYD2AbgF4AX2dPNLOdZtZlZl3j47w1sBBidplWsLt7n7uX3b0C4DsA6I+r3X2Xu3e6e2dTE/9NuhBidplWsJvZ8iv+fATAwWvjjhBitrCYXAAAZvYDAPcBWASgD8BXan9vQ7WUVzeAv3D33sl2tnhpmz/y2MeCtuIYrwt389qO4PiDn/4TOqch8o3h5V//ltp6Sy3UtqwpXAdt355DfHvjvD7dv304JHJUWTyfZ6mdHuAZVOcmwgd+6vQ5OidWkW3p8hXUdu+dXEbbcevm4HhTpDagsSJ/QLS22pGj71Dbz3/+8+D4vr176ZxLA1yKHB3jteQqETksneWfakv5cKZlucwlQNYZ6sjhgxgdHQlaJ9XZ3f2xwPB3J5snhLi+0C/ohEgICnYhEoKCXYiEoGAXIiEo2IVICJNKb9eS9o4F/qkH7wjaSnn+vrO0PSx5feKe7XTOpx8IiQhVhi7xAoXPvsyzw3rf7gqOzyvzDLXufi6TDZa5HPPAZz5JbUsX81ZZx8+EFdC+Ua5Fnh/k/iOVo6bGLLdtvTWcqXjvXeHXHwBWLlpAbSNjvP1ThelQACby4fO/dw/PVPztazxjcs9bXLIbiGQq5hr4a50n7bwqsdAkh3z40AEqvenOLkRCULALkRAU7EIkBAW7EAlBwS5EQlCwC5EQ6trrLZs13HBDeJfjo5ECeoWwBvH2wQN0yo3ruCy3edunqG3DRp7V1HckLLsUx/mctcuaqW3POxeo7en//SK1PfLwZ/n+Voez1DJnzwfHASA/xmW5Uo7733eGFwndvTecsdU/yCW0ezo3UdvKJbznnDsvzNjWGs4evPvuu+mcTTfxQqBbt3Hp7cWXeFHM944do7a8ha+fTKSwaDobjiOLyJC6swuREBTsQiQEBbsQCUHBLkRCULALkRDquhqfShuaW7JBW1OO/+q/72T4Pelsb7h2FwDseYvXmWtdxNtGLV/Ga651/tGdwfGul35B5wyMjlDb6sV8pfvcEF9hPnSQ17y75fZ/Ed7XSn5cE6MlartY4au7Aw388sllw6/ZoWPv0TmDI0PU9pHNG6it8za+ep5ltd/S/Hprmc8Tcnbs4Ik8q1avorYXXuBNk958Lay8lMrhWAGAkUK4Xp9W44UQCnYhkoKCXYiEoGAXIiEo2IVICAp2IRLCpNKbma0C8D0AS1HtE7TL3b9lZu0AfgRgDaotoB51d943B0DFHePFcIKE5Xirm2I6LA2ly9z90z2nqe31t16itk2beZLMmps3Bsd7ji2jc/Yd4FJTLsXln62kfRIALLppG7W98I+/Dm9ve7gmHACsX8Mlo9aLPIFmZJhLVJmWtuB4YfgsnTMWSYZ6aTev7zY8zs/jR25ZHhw/fpjXoHuji0ubw0PD1LZ2fTu1bdywmtqOH2kMjo9G6u6VhsLXfiR3Zkp39hKAv3L3zQDuBPCXZrYZwBMAXnT3jQBerP0thLhOmTTY3b3X3ffUHl8GcBjACgAPAXiq9rSnADw8W04KIWbOVX1nN7M1AG4HsBvA0is6t55D9WO+EOI6ZcrBbmYtAH4C4Evu/oEvLl4tPh/84mRmO82sy8y6xiNFEoQQs8uUgt3MsqgG+vfd/ae14T4zW16zLwfQH5rr7rvcvdPdO5vm8UL5QojZZdJgt+ov678L4LC7f+MK0zMAHq89fhzA09fePSHEtWIqWW93A/g8gANm9n4Bri8D+BqAH5vZFwCcBPDoZBtKpRxNTWE5odQyj85rWRR2c16eSxNe4rae093UdmnkZWrbuiEssd20icsqPecuUtv4BJcbc0u5HLbqZi69VX7xy+D4L599js6578HPUNvWm8JZdABww9Db1FawsBzWnwvLTADQkOHnY3Sc286c55mFxdFwy67dL/6czjl8mNfWq0SyAE+e5hLgltt4zbtL403B8bHY9V0My9Gxdm6TBru7vwraWQp/PNl8IcT1gX5BJ0RCULALkRAU7EIkBAW7EAlBwS5EQqhrwUkvAyWS2VSISCvFYlhOKDXw96obWrmUlx/mbZdOnh2jtjXzw360pPgvA1tbuY8+Hm5NBAD5iMQzeuEUta1bHS5iaRf4D5pGLvKMsj1Hj1Nba/sSals4Hj4n7amwzAQAuQb+ml0a4y22GlN5ahsbHAyOnz49QOekypGijRYu9AgAA+e57DVymftfLoT3d7GPS28NpBZlJSK96c4uREJQsAuREBTsQiQEBbsQCUHBLkRCULALkRDqKr2VikDf2bA0kC9xyQvpsCw3r5X3wmrM8PexdKQq34JI9t3KheECixlwCe2euzqo7d2zPFvrTB+v3Xmh5yi1LV0S9jHVzCWvHXfdRW3vdndT2+nePmrbuCHcf21ZRGJtoPlWQLE9XMASALKNXG7ysXDPvGKB+xGr2hhpb4fRcd4zrxzJcMwS973C55hd/X1ad3YhEoKCXYiEoGAXIiEo2IVICAp2IRJCfRNhHCiTVdDCaHjVFADSFraNR5ISepwnd3S08TpozU3hxAkAGBsLJ9CsWL2GzlkAvro/UuCJDhORVeuWRp54M6+9NTh++hxP/jl06Ai1bdrK21AVj/AadKdOnQiOt7TyVlntRZ7Qsi7DE3kyzfw6GCRtkioVPmdhWziZCAAWtnLb0eO85Vgqxe+rC5rCPjZn+ZzCNGrQ6c4uREJQsAuREBTsQiQEBbsQCUHBLkRCULALkRAmld7MbBWA76HaktkB7HL3b5nZVwH8OYDztad+2d2fjW0rnQbawsoQPFJzrVwKvycNX+ZyXSUiXRUibXUWrONJLae6D4a3V+Qtnqyco7bBQe7H7bfcSm1NmfPUduBQ2JcT3byl0Ynj3JayCWrbsr2T2vYfPhYcP9vXGxwHgI6N66jNh7iUiois2FwJS1TrFy/kcxq4zNfWwmXblpVcVlw1j0t95Wz4OpgfSeYqIby9tPE4morOXgLwV+6+x8zmA3jTzJ6v2b7p7v9tCtsQQswxU+n11gugt/b4spkdBrBith0TQlxbruo7u5mtAXA7gN21oS+a2X4ze9LM+OciIcScM+VgN7MWAD8B8CV3HwbwbQDrAWxD9c7/dTJvp5l1mVnXOKklLoSYfaYU7GaWRTXQv+/uPwUAd+9z97K7VwB8B8CO0Fx33+Xune7e2dTEFz6EELPLpMFuZgbguwAOu/s3rhhffsXTHgEQXqoWQlwXTGU1/m4AnwdwwMz21sa+DOAxM9uGqhzXDeAvJttQyoB55OZuRJIDgCGSEVcu8wyffIFLHQXj9dj6h7gctrCJ1DM7cYbOGRzk8mCxxDPi2uZxW24pr3VWnAjX8rs0yNsdVUr8XO199TVqmzef14W7a8f24Pirr+0OjgPAO8fCch0ALL9xA7UtrvDXc17+bHD8wTu20DntHbytVa6ZS2/5Er928s7rDd6wLNwayif4nJN94esqUj5vSqvxrwLBSoBRTV0IcX2hX9AJkRAU7EIkBAW7EAlBwS5EQlCwC5EQ6lpwMgWgkUgDuZZIho+HJ5lx9y8P8qy3waGw1AEAly7yLK/lHeH9LWnlc5DmstDSG3iGXTrNf204MMylt9Vrw7LRnZt5q6a97wxRW98F3obqN7/6BbUVRsL+p0r8uHrf3UdtuWYu863cxmW0G3OrguOZCr8Gbtm2ldpQ4ddp96luauu70E9t53rCkuO9OxbTOYuPDgfH9xzmMqru7EIkBAW7EAlBwS5EQlCwC5EQFOxCJAQFuxAJoa7SW8Ud+WI4W8cqPIMtmw276ZH3qlwTl94mRqkJLU1cDkMl7PtApPBlWyv3o6MjS21jpXD2GgDctPFmamtpDZ+r/pOn6JyRUS5D7T/BbUMDYfkHAPb/9h+C46kyl4bOnOVFJdNpngW4sJ2/ZsXmcMHPEskOBICJxogkGino+Pb+Lmo7GcnoG+wOvzaLmviFumlDOE20sZHHhO7sQiQEBbsQCUHBLkRCULALkRAU7EIkBAW7EAmhrtJbseQ43R/OEGtbwGWopsawbSxShr4hx9/H5md50cB1N0R6XXg42+zcRZ4Zlsvx8tkZ43LjSJFn0g2Pc8mrfeX64PgtH9nG91U4QG2XR/lJ7j7Hs+/KpPbi8g4uU/YOcFnrxJHD1JaJnOPdJNtsZJjLWrd0hotlAsCipbwY5dHdr1LbwJlw4UsA6GgKX49jGV7Acmg0nKk4OsbPr+7sQiQEBbsQCUHBLkRCULALkRAU7EIkhElX482sEcArAHK15/+9u3/FzNYC+CGADgBvAvi8u0fbtFbcMFEI73LoMl+ZXtgUXo0fmuAr1tksXyle0MYPe0EbX6kvTYRXRxeWmumcTJqrDMUCP103b76V2tpvCK+4A0BDYzhBYjlJnACADecvUtv5s9w2mucr2mP58PmvGF85v+OmBdT2f45wBeLku+9QW4F0Di6V+Kr18aN8e6ND/JiHLnFbJZLoVSyEbakSv3YGJ8Jzyvyyn9KdfQLAJ919K6rtmR8wszsB/DWAb7r7BgCXAHxhCtsSQswRkwa7V3m/w1y29s8BfBLA39fGnwLw8Kx4KIS4Jky1P3u61sG1H8DzAN4DMOj+/35lcgbAitlxUQhxLZhSsLt72d23AVgJYAeATVPdgZntNLMuM+uaIN95hRCzz1Wtxrv7IIDfALgLQJv9c5eGlQB6yJxd7t7p7p25HF9wEELMLpMGu5ktNrO22uMmAPcDOIxq0P+b2tMeB/D0bDkphJg5U0mEWQ7gKTNLo/rm8GN3/wczOwTgh2b2XwC8BeC7k23IK44CkRnyIzwJYqwl/PG/kas4qERqhY2WuWR38gKXmjwf3mYlonec6+etlZrC5dEAADfP5wk5BW+htgs94TZPTQu4PDivlctyHYu4FLkmIpdmyYe4Fct5Lbll8/j2Uhn+ev7uEK9dVyZ1Ay3F93Wx5wy1jfXxNk7FCr8OWiKRNgFWl5HX62tIMemQH9ekwe7u+wHcHhg/jur3dyHE7wH6BZ0QCUHBLkRCULALkRAU7EIkBAW7EAnB3PlS/TXfmdl5ACdrfy4CcKFuO+fIjw8iPz7I75sfN7r74pChrsH+gR2bdbl755zsXH7IjwT6oY/xQiQEBbsQCWEug33XHO77SuTHB5EfH+QPxo85+84uhKgv+hgvREKYk2A3swfM7KiZHTOzJ+bCh5of3WZ2wMz2mllXHff7pJn1m9nBK8bazex5M3u39n+kD9Ws+vFVM+upnZO9ZvZgHfxYZWa/MbNDZva2mf372nhdz0nEj7qeEzNrNLPXzWxfzY//XBtfa2a7a3HzI7NI9c4Q7l7XfwDSqJa1WgegAcA+AJvr7UfNl24Ai+Zgvx8DsB3AwSvG/iuAJ2qPnwDw13Pkx1cB/Ic6n4/lALbXHs8H8A6AzfU+JxE/6npOABiAltrjLIDdAO4E8GMAn6uN/w8A/+5qtjsXd/YdAI65+3Gvlp7+IYCH5sCPOcPdXwEw8KHhh1At3AnUqYAn8aPuuHuvu++pPb6ManGUFajzOYn4UVe8yjUv8joXwb4CwOkr/p7LYpUO4Dkze9PMds6RD++z1N17a4/PAVg6h7580cz21z7mz/rXiSsxszWo1k/YjTk8Jx/yA6jzOZmNIq9JX6C7x923A/gTAH9pZh+ba4eA6js7YiVHZpdvA1iPao+AXgBfr9eOzawFwE8AfMndP9AVop7nJOBH3c+Jz6DIK2Mugr0HwKor/qbFKmcbd++p/d8P4GeY28o7fWa2HABq//P6R7OIu/fVLrQKgO+gTufEzLKoBtj33f2nteG6n5OQH3N1Tmr7vuoir4y5CPY3AGysrSw2APgcgGfq7YSZNZvZ/PcfA/g0gIPxWbPKM6gW7gTmsIDn+8FV4xHU4ZyYmaFaw/Cwu3/jClNdzwnzo97nZNaKvNZrhfFDq40PorrS+R6A/zhHPqxDVQnYB+DtevoB4Aeofhwsovrd6wuo9sx7EcC7AF4A0D5HfvwtgAMA9qMabMvr4Mc9qH5E3w9gb+3fg/U+JxE/6npOAGxBtYjrflTfWP7TFdfs6wCOAfhfAHJXs139gk6IhJD0BTohEoOCXYiEoGAXIiEo2IVICAp2IRKCgl2IhKBgFyIhKNiFSAj/F1U5f8KjgXVLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmEo_9lnwyBk"
      },
      "source": [
        "RANDOM_SEED = [42,13,10]\n",
        "# Settings\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "NUM_CLASSES = 100       # Total number of classes\n",
        "\n",
        "VAL_SIZE = 0.1          # Proportion of validation set with respect to training set (between 0 and 1)\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 128        # Batch size\n",
        "LR = 2               # Initial learning rate\n",
        "                       \n",
        "MOMENTUM = 0.9          # Momentum for stochastic gradient descent (SGD)\n",
        "WEIGHT_DECAY = 1e-5     # Weight decay from iCaRL\n",
        "\n",
        "NUM_RUNS = 3            # Number of runs of every method\n",
        "                        # Note: this should be at least 3 to have a fair benchmark\n",
        "\n",
        "NUM_EPOCHS = 70         # Total number of training epochs\n",
        "MILESTONES = [49, 63]   # Step down policy from iCaRL (MultiStepLR)\n",
        "                        # Decrease the learning rate by gamma at each milestone\n",
        "GAMMA = 0.2             # Gamma factor from iCaRL"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mr8mBkBx7BV"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efcfUm_jEOVh"
      },
      "source": [
        "## Training Larocca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hNLpdJTWSR1"
      },
      "source": [
        "class FineTuning(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(FineTuning, self).__init__()\n",
        "    self.feature_extractor = resnet32()\n",
        "    self.n_classes = n_classes\n",
        "    self.n_known = 0\n",
        "    self.p = self.parameters()\n",
        "    self.fc = nn.Linear(10, n_classes, bias = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.feature_extractor(x)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def increment_classes(self, n):\n",
        "    in_features = self.feature_extractor.in_features\n",
        "    out_features = self.fc.out_features\n",
        "    weight = self.fc.weight.data\n",
        "    bias = self.fc.bias.data\n",
        "\n",
        "    self.fc = nn.Linear(in_features, out_features+n, bias=True)\n",
        "    self.fc.weight.data[:out_features] = weight\n",
        "    self.fc.bias.data[:out_features] = bias\n",
        "    self.n_classes += n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvbNmnd_WWH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "c2b2e021-debe-4b6d-c558-249ca444473b"
      },
      "source": [
        "train_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "test_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "\n",
        "best_acc = []\n",
        "tot_matrix = []\n",
        "tot_labe = []\n",
        "\n",
        "#net = FineTuning(10)\n",
        "net = resnet32()\n",
        "\n",
        "\n",
        "for run_i in range(len(RANDOM_SEED)):\n",
        "  random_state = RANDOM_SEED[run_i]\n",
        "  subset_train = []\n",
        "  subset_test = []\n",
        "\n",
        "  train_data.__shuffle_seed__(RANDOM_SEED[run_i])\n",
        "  test_data.__shuffle_seed__(RANDOM_SEED[run_i])\n",
        "\n",
        "  indexes_train_data = train_data.__incremental_indexes__(True)\n",
        "  indexes_test_data = test_data.__incremental_indexes__(False)\n",
        "\n",
        "  train_dataloader = []\n",
        "  test_dataloader = []\n",
        "\n",
        "  for i in range(10):\n",
        "    train_dataset = Subset(train_data, indexes_train_data[i])\n",
        "    subset_train.append(train_dataset) #[[train0],[train1],...]\n",
        "    train_dataloader=DataLoader(subset_train[i],\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True)\n",
        "    \n",
        "    test_dataset = Subset(test_data, indexes_test_data[i])\n",
        "    subset_test.append(test_dataset) #[[train0],[train1],...]\n",
        "    test_dataloader=DataLoader(subset_test[i],\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True)\n",
        "    net.cuda()\n",
        "    if(i!=0):\n",
        "      net.addOutputNodes(10)\n",
        "      \n",
        "    net.train()\n",
        "    \n",
        "    p = net.parameters()\n",
        "    optimizer = optim.SGD(p, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA)\n",
        "\n",
        "    matrix = []\n",
        "    labe = []    \n",
        "    b_ac = 0\n",
        "    #Training\n",
        "\n",
        "    for epoch in range(0, NUM_EPOCHS):\n",
        "      running_corrects = 0\n",
        "      total = 0\n",
        "\n",
        "      for indices, images, labels in train_dataloader:\n",
        "        images = Variable(images).cuda()\n",
        "        labels = Variable(labels).cuda()\n",
        "        indices = indices.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        g = net(images)\n",
        "        #print(g)\n",
        "        #g = net.forward(images)\n",
        "        _, preds = torch.max(g, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "\n",
        "        #Loss\n",
        "        g.cuda()\n",
        "        #print(\"Loss1 : {}\".format(loss))\n",
        "        loss = criterion(g, labels)\n",
        "        #print(\"Loss2 : {}\".format(loss))\n",
        "        loss.backward()\n",
        "        #print(\"Loss3 : {}\".format(loss))\n",
        "        optimizer.step()\n",
        "\n",
        "      accuracy = running_corrects / float(total)\n",
        "      scheduler.step()\n",
        "      print ('Epoch (%d/%d), Loss: %.4f, Accuracy: %.2f' %(epoch+1, NUM_EPOCHS, loss, accuracy))\n",
        "\n",
        "      #test\n",
        "      m = []\n",
        "      l = []\n",
        "      #net.train(False)\n",
        "      net.eval()  #per spegnere i layer di dropout\n",
        "      total = 0.0\n",
        "      running_corrects = 0\n",
        "      for indices, images, labels in test_dataloader:\n",
        "        images = Variable(images).cuda()\n",
        "        labels = Variable(labels).cuda()\n",
        "        indices = indices.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        g = net(images)\n",
        "        #g = net.forward(images)\n",
        "        _, preds = torch.max(g, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        m.extend(preds)\n",
        "        l.extend(labels)\n",
        "\n",
        "      matrix.append(m)\n",
        "      labe.append(l)\n",
        "\n",
        "      accuracy = float(running_corrects / float(total))\n",
        "      print('Test Accuracy', accuracy)\n",
        "\n",
        "      if(b_ac < accuracy):\n",
        "        b_ac = accuracy\n",
        "      \n",
        "  tot_matrix.append(matrix)\n",
        "  tot_labe.append(labe)\n",
        "  best_acc.append(b_ac)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch (1/70), Loss: 2.3369, Accuracy: 0.11\n",
            "Test Accuracy 0.007612179487179487\n",
            "Epoch (2/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.010016025641025642\n",
            "Epoch (3/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.010016025641025642\n",
            "Epoch (4/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.010016025641025642\n",
            "Epoch (5/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.009915865384615384\n",
            "Epoch (6/70), Loss: nan, Accuracy: 0.10\n",
            "Test Accuracy 0.010016025641025642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-cd76b8fac94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZOt-s7ZEVfC"
      },
      "source": [
        "## Training Montagna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hajNZJmbcui9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8154f817-3ce5-46ac-f459-b77f6f3633a6"
      },
      "source": [
        "train_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "val_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "test_dataloader = [[] for i in range(len(RANDOM_SEED))]\n",
        "\n",
        "\n",
        "for run_i in range(len(RANDOM_SEED)):\n",
        "  random_state = RANDOM_SEED[run_i]\n",
        "  \n",
        "\n",
        "  train_data.__shuffle_seed__(RANDOM_SEED[run_i])\n",
        "  test_data.__shuffle_seed__(RANDOM_SEED[run_i])\n",
        "  \n",
        "\n",
        "  indexes_train_data = train_data.__incremental_indexes__(True)\n",
        "  indexes_test_data = test_data.__incremental_indexes__(False)\n",
        "\n",
        "  for i in range(10):\n",
        "    train_dataset = Subset(train_data, indexes_train_data[i])\n",
        "    train_set, val_set = torch.utils.data.random_split(train_dataset, [int(0.8*len(indexes_train_data[i])), int(0.2*len(indexes_train_data[i]))])\n",
        "    #subset_train.append(train_set) #[[train0],[train1],...]\n",
        "    #subset_val.append(val_set) \n",
        "    train_dataloader[run_i].append(DataLoader(train_set,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True))\n",
        "    val_dataloader[run_i].append(DataLoader(val_set,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True))\n",
        "    \n",
        "    test_dataset = Subset(test_data, indexes_test_data[i])\n",
        "    #subset_test.append(test_dataset) #[[train0],[train1],...]\n",
        "    test_dataloader[run_i].append(DataLoader(test_dataset,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUYTSpVYfCMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "657ea9e7-4082-49b9-e5b0-28b396826041"
      },
      "source": [
        "from data.utils_plot import check_cifar100_dataloader\n",
        "check_cifar100_dataloader(val_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sea\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flMwPsCIbQIp"
      },
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdRGb-VIEY-e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b5d4cc3-ed34-4807-ecd4-850d15cc4499"
      },
      "source": [
        "logs = [[] for _ in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    net = resnet32()\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    for split_i in range(10):\n",
        "        print(f\"## Split {split_i} of run {run_i} ##\")\n",
        "\n",
        "        parameters_to_optimize = net.parameters()\n",
        "        optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA)\n",
        "\n",
        "        manager = Trainer(DEVICE, net, criterion, optimizer, scheduler,\n",
        "                          train_dataloader[run_i][split_i],\n",
        "                          val_dataloader[run_i][split_i],\n",
        "                          test_dataloader[run_i][split_i])\n",
        "\n",
        "        scores = manager.train(NUM_EPOCHS)  # train the model\n",
        "\n",
        "        logs[run_i].append({})\n",
        "\n",
        "        # score[i] = dictionary with key:epoch, value: score\n",
        "        logs[run_i][split_i]['train_loss'] = scores[0]\n",
        "        logs[run_i][split_i]['train_accuracy'] = scores[1]\n",
        "        logs[run_i][split_i]['val_loss'] = scores[2]\n",
        "        logs[run_i][split_i]['val_accuracy'] = scores[3]\n",
        "\n",
        "        # Test the model on classes seen until now\n",
        "        test_accuracy, all_targets, all_preds = manager.test()\n",
        "\n",
        "        logs[run_i][split_i]['test_accuracy'] = test_accuracy\n",
        "        logs[run_i][split_i]['conf_mat'] = confusion_matrix(all_targets.to('cpu'), all_preds.to('cpu'))\n",
        "\n",
        "        # Add 10 nodes to last FC layer\n",
        "        manager.increment_classes(n=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Split 0 of run 0 ##\n",
            "Epoch: 1, LR: [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "output: tensor([[ 0.9194, -0.9590,  0.7439, -0.9826, -0.2627, -1.0050,  0.7887,  0.6696,\n",
            "          2.1407,  0.1130],\n",
            "        [ 0.3057, -0.9949,  0.1400, -0.2803, -0.0398, -0.2558,  0.2307,  0.8007,\n",
            "          1.3077,  0.1453],\n",
            "        [ 0.1413, -1.0062,  0.2902, -0.3347, -0.1481, -0.2450,  0.2323,  0.6183,\n",
            "          1.4084,  0.2393],\n",
            "        [ 0.2985, -0.8117,  0.1122, -0.5369, -0.1188, -0.2595,  0.1364,  0.7010,\n",
            "          1.1449,  0.2312],\n",
            "        [ 0.3061, -0.9256,  0.3193, -0.3967, -0.1577, -0.2140,  0.3303,  0.6258,\n",
            "          1.3368,  0.0913],\n",
            "        [ 0.8168, -0.7340,  0.3187, -0.7376, -0.0913, -0.7567,  0.5063,  0.5420,\n",
            "          1.8608,  0.1010],\n",
            "        [ 0.1215, -0.9279,  0.2693, -0.1525,  0.0083, -0.2568,  0.2589,  0.7401,\n",
            "          1.2438,  0.2118],\n",
            "        [ 0.2736, -0.9361,  0.2965, -0.3977, -0.0612, -0.0936,  0.3126,  0.5906,\n",
            "          1.3916,  0.2055],\n",
            "        [ 0.7158, -0.6735,  0.2820, -0.7241, -0.1995, -0.7049,  0.4589,  0.5945,\n",
            "          1.4419,  0.0591],\n",
            "        [ 0.2400, -0.9475,  0.1855, -0.3869, -0.1161, -0.0982,  0.1674,  0.6950,\n",
            "          1.2177,  0.2393],\n",
            "        [ 0.3405, -0.7803,  0.1672, -0.2846, -0.0081, -0.3051,  0.1672,  0.6840,\n",
            "          1.2259,  0.1646],\n",
            "        [ 0.2304, -1.0393,  0.3870, -0.4284, -0.1268, -0.1732,  0.2675,  0.4967,\n",
            "          1.3846, -0.0236],\n",
            "        [ 0.4087, -0.8776,  0.1852, -0.5431, -0.1300, -0.0651,  0.2970,  0.6132,\n",
            "          1.4215,  0.1029],\n",
            "        [ 0.1836, -0.9316,  0.3525, -0.2124, -0.0914, -0.3093,  0.2578,  0.6856,\n",
            "          1.2368,  0.1998],\n",
            "        [ 0.3224, -0.9449,  0.2804, -0.3153, -0.1859, -0.3187,  0.1465,  0.6378,\n",
            "          1.3153,  0.0707],\n",
            "        [ 0.3422, -1.0581,  0.4221, -0.3026, -0.2231, -0.2775,  0.4311,  0.4891,\n",
            "          1.4631,  0.0542],\n",
            "        [ 0.3428, -0.9148,  0.3220, -0.3349, -0.1529, -0.1243,  0.3452,  0.6074,\n",
            "          1.2536,  0.1093],\n",
            "        [ 0.3369, -1.2069,  0.3248, -0.5166, -0.1924, -0.4117,  0.4641,  0.5540,\n",
            "          1.6962, -0.0545],\n",
            "        [ 0.9667, -1.0301,  0.5076, -0.7223, -0.1177, -1.3557,  1.0401,  0.8539,\n",
            "          2.4369,  0.0280],\n",
            "        [ 0.2646, -0.7637,  0.2365, -0.1650,  0.0058, -0.2910,  0.3291,  0.6008,\n",
            "          0.9930,  0.0979],\n",
            "        [ 0.3867, -0.8117,  0.1853, -0.3658, -0.1783, -0.2019,  0.3309,  0.6678,\n",
            "          1.2945,  0.1160],\n",
            "        [ 0.2204, -1.0599,  0.2241, -0.3405, -0.1049, -0.2864,  0.2178,  0.6609,\n",
            "          1.1963,  0.1985],\n",
            "        [ 0.6794, -0.9302,  0.3275, -0.3912,  0.0168, -0.7939,  0.8397,  0.6014,\n",
            "          1.6909,  0.0947],\n",
            "        [ 0.3004, -0.7937,  0.2642, -0.3583, -0.0242, -0.3672,  0.1974,  0.6330,\n",
            "          1.2559,  0.1439],\n",
            "        [ 0.2058, -0.9612,  0.2363, -0.4329, -0.0703, -0.1683,  0.2610,  0.6955,\n",
            "          1.2109,  0.3228],\n",
            "        [ 0.4451, -0.7960,  0.2506, -0.3819, -0.1312, -0.4205,  0.3221,  0.6596,\n",
            "          1.2338,  0.0733],\n",
            "        [ 0.1163, -0.8387,  0.2847, -0.2974, -0.0193, -0.1038,  0.0760,  0.6445,\n",
            "          1.2418,  0.3100],\n",
            "        [ 0.5844, -0.6037,  0.1366, -0.2920, -0.1429, -0.4356,  0.2383,  0.7941,\n",
            "          1.3113,  0.2180],\n",
            "        [ 0.2698, -0.8572,  0.2370, -0.3059, -0.0882, -0.1262,  0.1012,  0.6530,\n",
            "          1.1955,  0.3711],\n",
            "        [ 0.2149, -0.9229,  0.2267, -0.3405, -0.0753, -0.3064,  0.0486,  0.6662,\n",
            "          1.1039,  0.0587],\n",
            "        [ 0.2781, -0.9712,  0.3015, -0.3343, -0.0186, -0.3832,  0.3652,  0.5859,\n",
            "          1.5284,  0.1103],\n",
            "        [ 1.3304, -0.7731,  0.5079, -1.2609, -0.2397, -1.1681,  1.0908,  0.9013,\n",
            "          2.3661,  0.1409],\n",
            "        [ 0.3755, -1.0965,  0.4126, -0.2835, -0.2413, -0.3554,  0.5511,  0.4572,\n",
            "          1.4230, -0.0545],\n",
            "        [ 1.1287, -0.9221,  0.5649, -0.5008,  0.1786, -1.2089,  1.2462,  0.8387,\n",
            "          2.3525, -0.1489],\n",
            "        [ 0.2341, -0.9859,  0.2893, -0.3288, -0.1106, -0.2095,  0.2963,  0.6527,\n",
            "          1.2279,  0.0549],\n",
            "        [ 0.6138, -1.2445,  0.4893, -0.4318, -0.2422, -0.9219,  1.0228,  0.5895,\n",
            "          2.0000, -0.2030],\n",
            "        [ 1.1851, -1.2030,  0.5422, -0.7523,  0.1048, -1.4714,  1.1396,  0.7729,\n",
            "          2.4715, -0.3508],\n",
            "        [ 0.4596, -0.7203,  0.1942, -0.5413, -0.0671, -0.2949,  0.3281,  0.6777,\n",
            "          1.4021,  0.1995],\n",
            "        [ 0.3953, -1.0437,  0.3803, -0.4457, -0.0293, -0.3674,  0.6116,  0.6516,\n",
            "          1.5311,  0.0285],\n",
            "        [ 0.4481, -0.8259,  0.2838, -0.4711,  0.0157, -0.2727,  0.3769,  0.6529,\n",
            "          1.2943,  0.0780],\n",
            "        [ 0.5617, -0.7516,  0.4204, -0.5638, -0.1439, -0.4183,  0.4256,  0.6260,\n",
            "          1.4879,  0.1770],\n",
            "        [ 0.1275, -0.7189,  0.2301, -0.3350,  0.0552, -0.2205,  0.2645,  0.6145,\n",
            "          1.3703,  0.0917],\n",
            "        [ 0.5073, -1.1565,  0.3929, -0.0821, -0.1287, -0.7451,  0.7887,  0.5863,\n",
            "          1.8723,  0.0363],\n",
            "        [ 0.1796, -1.0322,  0.3891, -0.3407, -0.0813, -0.2725,  0.3230,  0.6118,\n",
            "          1.2570,  0.2967],\n",
            "        [ 0.1548, -0.9891,  0.1313, -0.3515,  0.0037, -0.1625,  0.3525,  0.7327,\n",
            "          1.3942,  0.1871],\n",
            "        [ 0.5120, -0.7945,  0.1894, -0.3400, -0.0882, -0.3040,  0.3008,  0.6322,\n",
            "          1.2234,  0.1583],\n",
            "        [ 1.1766, -0.5762,  0.5684, -0.8576, -0.0268, -1.3894,  0.8423,  0.7828,\n",
            "          2.0010,  0.2362],\n",
            "        [ 0.1927, -0.8853,  0.1771, -0.3813, -0.0866, -0.1861,  0.1548,  0.6989,\n",
            "          1.3113,  0.1634],\n",
            "        [ 0.5145, -1.0241,  0.3487, -0.2895, -0.0486, -0.4593,  0.6425,  0.4887,\n",
            "          1.5469,  0.1030],\n",
            "        [ 0.2975, -0.8864,  0.4167, -0.4800, -0.0420, -0.4632,  0.2845,  0.7270,\n",
            "          1.2270,  0.1333],\n",
            "        [ 0.1740, -1.0177,  0.2244, -0.2477, -0.0307, -0.0475,  0.1373,  0.6074,\n",
            "          0.9945,  0.0809],\n",
            "        [ 0.3910, -0.8503,  0.3767, -0.3334, -0.1352, -0.3086,  0.3581,  0.5551,\n",
            "          1.5706,  0.0340],\n",
            "        [ 0.3865, -0.6562,  0.2575, -0.3144, -0.0052, -0.4535,  0.1992,  0.7732,\n",
            "          1.3047,  0.1812],\n",
            "        [ 0.2396, -1.0868,  0.4706, -0.3873,  0.0733, -0.7235,  0.4931,  0.6149,\n",
            "          1.7060, -0.0225],\n",
            "        [ 0.1433, -0.9328,  0.2324, -0.2836, -0.0397, -0.0667,  0.2253,  0.6993,\n",
            "          1.2594,  0.2824],\n",
            "        [ 0.1765, -0.8549,  0.2586, -0.2337, -0.0652, -0.1442,  0.2288,  0.5985,\n",
            "          1.2942,  0.2896],\n",
            "        [ 0.3168, -0.9708,  0.2126, -0.3280, -0.0456, -0.4656,  0.2929,  0.7441,\n",
            "          1.3884,  0.1740],\n",
            "        [ 0.1628, -0.9576,  0.4615, -0.2560, -0.0342,  0.0046,  0.3133,  0.4830,\n",
            "          1.1722,  0.1861],\n",
            "        [ 0.3616, -0.9015,  0.1140, -0.1532, -0.1137, -0.2754,  0.2327,  0.8425,\n",
            "          1.0546,  0.1535],\n",
            "        [ 0.6530, -1.0201,  0.2602, -0.3452, -0.2494, -0.4239,  0.6233,  0.4724,\n",
            "          1.7493, -0.0248],\n",
            "        [ 0.4511, -0.8355,  0.1697, -0.4928, -0.0883, -0.2585,  0.2324,  0.5123,\n",
            "          1.5209,  0.2089],\n",
            "        [ 0.8221, -0.9016,  0.5529, -0.6504, -0.1689, -0.9937,  0.8284,  0.6588,\n",
            "          2.1435,  0.1530],\n",
            "        [ 0.6916, -0.9835,  0.2868, -0.5458, -0.1932, -0.7279,  0.3577,  0.7096,\n",
            "          1.8585,  0.1691],\n",
            "        [ 0.5391, -0.9949,  0.3153, -0.4601, -0.2192, -0.4165,  0.5696,  0.5983,\n",
            "          1.7063,  0.0699]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "labels: tensor([73, 72, 74, 58, 35, 20, 19, 80, 28, 90, 17, 35, 27, 18, 38, 11, 65, 36,\n",
            "         2, 40, 10, 34, 80, 13, 15, 16, 67, 10, 60, 41, 64, 67, 64, 24, 61, 72,\n",
            "        35, 67, 33,  5, 86,  3, 38, 92,  4, 43, 24, 80, 20, 25, 71, 65, 26, 70,\n",
            "         8, 34, 21, 96, 10, 82,  4,  5, 34, 81], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-01fc5fce8ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                           test_dataloader[run_i][split_i])\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ProjectMLDL/model/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Run an epoch (start counting form 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Validate after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ProjectMLDL/model/trainer.py\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(self, current_epoch)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ProjectMLDL/model/trainer.py\u001b[0m in \u001b[0;36mdo_batch\u001b[0;34m(self, batch, labels)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m#loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1048\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2386\u001b[0m         )\n\u001b[1;32m   2387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:115"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkw52To1iUwt",
        "outputId": "a228c3b4-5369-4347-c3d5-623c80ecae17"
      },
      "source": [
        "list = [73, 72, 74, 58, 35, 20, 19, 80, 28, 90, 17, 35, 27, 18, 38, 11, 65, 36,\n",
        "         2, 40, 10, 34, 80, 13, 15, 16, 67, 10, 60, 41, 64, 67, 64, 24, 61, 72,\n",
        "        35, 67, 33,  5, 86,  3, 38, 92,  4, 43, 24, 80, 20, 25, 71, 65, 26, 70,\n",
        "         8, 34, 21, 96, 10, 82,  4,  5, 34, 81]\n",
        "\n",
        "ins = set(list)\n",
        "len(ins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX-EdN4znF2Z",
        "outputId": "a50eb5ed-7c80-4283-e441-2f85b142767b"
      },
      "source": [
        "tot = set([])\n",
        "for k in range(1):\n",
        "  for i in range(5000):\n",
        "    idx = indexes_train_data[k][i]\n",
        "    lbl = train_data.__getitem__(idx)[2]\n",
        "    tot.add(lbl)\n",
        "\n",
        "tot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5arFUoICJDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929f51c1-67b4-42a0-c2d8-8dd0fe4b4caa"
      },
      "source": [
        "len(next(iter(test_dataloader[0][9]))[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4pEBuFdCpqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2973de0-023a-4510-923b-98017579a3a9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442, tensor([[[-0.7082, -0.2978,  0.1860,  ..., -0.6496, -0.6789, -1.8957],\n",
              "          [-0.7229, -0.3857,  0.0687,  ..., -0.6203, -0.6203, -1.8957],\n",
              "          [-0.7082, -0.4737, -0.0632,  ..., -0.6203, -0.5177, -1.8957],\n",
              "          ...,\n",
              "          [-0.4150, -0.1951, -0.0339,  ..., -0.2391, -0.1512, -1.8957],\n",
              "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
              "          [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
              " \n",
              "         [[-0.7967, -0.0781,  0.6252,  ..., -1.0107, -0.9954, -1.8975],\n",
              "          [-0.8273, -0.2004,  0.5029,  ..., -1.0107, -0.8884, -1.8975],\n",
              "          [-0.8578, -0.3227,  0.3653,  ..., -0.9801, -0.6132, -1.8975],\n",
              "          ...,\n",
              "          [ 0.1512,  0.2124,  0.1971,  ...,  0.5029,  0.3806, -1.8975],\n",
              "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
              "          [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
              " \n",
              "         [[-0.8437, -0.8864, -0.4318,  ..., -0.9432, -0.9432, -1.5965],\n",
              "          [-0.8011, -0.9432, -0.6023,  ..., -0.9006, -0.9006, -1.5965],\n",
              "          [-0.7727, -0.9716, -0.7869,  ..., -0.8864, -0.8295, -1.5965],\n",
              "          ...,\n",
              "          [-1.4261, -1.0852, -0.6875,  ...,  0.3209,  0.0369, -1.5965],\n",
              "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
              "          [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]]), 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDg2IZdaReFH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRoS-R_sRhHT"
      },
      "source": [
        "## Antonio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb_MRBMLSLW1"
      },
      "source": [
        "  train_data.__shuffle_seed__(RANDOM_SEED[0])\n",
        "  test_data.__shuffle_seed__(RANDOM_SEED[0])\n",
        "  \n",
        "\n",
        "  indexes_train_data = train_data.__incremental_indexes__(True)\n",
        "  indexes_test_data = test_data.__incremental_indexes__(False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVh61C63FECy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81990c9-b3a9-40d2-f2ac-f38e3ca6a527"
      },
      "source": [
        "train_dataloader = [[] for i in range(10)]\n",
        "val_dataloader = [[] for i in range(10)]\n",
        "test_dataloader = [[] for i in range(10)]\n",
        "for i in range(10):\n",
        "  train_dataset = Subset(train_data, indexes_train_data[i])\n",
        "  train_set, val_set = torch.utils.data.random_split(train_dataset, [int(0.8*len(indexes_train_data[0])), int(0.2*len(indexes_train_data[0]))])\n",
        "  tmp_dl = DataLoader(train_set, \n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4,\n",
        "                      drop_last=True)\n",
        "  train_dataloader[i] = copy(tmp_dl)\n",
        "  tmp_dl = DataLoader(val_set, \n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4,\n",
        "                      drop_last=True)\n",
        "  val_dataloader[i] = copy(tmp_dl)\n",
        "\n",
        "\n",
        "  test_dataset = Subset(test_data, indexes_test_data[i])\n",
        "  tmp_dl = DataLoader(test_dataset,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4,\n",
        "                      drop_last=True)\n",
        "  test_dataloader[i] = copy(tmp_dl)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvRuvlH3Syf1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.backends import cudnn\n",
        "from copy import deepcopy"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad1QQmI5vJjy"
      },
      "source": [
        "def to_onehot(net, targets, device): \n",
        "  '''\n",
        "  Args:\n",
        "  targets : dataloader.dataset.targets of the new task images\n",
        "  '''\n",
        "  num_classes = net.fc.out_features\n",
        "  one_hot_targets = torch.eye(num_classes)[targets]\n",
        "\n",
        "  return one_hot_targets.to(device)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKiy8o9YgaXC"
      },
      "source": [
        "def train(net, criterion, optimizer, train_dl, device):\n",
        "  net.train()\n",
        "\n",
        "  running_loss = 0\n",
        "\n",
        "  for batch in train_dl:\n",
        "    labels = batch[2]\n",
        "    images = batch[1]\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    one_hot_labels = to_onehot(net, labels, device) \n",
        "\n",
        "    output = net(images)\n",
        "    loss = criterion(output, one_hot_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    epoch_loss = running_loss/len(train_dl)\n",
        "  return epoch_loss\n",
        "    "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk8THneNZ97U"
      },
      "source": [
        "#### VALIDATION\n",
        "\n",
        "def validate(net, criterion, optimizer, validation_dl, device):\n",
        "  net.train(False)\n",
        "  running_loss=0\n",
        "  running_corrects = 0\n",
        "  total = 0\n",
        "  for batch in validation_dl:\n",
        "    labels = batch[2]\n",
        "    images = batch[1]\n",
        "    total += labels.size(0)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    one_hot_labels = to_onehot(net, labels, device) \n",
        "\n",
        "    output = net(images)\n",
        "    loss = criterion(output, one_hot_labels)\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    _, preds = torch.max(output.data, 1)\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "  else:\n",
        "    val_loss = running_loss/len(validation_dl)\n",
        "    \n",
        "\n",
        "  val_accuracy = running_corrects / float(total)\n",
        "  \n",
        "\n",
        "  return val_loss, val_accuracy"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoKj6zF9AkEn"
      },
      "source": [
        "def test(best_net, test_dl, device):\n",
        "  \"\"\"Test the model.\n",
        "  Returns:\n",
        "      accuracy (float): accuracy of the model on the test set\n",
        "  \"\"\"\n",
        "\n",
        "  best_net.train(False)  # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  total = 0\n",
        "\n",
        "  all_preds = torch.tensor([]) # to store all predictions\n",
        "  all_preds = all_preds.type(torch.LongTensor)\n",
        "  all_targets = torch.tensor([])\n",
        "  all_targets = all_targets.type(torch.LongTensor)\n",
        "\n",
        "  for _, images, labels in test_dl:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      total += labels.size(0)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = best_net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # Append batch predictions and labels\n",
        "      all_targets = torch.cat(\n",
        "          (all_targets.to(device), labels.to(device)), dim=0\n",
        "      )\n",
        "      all_preds = torch.cat(\n",
        "          (all_preds.to(device), preds.to(device)), dim=0\n",
        "      )\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = running_corrects / float(total)  \n",
        "\n",
        "\n",
        "  return accuracy, all_targets, all_preds"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZnfajyhEdUA"
      },
      "source": [
        "def increment_classes(net, n=10):\n",
        "  \"\"\"Add n classes in the final fully connected layer.\"\"\"\n",
        "\n",
        "  in_features = net.fc.in_features  # size of each input sample\n",
        "  out_features = net.fc.out_features  # size of each output sample\n",
        "  weight = net.fc.weight.data\n",
        "\n",
        "  net.fc = nn.Linear(in_features, out_features+n)\n",
        "  net.fc.weight.data[:out_features] = weight"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNPwfXa2tqpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90930cc0-0737-46a6-a3a2-9505b3a45553"
      },
      "source": [
        "net = resnet32()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "\n",
        "net.to(DEVICE)\n",
        "cudnn.benchmark\n",
        "num_epochs = 80\n",
        "\n",
        "epoch_losses = [[] for i in range(10)]\n",
        "for i in range(10):\n",
        "  net.to(DEVICE)\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA)\n",
        "\n",
        "  best_acc = 0\n",
        "  best_net = deepcopy(net)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    e_loss = train(net, criterion, optimizer, train_dataloader[i], DEVICE)\n",
        "    epoch_losses[i].append(e_loss)\n",
        "    print(f\"Epoch[{epoch}] loss: {e_loss} LR: {scheduler.get_last_lr()}\")\n",
        "    validate_loss, validate_acc = validate(net, criterion, optimizer, val_dataloader[i], DEVICE)\n",
        "    print(f\"Validation on group[{i}] of 10 classes\")\n",
        "    print(f\"val loss: {validate_loss}\")\n",
        "    print(f\"val acc: {validate_acc}\")\n",
        "    scheduler.step()\n",
        "    if validate_acc > best_acc:\n",
        "      best_acc = validate_acc\n",
        "      best_net = deepcopy(net)\n",
        "      best_epoch = epoch\n",
        "      print(\"Best model updated\")\n",
        "    print(\"\")\n",
        "\n",
        "  print(f\"Group[{i}]Finished!\")\n",
        "  print(f\"Best model at epoch {best_epoch}, best accuracy: {best_acc:.2f}\")\n",
        "  print(\"\")\n",
        "  acc_all, all_targets, all_preds = test(best_net, test_dataloader[i], DEVICE)\n",
        "  print(f\"Testing classes seen so far, accuracy: {acc_all}\")\n",
        "  print(\"\")\n",
        "  print(\"=============================================\")\n",
        "  print(\"\")\n",
        "\n",
        "  if i < 9:\n",
        "    increment_classes(net)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch[0] loss: 0.43079329306079495 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 1.4764954703194755\n",
            "val acc: 0.11941964285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.3252225075998614 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.32302625690187725\n",
            "val acc: 0.13058035714285715\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.3226424321051567 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3273803847176688\n",
            "val acc: 0.1328125\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.32311999317138423 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3209583716733115\n",
            "val acc: 0.140625\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.3208273658829351 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.32389557361602783\n",
            "val acc: 0.15513392857142858\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.31891891744828993 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.32285150459834505\n",
            "val acc: 0.15401785714285715\n",
            "\n",
            "Epoch[6] loss: 0.31827220512974647 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.31919123019490925\n",
            "val acc: 0.16852678571428573\n",
            "Best model updated\n",
            "\n",
            "Epoch[7] loss: 0.3171597786488072 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.31896109666143146\n",
            "val acc: 0.15513392857142858\n",
            "\n",
            "Epoch[8] loss: 0.31640303615600834 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3152925797871181\n",
            "val acc: 0.18973214285714285\n",
            "Best model updated\n",
            "\n",
            "Epoch[9] loss: 0.3143669068813324 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3191571533679962\n",
            "val acc: 0.15625\n",
            "\n",
            "Epoch[10] loss: 0.3138523361375255 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3150446116924286\n",
            "val acc: 0.1875\n",
            "\n",
            "Epoch[11] loss: 0.31264662742614746 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3123828981603895\n",
            "val acc: 0.23772321428571427\n",
            "Best model updated\n",
            "\n",
            "Epoch[12] loss: 0.3091834004848234 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3156083566801889\n",
            "val acc: 0.1796875\n",
            "\n",
            "Epoch[13] loss: 0.30281649674138716 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3221664045538221\n",
            "val acc: 0.17522321428571427\n",
            "\n",
            "Epoch[14] loss: 0.29635193367158214 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3021355058465685\n",
            "val acc: 0.26339285714285715\n",
            "Best model updated\n",
            "\n",
            "Epoch[15] loss: 0.2933015304227029 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.30710085374968393\n",
            "val acc: 0.2544642857142857\n",
            "\n",
            "Epoch[16] loss: 0.2875200461956762 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3086602134363992\n",
            "val acc: 0.22209821428571427\n",
            "\n",
            "Epoch[17] loss: 0.28773969892532597 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2916980641228812\n",
            "val acc: 0.29575892857142855\n",
            "Best model updated\n",
            "\n",
            "Epoch[18] loss: 0.2860095625923526 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.285271874495915\n",
            "val acc: 0.328125\n",
            "Best model updated\n",
            "\n",
            "Epoch[19] loss: 0.281661186487444 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.29355646882738384\n",
            "val acc: 0.29575892857142855\n",
            "\n",
            "Epoch[20] loss: 0.2777647702924667 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.3068240540368216\n",
            "val acc: 0.2544642857142857\n",
            "\n",
            "Epoch[21] loss: 0.2769219471562293 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.29070551480565754\n",
            "val acc: 0.3002232142857143\n",
            "\n",
            "Epoch[22] loss: 0.27233019903782874 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.28748818806239534\n",
            "val acc: 0.3013392857142857\n",
            "\n",
            "Epoch[23] loss: 0.2683771050745441 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.28739417025021147\n",
            "val acc: 0.29464285714285715\n",
            "\n",
            "Epoch[24] loss: 0.2645019581240992 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.29112730281693594\n",
            "val acc: 0.32142857142857145\n",
            "\n",
            "Epoch[25] loss: 0.2642504495959128 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2790704071521759\n",
            "val acc: 0.33816964285714285\n",
            "Best model updated\n",
            "\n",
            "Epoch[26] loss: 0.2593445446222059 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2730283737182617\n",
            "val acc: 0.3671875\n",
            "Best model updated\n",
            "\n",
            "Epoch[27] loss: 0.25662156554960436 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.27061659736292704\n",
            "val acc: 0.36160714285714285\n",
            "\n",
            "Epoch[28] loss: 0.2519446750802378 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.25300141743251253\n",
            "val acc: 0.43080357142857145\n",
            "Best model updated\n",
            "\n",
            "Epoch[29] loss: 0.24742160737514496 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2528728204114096\n",
            "val acc: 0.40625\n",
            "\n",
            "Epoch[30] loss: 0.2454699032729672 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.28102251461574007\n",
            "val acc: 0.36607142857142855\n",
            "\n",
            "Epoch[31] loss: 0.24290938963813166 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2462424635887146\n",
            "val acc: 0.43080357142857145\n",
            "\n",
            "Epoch[32] loss: 0.23830239715114718 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2634889228003366\n",
            "val acc: 0.4107142857142857\n",
            "\n",
            "Epoch[33] loss: 0.2383262082453697 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2574775218963623\n",
            "val acc: 0.4174107142857143\n",
            "\n",
            "Epoch[34] loss: 0.2294589699276032 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.23229701604161943\n",
            "val acc: 0.4765625\n",
            "Best model updated\n",
            "\n",
            "Epoch[35] loss: 0.22605884988461772 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.23493204372269766\n",
            "val acc: 0.45424107142857145\n",
            "\n",
            "Epoch[36] loss: 0.22240410889348677 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2428219871861594\n",
            "val acc: 0.4486607142857143\n",
            "\n",
            "Epoch[37] loss: 0.2187965320002648 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.23572598184858048\n",
            "val acc: 0.4921875\n",
            "Best model updated\n",
            "\n",
            "Epoch[38] loss: 0.21486160014906236 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2317202878849847\n",
            "val acc: 0.4877232142857143\n",
            "\n",
            "Epoch[39] loss: 0.21044269540617544 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2324162040437971\n",
            "val acc: 0.49330357142857145\n",
            "Best model updated\n",
            "\n",
            "Epoch[40] loss: 0.20582501109569304 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.23389334763799394\n",
            "val acc: 0.49330357142857145\n",
            "\n",
            "Epoch[41] loss: 0.20180006805927522 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2367772204535348\n",
            "val acc: 0.5212053571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[42] loss: 0.19863327856986754 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.24363828344004496\n",
            "val acc: 0.46205357142857145\n",
            "\n",
            "Epoch[43] loss: 0.19464983574805722 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.22923526806490763\n",
            "val acc: 0.5234375\n",
            "Best model updated\n",
            "\n",
            "Epoch[44] loss: 0.18952187078614388 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2900453231164387\n",
            "val acc: 0.43526785714285715\n",
            "\n",
            "Epoch[45] loss: 0.18355576021056022 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.21240040447030747\n",
            "val acc: 0.5569196428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[46] loss: 0.1816491513482986 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.23425136932304927\n",
            "val acc: 0.5189732142857143\n",
            "\n",
            "Epoch[47] loss: 0.18242819222711748 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.23411037240709578\n",
            "val acc: 0.48660714285714285\n",
            "\n",
            "Epoch[48] loss: 0.17292661147732888 LR: [2]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.2118102695260729\n",
            "val acc: 0.5747767857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[49] loss: 0.15279847287362622 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.17358888685703278\n",
            "val acc: 0.65625\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.14016496462206687 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.1737470839704786\n",
            "val acc: 0.6484375\n",
            "\n",
            "Epoch[51] loss: 0.13642814899644545 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.18161078223160335\n",
            "val acc: 0.6450892857142857\n",
            "\n",
            "Epoch[52] loss: 0.13402341810926313 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.16555200730051314\n",
            "val acc: 0.6573660714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[53] loss: 0.13061387596591825 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.1649241362299238\n",
            "val acc: 0.65625\n",
            "\n",
            "Epoch[54] loss: 0.1311221423168336 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.16764997584479197\n",
            "val acc: 0.6618303571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[55] loss: 0.12590856489635283 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15864176941769464\n",
            "val acc: 0.6819196428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[56] loss: 0.124094431679095 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.168263954775674\n",
            "val acc: 0.6595982142857143\n",
            "\n",
            "Epoch[57] loss: 0.11970079954593413 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.16206904820033483\n",
            "val acc: 0.6774553571428571\n",
            "\n",
            "Epoch[58] loss: 0.12073733705666757 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.17005483380385808\n",
            "val acc: 0.6819196428571429\n",
            "\n",
            "Epoch[59] loss: 0.11381174599932085 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.1590592818600791\n",
            "val acc: 0.6863839285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[60] loss: 0.11361940878052865 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.16315880417823792\n",
            "val acc: 0.6796875\n",
            "\n",
            "Epoch[61] loss: 0.10922151058912277 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.18647696716444834\n",
            "val acc: 0.6506696428571429\n",
            "\n",
            "Epoch[62] loss: 0.10896766185760498 LR: [0.4]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.17208301275968552\n",
            "val acc: 0.6595982142857143\n",
            "\n",
            "Epoch[63] loss: 0.09983734113554801 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15220704248973302\n",
            "val acc: 0.7020089285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[64] loss: 0.09546098401469569 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15038363741976873\n",
            "val acc: 0.7053571428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[65] loss: 0.09178698014828467 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15136144629546575\n",
            "val acc: 0.7020089285714286\n",
            "\n",
            "Epoch[66] loss: 0.09118533086392187 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.14637069510562079\n",
            "val acc: 0.7220982142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[67] loss: 0.08868082937213682 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.14421713139329637\n",
            "val acc: 0.7399553571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[68] loss: 0.08741433437793486 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.155111163854599\n",
            "val acc: 0.6997767857142857\n",
            "\n",
            "Epoch[69] loss: 0.08720228027912878 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.1547901662332671\n",
            "val acc: 0.6875\n",
            "\n",
            "Epoch[70] loss: 0.08695838131731556 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15190542382853373\n",
            "val acc: 0.7131696428571429\n",
            "\n",
            "Epoch[71] loss: 0.08434191995090054 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.14951506469930922\n",
            "val acc: 0.7131696428571429\n",
            "\n",
            "Epoch[72] loss: 0.0854756815298911 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15043033978768758\n",
            "val acc: 0.7120535714285714\n",
            "\n",
            "Epoch[73] loss: 0.08310004443891587 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15786887492452348\n",
            "val acc: 0.6908482142857143\n",
            "\n",
            "Epoch[74] loss: 0.08203337149273965 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.1537349202803203\n",
            "val acc: 0.7075892857142857\n",
            "\n",
            "Epoch[75] loss: 0.07847125936419733 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15241024323872157\n",
            "val acc: 0.7165178571428571\n",
            "\n",
            "Epoch[76] loss: 0.07783393682010713 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.1516968458890915\n",
            "val acc: 0.7109375\n",
            "\n",
            "Epoch[77] loss: 0.07895156068186607 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.15910927099840982\n",
            "val acc: 0.7109375\n",
            "\n",
            "Epoch[78] loss: 0.07927935943007469 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.16163732324327743\n",
            "val acc: 0.7008928571428571\n",
            "\n",
            "Epoch[79] loss: 0.0778607428073883 LR: [0.08000000000000002]\n",
            "Validation on group[0] of 10 classes\n",
            "val loss: 0.1476800569466182\n",
            "val acc: 0.7109375\n",
            "\n",
            "Group[0]Finished!\n",
            "Best model at epoch 67, best accuracy: 0.74\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.7087053571428571\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.189392842112049 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.14856702089309692\n",
            "val acc: 0.2578125\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.13002518684633316 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.12814913583653315\n",
            "val acc: 0.4095982142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.11847075291218297 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.1279011411326272\n",
            "val acc: 0.38950892857142855\n",
            "\n",
            "Epoch[3] loss: 0.1104954079754891 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.11381122044154576\n",
            "val acc: 0.48214285714285715\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.10128159580692168 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.11754262766667775\n",
            "val acc: 0.48995535714285715\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.09705762132521599 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.11338154545852117\n",
            "val acc: 0.5245535714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[6] loss: 0.09073685301888373 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.12430486295904432\n",
            "val acc: 0.49441964285714285\n",
            "\n",
            "Epoch[7] loss: 0.08445925986574541 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10645096536193575\n",
            "val acc: 0.546875\n",
            "Best model updated\n",
            "\n",
            "Epoch[8] loss: 0.08239685287398676 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10712560904877526\n",
            "val acc: 0.5747767857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[9] loss: 0.07753502769816306 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09355525140251432\n",
            "val acc: 0.6116071428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[10] loss: 0.07577183926778455 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0915750509926251\n",
            "val acc: 0.6138392857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[11] loss: 0.0721472469308684 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08889381906815938\n",
            "val acc: 0.6283482142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[12] loss: 0.06909095652161105 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.1147957912513188\n",
            "val acc: 0.5424107142857143\n",
            "\n",
            "Epoch[13] loss: 0.06706635101187614 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.12086981215647288\n",
            "val acc: 0.5714285714285714\n",
            "\n",
            "Epoch[14] loss: 0.06362769872911515 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0956759410245078\n",
            "val acc: 0.5993303571428571\n",
            "\n",
            "Epoch[15] loss: 0.06349753312045528 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10438398484672819\n",
            "val acc: 0.5904017857142857\n",
            "\n",
            "Epoch[16] loss: 0.06066163220713215 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10215812495776586\n",
            "val acc: 0.6026785714285714\n",
            "\n",
            "Epoch[17] loss: 0.05726820482842384 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09072007771049227\n",
            "val acc: 0.6618303571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[18] loss: 0.056789975973867604 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.1057205977184432\n",
            "val acc: 0.6216517857142857\n",
            "\n",
            "Epoch[19] loss: 0.05670244414960184 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08740054709570748\n",
            "val acc: 0.6741071428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[20] loss: 0.05170281183335089 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0919611666883741\n",
            "val acc: 0.6473214285714286\n",
            "\n",
            "Epoch[21] loss: 0.051639523717664906 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10639701038599014\n",
            "val acc: 0.5837053571428571\n",
            "\n",
            "Epoch[22] loss: 0.05273988097906113 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09081402740308217\n",
            "val acc: 0.6729910714285714\n",
            "\n",
            "Epoch[23] loss: 0.04987374044233753 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.11790429694311959\n",
            "val acc: 0.5892857142857143\n",
            "\n",
            "Epoch[24] loss: 0.04770680072326814 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09149935522249766\n",
            "val acc: 0.6741071428571429\n",
            "\n",
            "Epoch[25] loss: 0.04677981114195239 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09395039188010353\n",
            "val acc: 0.6417410714285714\n",
            "\n",
            "Epoch[26] loss: 0.044469835477009896 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08651106538517135\n",
            "val acc: 0.6886160714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[27] loss: 0.04322238915389584 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.11314956311668668\n",
            "val acc: 0.6127232142857143\n",
            "\n",
            "Epoch[28] loss: 0.04258434071896538 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08635663986206055\n",
            "val acc: 0.6752232142857143\n",
            "\n",
            "Epoch[29] loss: 0.04218723648978818 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10559644017900739\n",
            "val acc: 0.6328125\n",
            "\n",
            "Epoch[30] loss: 0.04134052427064988 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09124752559832164\n",
            "val acc: 0.6629464285714286\n",
            "\n",
            "Epoch[31] loss: 0.039873718554454464 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.11167353710957936\n",
            "val acc: 0.6194196428571429\n",
            "\n",
            "Epoch[32] loss: 0.03882849799288857 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10239857115915843\n",
            "val acc: 0.6506696428571429\n",
            "\n",
            "Epoch[33] loss: 0.04035228268513756 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10393482446670532\n",
            "val acc: 0.65625\n",
            "\n",
            "Epoch[34] loss: 0.03642169476276444 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.097894372684615\n",
            "val acc: 0.640625\n",
            "\n",
            "Epoch[35] loss: 0.037951203423642346 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10229738908154624\n",
            "val acc: 0.6517857142857143\n",
            "\n",
            "Epoch[36] loss: 0.03881285934438629 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.1077405395252364\n",
            "val acc: 0.6506696428571429\n",
            "\n",
            "Epoch[37] loss: 0.0339430432406164 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08297517895698547\n",
            "val acc: 0.7142857142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[38] loss: 0.03288087993860245 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.11179895060403007\n",
            "val acc: 0.6473214285714286\n",
            "\n",
            "Epoch[39] loss: 0.03360061401561383 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.1043947349701609\n",
            "val acc: 0.6607142857142857\n",
            "\n",
            "Epoch[40] loss: 0.03278852290203495 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0870452608380999\n",
            "val acc: 0.6953125\n",
            "\n",
            "Epoch[41] loss: 0.029932873684071725 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08671844431332179\n",
            "val acc: 0.7131696428571429\n",
            "\n",
            "Epoch[42] loss: 0.02955924058633466 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07830785321337837\n",
            "val acc: 0.7232142857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[43] loss: 0.027676047276585333 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09604310776506152\n",
            "val acc: 0.6930803571428571\n",
            "\n",
            "Epoch[44] loss: 0.02977231217007483 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.1213486481990133\n",
            "val acc: 0.6328125\n",
            "\n",
            "Epoch[45] loss: 0.030472524073575775 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08915220201015472\n",
            "val acc: 0.6886160714285714\n",
            "\n",
            "Epoch[46] loss: 0.026607937570060452 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09513350576162338\n",
            "val acc: 0.6674107142857143\n",
            "\n",
            "Epoch[47] loss: 0.02698510248334177 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.10729490646294185\n",
            "val acc: 0.6618303571428571\n",
            "\n",
            "Epoch[48] loss: 0.027793538185857957 LR: [2]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.09488659032753535\n",
            "val acc: 0.6897321428571429\n",
            "\n",
            "Epoch[49] loss: 0.02044977878610934 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07220125570893288\n",
            "val acc: 0.7444196428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.013650484157786254 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0692613029054233\n",
            "val acc: 0.7589285714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[51] loss: 0.011429968229945629 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07485592152391161\n",
            "val acc: 0.75\n",
            "\n",
            "Epoch[52] loss: 0.011388121811192363 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07109082436987332\n",
            "val acc: 0.7600446428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[53] loss: 0.008767399951935775 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0738173888197967\n",
            "val acc: 0.7578125\n",
            "\n",
            "Epoch[54] loss: 0.009329142785000225 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07401277124881744\n",
            "val acc: 0.7566964285714286\n",
            "\n",
            "Epoch[55] loss: 0.008316994209082858 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07511244448167938\n",
            "val acc: 0.7667410714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[56] loss: 0.007672208436434308 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07736890763044357\n",
            "val acc: 0.7566964285714286\n",
            "\n",
            "Epoch[57] loss: 0.007326024411726863 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07744771987199783\n",
            "val acc: 0.7477678571428571\n",
            "\n",
            "Epoch[58] loss: 0.007569789721239959 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08226995755519186\n",
            "val acc: 0.7366071428571429\n",
            "\n",
            "Epoch[59] loss: 0.0066329784946696415 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0753377793090684\n",
            "val acc: 0.7522321428571429\n",
            "\n",
            "Epoch[60] loss: 0.006243033026675543 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07273915197168078\n",
            "val acc: 0.7756696428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[61] loss: 0.006551908096298575 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07877090307218688\n",
            "val acc: 0.7645089285714286\n",
            "\n",
            "Epoch[62] loss: 0.005926166217954409 LR: [0.4]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08138739211218697\n",
            "val acc: 0.7566964285714286\n",
            "\n",
            "Epoch[63] loss: 0.005606877572473979 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0770023949444294\n",
            "val acc: 0.7622767857142857\n",
            "\n",
            "Epoch[64] loss: 0.005108573105967333 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08051023951598577\n",
            "val acc: 0.7622767857142857\n",
            "\n",
            "Epoch[65] loss: 0.005037027794206815 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07839977155838694\n",
            "val acc: 0.7756696428571429\n",
            "\n",
            "Epoch[66] loss: 0.004620203560578727 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08219194412231445\n",
            "val acc: 0.7611607142857143\n",
            "\n",
            "Epoch[67] loss: 0.004665071985894634 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07752860603587967\n",
            "val acc: 0.7645089285714286\n",
            "\n",
            "Epoch[68] loss: 0.004256668478070247 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0841857258762632\n",
            "val acc: 0.7600446428571429\n",
            "\n",
            "Epoch[69] loss: 0.004614215697191896 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0772838895874364\n",
            "val acc: 0.7633928571428571\n",
            "\n",
            "Epoch[70] loss: 0.004528434188555806 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07643775056515421\n",
            "val acc: 0.7790178571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[71] loss: 0.004177362218709482 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07731840546642031\n",
            "val acc: 0.7511160714285714\n",
            "\n",
            "Epoch[72] loss: 0.003933172909572961 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08498916881425041\n",
            "val acc: 0.7533482142857143\n",
            "\n",
            "Epoch[73] loss: 0.004139019289023934 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07679530020271029\n",
            "val acc: 0.7645089285714286\n",
            "\n",
            "Epoch[74] loss: 0.004188728913094008 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08359698259404727\n",
            "val acc: 0.7633928571428571\n",
            "\n",
            "Epoch[75] loss: 0.0039464423410414205 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08137656961168561\n",
            "val acc: 0.7611607142857143\n",
            "\n",
            "Epoch[76] loss: 0.004116677408737521 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08132352892841611\n",
            "val acc: 0.7779017857142857\n",
            "\n",
            "Epoch[77] loss: 0.004031584560570698 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.07788198494485446\n",
            "val acc: 0.7712053571428571\n",
            "\n",
            "Epoch[78] loss: 0.003953645110971505 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.08468886358397347\n",
            "val acc: 0.7511160714285714\n",
            "\n",
            "Epoch[79] loss: 0.004231489913147543 LR: [0.08000000000000002]\n",
            "Validation on group[1] of 10 classes\n",
            "val loss: 0.0791005864739418\n",
            "val acc: 0.7589285714285714\n",
            "\n",
            "Group[1]Finished!\n",
            "Best model at epoch 70, best accuracy: 0.78\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.39739583333333334\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.12946641853740137 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.08814020987067904\n",
            "val acc: 0.390625\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.0685963113942454 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.06507989072373935\n",
            "val acc: 0.59375\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.0560042925419346 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.056392637746674676\n",
            "val acc: 0.6439732142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.04877582252506287 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05370948037930897\n",
            "val acc: 0.6696428571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.04346645046626368 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04919478563325746\n",
            "val acc: 0.6941964285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.0368825766227899 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.054967335292271206\n",
            "val acc: 0.6741071428571429\n",
            "\n",
            "Epoch[6] loss: 0.03582579954977958 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05038079885499818\n",
            "val acc: 0.7087053571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[7] loss: 0.03179342924587188 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.045869000256061554\n",
            "val acc: 0.7232142857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[8] loss: 0.029567365684816913 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04731948993035725\n",
            "val acc: 0.7142857142857143\n",
            "\n",
            "Epoch[9] loss: 0.028505081731465556 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.050473742719207494\n",
            "val acc: 0.7176339285714286\n",
            "\n",
            "Epoch[10] loss: 0.027032483549368 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04903727237667356\n",
            "val acc: 0.7198660714285714\n",
            "\n",
            "Epoch[11] loss: 0.02622073227840085 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05577273879732404\n",
            "val acc: 0.6785714285714286\n",
            "\n",
            "Epoch[12] loss: 0.025557087914597605 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04991289707166808\n",
            "val acc: 0.6908482142857143\n",
            "\n",
            "Epoch[13] loss: 0.023737131347579342 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04623649162905557\n",
            "val acc: 0.7600446428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[14] loss: 0.021475422766900832 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05089364254048893\n",
            "val acc: 0.7265625\n",
            "\n",
            "Epoch[15] loss: 0.020549825993516752 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.053598047367164066\n",
            "val acc: 0.734375\n",
            "\n",
            "Epoch[16] loss: 0.02000540386765234 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04807346101318087\n",
            "val acc: 0.7377232142857143\n",
            "\n",
            "Epoch[17] loss: 0.019975180737674236 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04772328319294112\n",
            "val acc: 0.7488839285714286\n",
            "\n",
            "Epoch[18] loss: 0.018141904214937842 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.054608870829854696\n",
            "val acc: 0.7321428571428571\n",
            "\n",
            "Epoch[19] loss: 0.0186423615462357 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05234128130333764\n",
            "val acc: 0.7299107142857143\n",
            "\n",
            "Epoch[20] loss: 0.018547769545787764 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05143422952720097\n",
            "val acc: 0.7388392857142857\n",
            "\n",
            "Epoch[21] loss: 0.01640110721270884 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.046446935406752994\n",
            "val acc: 0.7745535714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[22] loss: 0.01512101971574368 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03933976909943989\n",
            "val acc: 0.7712053571428571\n",
            "\n",
            "Epoch[23] loss: 0.014185165746077415 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.044728862919977734\n",
            "val acc: 0.7745535714285714\n",
            "\n",
            "Epoch[24] loss: 0.013355834289423881 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04731507120387895\n",
            "val acc: 0.7578125\n",
            "\n",
            "Epoch[25] loss: 0.015027885505508992 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.049324412431035726\n",
            "val acc: 0.7566964285714286\n",
            "\n",
            "Epoch[26] loss: 0.012711991090327501 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04575683868357113\n",
            "val acc: 0.7622767857142857\n",
            "\n",
            "Epoch[27] loss: 0.012461717210469707 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.0451105779835156\n",
            "val acc: 0.7767857142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[28] loss: 0.013647794212785459 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05152160408241408\n",
            "val acc: 0.7354910714285714\n",
            "\n",
            "Epoch[29] loss: 0.012308830094914283 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04276316133993013\n",
            "val acc: 0.7901785714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[30] loss: 0.012238175247705752 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05004582128354481\n",
            "val acc: 0.7578125\n",
            "\n",
            "Epoch[31] loss: 0.01234378513970202 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05633776049528803\n",
            "val acc: 0.7410714285714286\n",
            "\n",
            "Epoch[32] loss: 0.011624447851171416 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04421201507960047\n",
            "val acc: 0.7868303571428571\n",
            "\n",
            "Epoch[33] loss: 0.011153108635616879 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.045945716223546436\n",
            "val acc: 0.7756696428571429\n",
            "\n",
            "Epoch[34] loss: 0.009254352610197759 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05782179055469377\n",
            "val acc: 0.7243303571428571\n",
            "\n",
            "Epoch[35] loss: 0.010221885577324898 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.06153960419552667\n",
            "val acc: 0.7544642857142857\n",
            "\n",
            "Epoch[36] loss: 0.01110725726691946 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.049626914518220086\n",
            "val acc: 0.7712053571428571\n",
            "\n",
            "Epoch[37] loss: 0.011113545662092586 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04631497338414192\n",
            "val acc: 0.7622767857142857\n",
            "\n",
            "Epoch[38] loss: 0.010076811326847922 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.054781560386930196\n",
            "val acc: 0.7633928571428571\n",
            "\n",
            "Epoch[39] loss: 0.010974942030565392 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05883362250668662\n",
            "val acc: 0.75\n",
            "\n",
            "Epoch[40] loss: 0.011234358388690217 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04851641559175083\n",
            "val acc: 0.7645089285714286\n",
            "\n",
            "Epoch[41] loss: 0.008336328570881197 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04719830783350127\n",
            "val acc: 0.765625\n",
            "\n",
            "Epoch[42] loss: 0.007862798343863218 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04756989117179598\n",
            "val acc: 0.7845982142857143\n",
            "\n",
            "Epoch[43] loss: 0.006674617904448702 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04080132022500038\n",
            "val acc: 0.8058035714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[44] loss: 0.006681882100360048 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04770763537713459\n",
            "val acc: 0.7957589285714286\n",
            "\n",
            "Epoch[45] loss: 0.008980014015950503 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.05024043896368572\n",
            "val acc: 0.7667410714285714\n",
            "\n",
            "Epoch[46] loss: 0.00982506095521873 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.0397868598146098\n",
            "val acc: 0.8113839285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[47] loss: 0.00754666444094431 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.0705881943660123\n",
            "val acc: 0.7075892857142857\n",
            "\n",
            "Epoch[48] loss: 0.00900659145366761 LR: [2]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.0487782997744424\n",
            "val acc: 0.7723214285714286\n",
            "\n",
            "Epoch[49] loss: 0.005755141985812976 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03548509893672807\n",
            "val acc: 0.8337053571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.0032492078795668578 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03454529627093247\n",
            "val acc: 0.8303571428571429\n",
            "\n",
            "Epoch[51] loss: 0.0028991719572654655 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03354638522224767\n",
            "val acc: 0.8314732142857143\n",
            "\n",
            "Epoch[52] loss: 0.0025424546441964566 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.038223455526999066\n",
            "val acc: 0.8180803571428571\n",
            "\n",
            "Epoch[53] loss: 0.0022622667883913363 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03770180631961141\n",
            "val acc: 0.8191964285714286\n",
            "\n",
            "Epoch[54] loss: 0.0019292962707338794 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03336007281073502\n",
            "val acc: 0.8470982142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[55] loss: 0.0019140027260648148 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03217141330242157\n",
            "val acc: 0.8482142857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[56] loss: 0.0016227443721295604 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03389818806733404\n",
            "val acc: 0.8448660714285714\n",
            "\n",
            "Epoch[57] loss: 0.0017519212410514874 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.035402827497039525\n",
            "val acc: 0.8381696428571429\n",
            "\n",
            "Epoch[58] loss: 0.001861768318415289 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03752039346311774\n",
            "val acc: 0.8258928571428571\n",
            "\n",
            "Epoch[59] loss: 0.0017227576463483274 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03669425073478903\n",
            "val acc: 0.8303571428571429\n",
            "\n",
            "Epoch[60] loss: 0.0015018882470265512 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.037371469395501275\n",
            "val acc: 0.8180803571428571\n",
            "\n",
            "Epoch[61] loss: 0.0013058204297727394 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.036957774577396255\n",
            "val acc: 0.8392857142857143\n",
            "\n",
            "Epoch[62] loss: 0.001475229558925475 LR: [0.4]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.04134059005549976\n",
            "val acc: 0.8002232142857143\n",
            "\n",
            "Epoch[63] loss: 0.0011255792755212996 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03612993923681123\n",
            "val acc: 0.8370535714285714\n",
            "\n",
            "Epoch[64] loss: 0.0012296870587423683 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03744842324938093\n",
            "val acc: 0.8292410714285714\n",
            "\n",
            "Epoch[65] loss: 0.0011961404985237505 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03794523514807224\n",
            "val acc: 0.8314732142857143\n",
            "\n",
            "Epoch[66] loss: 0.0010799168366863723 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03497240000537464\n",
            "val acc: 0.8292410714285714\n",
            "\n",
            "Epoch[67] loss: 0.0012162874524121084 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03568235678332193\n",
            "val acc: 0.84375\n",
            "\n",
            "Epoch[68] loss: 0.0011349160988409553 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03418918539370809\n",
            "val acc: 0.8482142857142857\n",
            "\n",
            "Epoch[69] loss: 0.0010931953128742716 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.037589281265224726\n",
            "val acc: 0.828125\n",
            "\n",
            "Epoch[70] loss: 0.0010826039971077754 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.0378315339663199\n",
            "val acc: 0.8236607142857143\n",
            "\n",
            "Epoch[71] loss: 0.0009998940382032625 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.037569254104580195\n",
            "val acc: 0.8337053571428571\n",
            "\n",
            "Epoch[72] loss: 0.0008856331020773899 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03876783459314278\n",
            "val acc: 0.828125\n",
            "\n",
            "Epoch[73] loss: 0.0010175796642508958 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03658816617514406\n",
            "val acc: 0.8381696428571429\n",
            "\n",
            "Epoch[74] loss: 0.0009307901810614332 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03724000336868422\n",
            "val acc: 0.8348214285714286\n",
            "\n",
            "Epoch[75] loss: 0.000881712211506261 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03900142838912351\n",
            "val acc: 0.8247767857142857\n",
            "\n",
            "Epoch[76] loss: 0.001297816764675982 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.039374063323651044\n",
            "val acc: 0.8258928571428571\n",
            "\n",
            "Epoch[77] loss: 0.0008387919102284697 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03787876878465925\n",
            "val acc: 0.8247767857142857\n",
            "\n",
            "Epoch[78] loss: 0.0008679927024434531 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03711124349917684\n",
            "val acc: 0.8392857142857143\n",
            "\n",
            "Epoch[79] loss: 0.0009729758781876655 LR: [0.08000000000000002]\n",
            "Validation on group[2] of 10 classes\n",
            "val loss: 0.03449000311749322\n",
            "val acc: 0.8426339285714286\n",
            "\n",
            "Group[2]Finished!\n",
            "Best model at epoch 55, best accuracy: 0.85\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.27717391304347827\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.09996331699432866 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.07368281057902745\n",
            "val acc: 0.34263392857142855\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.056192933191214836 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.05026407326970782\n",
            "val acc: 0.5736607142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.04551330316931971 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04757826615657125\n",
            "val acc: 0.6004464285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.04046092212440506 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04179346561431885\n",
            "val acc: 0.6584821428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.035618737039546815 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04056116725717272\n",
            "val acc: 0.671875\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.032124012107810664 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03793531070862498\n",
            "val acc: 0.6774553571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[6] loss: 0.029954761266708374 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03764564437525613\n",
            "val acc: 0.6997767857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[7] loss: 0.028585830703377724 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03578313227210726\n",
            "val acc: 0.7310267857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[8] loss: 0.02579969041530163 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.035614676773548126\n",
            "val acc: 0.7232142857142857\n",
            "\n",
            "Epoch[9] loss: 0.02402639395046619 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03267072167779718\n",
            "val acc: 0.7477678571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[10] loss: 0.022357040175026464 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03333123932991709\n",
            "val acc: 0.7366071428571429\n",
            "\n",
            "Epoch[11] loss: 0.021077337434455272 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.035041277429887226\n",
            "val acc: 0.7232142857142857\n",
            "\n",
            "Epoch[12] loss: 0.02034017269409472 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03584933866347585\n",
            "val acc: 0.7477678571428571\n",
            "\n",
            "Epoch[13] loss: 0.020313139704446637 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.036104271454470496\n",
            "val acc: 0.7276785714285714\n",
            "\n",
            "Epoch[14] loss: 0.018907552194451133 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03476019789065633\n",
            "val acc: 0.7488839285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[15] loss: 0.017555379128504182 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03919936663338116\n",
            "val acc: 0.7120535714285714\n",
            "\n",
            "Epoch[16] loss: 0.01684946197295381 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03668529966047832\n",
            "val acc: 0.7321428571428571\n",
            "\n",
            "Epoch[17] loss: 0.017676632520892927 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04281960055232048\n",
            "val acc: 0.7109375\n",
            "\n",
            "Epoch[18] loss: 0.01669068331079137 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04206837021878788\n",
            "val acc: 0.7042410714285714\n",
            "\n",
            "Epoch[19] loss: 0.014334005423851551 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.035364420020154545\n",
            "val acc: 0.7600446428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[20] loss: 0.013416474384646262 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.038082213274070194\n",
            "val acc: 0.7511160714285714\n",
            "\n",
            "Epoch[21] loss: 0.013096738110987409 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.033141429402998517\n",
            "val acc: 0.7600446428571429\n",
            "\n",
            "Epoch[22] loss: 0.013935862950259639 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.041641167764152796\n",
            "val acc: 0.7287946428571429\n",
            "\n",
            "Epoch[23] loss: 0.014473898486504632 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03856929365013327\n",
            "val acc: 0.7455357142857143\n",
            "\n",
            "Epoch[24] loss: 0.013036022082932534 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03496687486767769\n",
            "val acc: 0.7466517857142857\n",
            "\n",
            "Epoch[25] loss: 0.012324028768606724 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.050690511507647376\n",
            "val acc: 0.71875\n",
            "\n",
            "Epoch[26] loss: 0.01216696378504557 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04245902890605586\n",
            "val acc: 0.7310267857142857\n",
            "\n",
            "Epoch[27] loss: 0.010962660108963329 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.0358416603079864\n",
            "val acc: 0.7645089285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[28] loss: 0.009895760220505537 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04035469517111778\n",
            "val acc: 0.7578125\n",
            "\n",
            "Epoch[29] loss: 0.010062522570332211 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.040690094764743535\n",
            "val acc: 0.7511160714285714\n",
            "\n",
            "Epoch[30] loss: 0.011721529607330599 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04387743451765606\n",
            "val acc: 0.7265625\n",
            "\n",
            "Epoch[31] loss: 0.01029062726264519 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.039581023422735076\n",
            "val acc: 0.7332589285714286\n",
            "\n",
            "Epoch[32] loss: 0.0091159870818017 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.039562586162771494\n",
            "val acc: 0.7455357142857143\n",
            "\n",
            "Epoch[33] loss: 0.00818139051778182 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04071359442813056\n",
            "val acc: 0.7566964285714286\n",
            "\n",
            "Epoch[34] loss: 0.009819247038854707 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04006821236440113\n",
            "val acc: 0.7589285714285714\n",
            "\n",
            "Epoch[35] loss: 0.009305785785639478 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.043353545878614695\n",
            "val acc: 0.7410714285714286\n",
            "\n",
            "Epoch[36] loss: 0.008889495680529264 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04427800912942205\n",
            "val acc: 0.7332589285714286\n",
            "\n",
            "Epoch[37] loss: 0.008295717754311139 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.05105934664607048\n",
            "val acc: 0.7042410714285714\n",
            "\n",
            "Epoch[38] loss: 0.007408160430889937 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03929508663713932\n",
            "val acc: 0.7756696428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[39] loss: 0.008383177085629395 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03662735729345253\n",
            "val acc: 0.7712053571428571\n",
            "\n",
            "Epoch[40] loss: 0.008932060171519556 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.039371010448251455\n",
            "val acc: 0.7555803571428571\n",
            "\n",
            "Epoch[41] loss: 0.008759644633579639 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.039506458810397556\n",
            "val acc: 0.7823660714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[42] loss: 0.007532451429494446 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04754542985132763\n",
            "val acc: 0.7154017857142857\n",
            "\n",
            "Epoch[43] loss: 0.007061765363980685 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04229063753570829\n",
            "val acc: 0.7555803571428571\n",
            "\n",
            "Epoch[44] loss: 0.006678551533109238 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.045477427542209625\n",
            "val acc: 0.7488839285714286\n",
            "\n",
            "Epoch[45] loss: 0.00815270449815979 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04315643012523651\n",
            "val acc: 0.7511160714285714\n",
            "\n",
            "Epoch[46] loss: 0.00819499128227753 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.04630429537168571\n",
            "val acc: 0.7410714285714286\n",
            "\n",
            "Epoch[47] loss: 0.007934431432776393 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03187826195997851\n",
            "val acc: 0.7912946428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[48] loss: 0.005825249936371561 LR: [2]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03468498906918934\n",
            "val acc: 0.7801339285714286\n",
            "\n",
            "Epoch[49] loss: 0.004058015904569578 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.029457939256514822\n",
            "val acc: 0.8147321428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.00270000655174015 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.029498779880149022\n",
            "val acc: 0.8136160714285714\n",
            "\n",
            "Epoch[51] loss: 0.0021078341242466722 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.030333275773695538\n",
            "val acc: 0.8180803571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[52] loss: 0.0018435100716869197 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.028816001223666326\n",
            "val acc: 0.8270089285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[53] loss: 0.0017456320722797705 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.029267905013901845\n",
            "val acc: 0.8270089285714286\n",
            "\n",
            "Epoch[54] loss: 0.001485985074748075 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.027280224221093313\n",
            "val acc: 0.8303571428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[55] loss: 0.001479454137640254 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.02615258257303919\n",
            "val acc: 0.8370535714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[56] loss: 0.0014388032066034934 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.025717224393572127\n",
            "val acc: 0.8370535714285714\n",
            "\n",
            "Epoch[57] loss: 0.001179045024928787 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.02771382432963167\n",
            "val acc: 0.8314732142857143\n",
            "\n",
            "Epoch[58] loss: 0.0013237717963244405 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.02722289945398058\n",
            "val acc: 0.8392857142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[59] loss: 0.0011640182882171844 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.029162950946816375\n",
            "val acc: 0.8225446428571429\n",
            "\n",
            "Epoch[60] loss: 0.0011128998181271937 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.030268965555088862\n",
            "val acc: 0.8236607142857143\n",
            "\n",
            "Epoch[61] loss: 0.001122866384497273 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.030311025945203646\n",
            "val acc: 0.828125\n",
            "\n",
            "Epoch[62] loss: 0.001265913674292425 LR: [0.4]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03136519183005605\n",
            "val acc: 0.8180803571428571\n",
            "\n",
            "Epoch[63] loss: 0.0009434160855298321 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.031116203271916935\n",
            "val acc: 0.8247767857142857\n",
            "\n",
            "Epoch[64] loss: 0.0008969086085280944 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.028336872346699238\n",
            "val acc: 0.8359375\n",
            "\n",
            "Epoch[65] loss: 0.0010233712579769594 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.028158830212695257\n",
            "val acc: 0.8493303571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[66] loss: 0.0009241923840055542 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.03018598418150629\n",
            "val acc: 0.8348214285714286\n",
            "\n",
            "Epoch[67] loss: 0.0008946653359734844 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.028015654534101486\n",
            "val acc: 0.8370535714285714\n",
            "\n",
            "Epoch[68] loss: 0.0009179297213127176 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.027293058910540173\n",
            "val acc: 0.8337053571428571\n",
            "\n",
            "Epoch[69] loss: 0.0008003600655243762 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.028697783393519267\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[70] loss: 0.0008733249241260872 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.029003491891281947\n",
            "val acc: 0.828125\n",
            "\n",
            "Epoch[71] loss: 0.0009458501937784135 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.029464290344289372\n",
            "val acc: 0.8258928571428571\n",
            "\n",
            "Epoch[72] loss: 0.0008681522261711859 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.02878981003803866\n",
            "val acc: 0.8415178571428571\n",
            "\n",
            "Epoch[73] loss: 0.0009589983392581944 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.027772697220955576\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[74] loss: 0.0008484241271000956 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.02900198900273868\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[75] loss: 0.000863406247639608 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.029983792454004288\n",
            "val acc: 0.8270089285714286\n",
            "\n",
            "Epoch[76] loss: 0.0008831028225681474 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.02894364989229611\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[77] loss: 0.0007783024892916963 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.029153847002557347\n",
            "val acc: 0.8258928571428571\n",
            "\n",
            "Epoch[78] loss: 0.0008487496947524168 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.028632808476686478\n",
            "val acc: 0.8247767857142857\n",
            "\n",
            "Epoch[79] loss: 0.0008658237845426606 LR: [0.08000000000000002]\n",
            "Validation on group[3] of 10 classes\n",
            "val loss: 0.02996339994881834\n",
            "val acc: 0.8292410714285714\n",
            "\n",
            "Group[3]Finished!\n",
            "Best model at epoch 65, best accuracy: 0.85\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.20942540322580644\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.07635411223576914 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.05288606722440038\n",
            "val acc: 0.42857142857142855\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.03738614532255357 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.035691933440310616\n",
            "val acc: 0.6350446428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.02969873095712354 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.029628838279417584\n",
            "val acc: 0.7109375\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.025265952331885215 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.027099928419504846\n",
            "val acc: 0.7455357142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.022223347858075174 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02690278073506696\n",
            "val acc: 0.7366071428571429\n",
            "\n",
            "Epoch[5] loss: 0.020401823424523877 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.024007414866771017\n",
            "val acc: 0.7734375\n",
            "Best model updated\n",
            "\n",
            "Epoch[6] loss: 0.018390309215793686 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.024565896285431727\n",
            "val acc: 0.7633928571428571\n",
            "\n",
            "Epoch[7] loss: 0.017662308809738004 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.025781931621687754\n",
            "val acc: 0.7477678571428571\n",
            "\n",
            "Epoch[8] loss: 0.01611934524149664 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.030490504311663762\n",
            "val acc: 0.7254464285714286\n",
            "\n",
            "Epoch[9] loss: 0.014931645214317306 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02623432661805834\n",
            "val acc: 0.7455357142857143\n",
            "\n",
            "Epoch[10] loss: 0.013637796344776307 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02620792788054262\n",
            "val acc: 0.7689732142857143\n",
            "\n",
            "Epoch[11] loss: 0.012902432541933751 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.024988575439367975\n",
            "val acc: 0.7723214285714286\n",
            "\n",
            "Epoch[12] loss: 0.012819884960810024 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.027713565421955928\n",
            "val acc: 0.7511160714285714\n",
            "\n",
            "Epoch[13] loss: 0.012476161633047366 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.026439531041043147\n",
            "val acc: 0.765625\n",
            "\n",
            "Epoch[14] loss: 0.011254022724085277 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.023198704102209637\n",
            "val acc: 0.8002232142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[15] loss: 0.011095329518279722 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02457670255431107\n",
            "val acc: 0.7834821428571429\n",
            "\n",
            "Epoch[16] loss: 0.011081768710526728 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.028770324641040394\n",
            "val acc: 0.7421875\n",
            "\n",
            "Epoch[17] loss: 0.010092364248609351 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.025376358202525547\n",
            "val acc: 0.7767857142857143\n",
            "\n",
            "Epoch[18] loss: 0.009609293628243669 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.021456521536622728\n",
            "val acc: 0.8046875\n",
            "Best model updated\n",
            "\n",
            "Epoch[19] loss: 0.009191421055865864 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.03067667649260589\n",
            "val acc: 0.7366071428571429\n",
            "\n",
            "Epoch[20] loss: 0.008628038599366141 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.029699753703815595\n",
            "val acc: 0.7533482142857143\n",
            "\n",
            "Epoch[21] loss: 0.010021372548034113 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.03647316247224808\n",
            "val acc: 0.7053571428571429\n",
            "\n",
            "Epoch[22] loss: 0.00913582799295264 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.027833317539521625\n",
            "val acc: 0.7645089285714286\n",
            "\n",
            "Epoch[23] loss: 0.007555108502387039 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.025246028921433857\n",
            "val acc: 0.7767857142857143\n",
            "\n",
            "Epoch[24] loss: 0.007519069758634414 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02192495869738715\n",
            "val acc: 0.8091517857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[25] loss: 0.006909421990595518 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.024659058079123497\n",
            "val acc: 0.7879464285714286\n",
            "\n",
            "Epoch[26] loss: 0.00745523992865797 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.024625143302338465\n",
            "val acc: 0.7946428571428571\n",
            "\n",
            "Epoch[27] loss: 0.007403106533832127 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.023730110110981122\n",
            "val acc: 0.8080357142857143\n",
            "\n",
            "Epoch[28] loss: 0.006384607840089067 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.023225482553243637\n",
            "val acc: 0.7935267857142857\n",
            "\n",
            "Epoch[29] loss: 0.006445892155170441 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.023325115708368167\n",
            "val acc: 0.8091517857142857\n",
            "\n",
            "Epoch[30] loss: 0.0068129417110955525 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.027361825108528137\n",
            "val acc: 0.7834821428571429\n",
            "\n",
            "Epoch[31] loss: 0.007175456056551587 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.025853597692080905\n",
            "val acc: 0.7924107142857143\n",
            "\n",
            "Epoch[32] loss: 0.006744495337648738 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.03190191436026778\n",
            "val acc: 0.7633928571428571\n",
            "\n",
            "Epoch[33] loss: 0.00654444900611716 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.028078270543898855\n",
            "val acc: 0.7790178571428571\n",
            "\n",
            "Epoch[34] loss: 0.006002200797440544 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.027233318824853216\n",
            "val acc: 0.7924107142857143\n",
            "\n",
            "Epoch[35] loss: 0.00593073750215192 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.029839886352419853\n",
            "val acc: 0.7667410714285714\n",
            "\n",
            "Epoch[36] loss: 0.0057737984048623235 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.027605829494340078\n",
            "val acc: 0.7767857142857143\n",
            "\n",
            "Epoch[37] loss: 0.0051544600902425665 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.026597393676638603\n",
            "val acc: 0.8013392857142857\n",
            "\n",
            "Epoch[38] loss: 0.005133710516196105 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.03671634862465518\n",
            "val acc: 0.7410714285714286\n",
            "\n",
            "Epoch[39] loss: 0.00513354686629628 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.0313192398420402\n",
            "val acc: 0.7645089285714286\n",
            "\n",
            "Epoch[40] loss: 0.004888473093629845 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02681067106979234\n",
            "val acc: 0.7868303571428571\n",
            "\n",
            "Epoch[41] loss: 0.004851299086435427 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.029191276856831143\n",
            "val acc: 0.796875\n",
            "\n",
            "Epoch[42] loss: 0.00491287148812966 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.038405458842005046\n",
            "val acc: 0.7265625\n",
            "\n",
            "Epoch[43] loss: 0.004744378827332008 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.029684743710926602\n",
            "val acc: 0.7767857142857143\n",
            "\n",
            "Epoch[44] loss: 0.0044826072445439714 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.023957179859280586\n",
            "val acc: 0.8091517857142857\n",
            "\n",
            "Epoch[45] loss: 0.0038583106736862854 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.03010471777192184\n",
            "val acc: 0.7868303571428571\n",
            "\n",
            "Epoch[46] loss: 0.0038988471271530272 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02660445762532098\n",
            "val acc: 0.7901785714285714\n",
            "\n",
            "Epoch[47] loss: 0.004641093809397951 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.028843184666974202\n",
            "val acc: 0.8002232142857143\n",
            "\n",
            "Epoch[48] loss: 0.004949214778119518 LR: [2]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.0316988860390016\n",
            "val acc: 0.7734375\n",
            "\n",
            "Epoch[49] loss: 0.0028732178710220804 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.020096336358359883\n",
            "val acc: 0.8325892857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.0016487186583089492 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.018169166520237923\n",
            "val acc: 0.8482142857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[51] loss: 0.0012380616671796288 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.019058704376220703\n",
            "val acc: 0.8470982142857143\n",
            "\n",
            "Epoch[52] loss: 0.001144142005585074 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.0203776444707598\n",
            "val acc: 0.8303571428571429\n",
            "\n",
            "Epoch[53] loss: 0.0009898218296227916 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.017369681570146765\n",
            "val acc: 0.8571428571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[54] loss: 0.0010015480943219436 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.020320592980299677\n",
            "val acc: 0.8415178571428571\n",
            "\n",
            "Epoch[55] loss: 0.0008587792530776032 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.019752745649644306\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[56] loss: 0.0009060999662089612 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.01946915247078453\n",
            "val acc: 0.8571428571428571\n",
            "\n",
            "Epoch[57] loss: 0.0009495121597748009 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.019400583979274546\n",
            "val acc: 0.84375\n",
            "\n",
            "Epoch[58] loss: 0.000718268669105225 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.018321119381913116\n",
            "val acc: 0.8537946428571429\n",
            "\n",
            "Epoch[59] loss: 0.0008080555567322599 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.018794223134006773\n",
            "val acc: 0.8549107142857143\n",
            "\n",
            "Epoch[60] loss: 0.0006373680953402072 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.021100252866744995\n",
            "val acc: 0.84375\n",
            "\n",
            "Epoch[61] loss: 0.0006128768126795729 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.018506712147167752\n",
            "val acc: 0.8604910714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[62] loss: 0.0006986531567940067 LR: [0.4]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.01869089435786009\n",
            "val acc: 0.8638392857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[63] loss: 0.0006133230466906341 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.020176656810300692\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Epoch[64] loss: 0.0005392855143121954 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.020981016967977797\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Epoch[65] loss: 0.0005871091571245943 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.01868206262588501\n",
            "val acc: 0.8616071428571429\n",
            "\n",
            "Epoch[66] loss: 0.0005932064020946141 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.019516654977841035\n",
            "val acc: 0.8560267857142857\n",
            "\n",
            "Epoch[67] loss: 0.0006056731367754119 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.019200912011521205\n",
            "val acc: 0.8526785714285714\n",
            "\n",
            "Epoch[68] loss: 0.0005307251056130495 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02066205535084009\n",
            "val acc: 0.8560267857142857\n",
            "\n",
            "Epoch[69] loss: 0.0005477127476385044 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.020695152559450695\n",
            "val acc: 0.8470982142857143\n",
            "\n",
            "Epoch[70] loss: 0.0004666132820514782 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.017648519149848392\n",
            "val acc: 0.8761160714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[71] loss: 0.0004976004889730605 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02033586454178606\n",
            "val acc: 0.8459821428571429\n",
            "\n",
            "Epoch[72] loss: 0.0004205515471121837 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.01977707871368953\n",
            "val acc: 0.8526785714285714\n",
            "\n",
            "Epoch[73] loss: 0.0006449245087306706 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.019316695497504303\n",
            "val acc: 0.859375\n",
            "\n",
            "Epoch[74] loss: 0.0006117078460632793 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.018848308495112827\n",
            "val acc: 0.8526785714285714\n",
            "\n",
            "Epoch[75] loss: 0.0005376361875659636 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.020144596695899963\n",
            "val acc: 0.8470982142857143\n",
            "\n",
            "Epoch[76] loss: 0.000472699407480597 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.020241028097059046\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Epoch[77] loss: 0.000496062331817924 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.01978229052786316\n",
            "val acc: 0.8571428571428571\n",
            "\n",
            "Epoch[78] loss: 0.0004830045818967084 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.020880269951054027\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[79] loss: 0.0005969235339322158 LR: [0.08000000000000002]\n",
            "Validation on group[4] of 10 classes\n",
            "val loss: 0.02011914418212005\n",
            "val acc: 0.8482142857142857\n",
            "\n",
            "Group[4]Finished!\n",
            "Best model at epoch 70, best accuracy: 0.88\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.17067307692307693\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.06862138127607684 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.044187775147812705\n",
            "val acc: 0.35825892857142855\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.0321132312979429 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.031119611912540028\n",
            "val acc: 0.5725446428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.025136011862947095 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02698263925101076\n",
            "val acc: 0.6529017857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.021739861897883878 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.022220713751656667\n",
            "val acc: 0.7198660714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.019201439715200854 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.021638172811695507\n",
            "val acc: 0.7232142857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.017090361535308823 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02416973135301045\n",
            "val acc: 0.6919642857142857\n",
            "\n",
            "Epoch[6] loss: 0.015725811042131915 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.020071917878729955\n",
            "val acc: 0.7645089285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[7] loss: 0.01445602583548715 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01826709123062236\n",
            "val acc: 0.7790178571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[8] loss: 0.01375974438363506 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02111184091440269\n",
            "val acc: 0.7611607142857143\n",
            "\n",
            "Epoch[9] loss: 0.012106923386454582 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.0183491673586624\n",
            "val acc: 0.8080357142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[10] loss: 0.011582870817472857 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02707334528011935\n",
            "val acc: 0.7008928571428571\n",
            "\n",
            "Epoch[11] loss: 0.012581937315483247 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.018868392599480494\n",
            "val acc: 0.8002232142857143\n",
            "\n",
            "Epoch[12] loss: 0.010897763208636353 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02516262126820428\n",
            "val acc: 0.7098214285714286\n",
            "\n",
            "Epoch[13] loss: 0.00998543653517 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02058087874736105\n",
            "val acc: 0.7611607142857143\n",
            "\n",
            "Epoch[14] loss: 0.009654717955497964 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.018641474656760693\n",
            "val acc: 0.7979910714285714\n",
            "\n",
            "Epoch[15] loss: 0.009208482780283498 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.023486801822270666\n",
            "val acc: 0.734375\n",
            "\n",
            "Epoch[16] loss: 0.008206050797936416 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02005394282085555\n",
            "val acc: 0.7611607142857143\n",
            "\n",
            "Epoch[17] loss: 0.007946449316917889 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.018526516056486537\n",
            "val acc: 0.7857142857142857\n",
            "\n",
            "Epoch[18] loss: 0.007914417348201237 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01886293158999511\n",
            "val acc: 0.7834821428571429\n",
            "\n",
            "Epoch[19] loss: 0.007840391834296526 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.020274092576333454\n",
            "val acc: 0.7912946428571429\n",
            "\n",
            "Epoch[20] loss: 0.008074555966642595 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02551246514277799\n",
            "val acc: 0.7466517857142857\n",
            "\n",
            "Epoch[21] loss: 0.0072052463468524714 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02434282749891281\n",
            "val acc: 0.75\n",
            "\n",
            "Epoch[22] loss: 0.00700011947793105 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.022598605336887494\n",
            "val acc: 0.7645089285714286\n",
            "\n",
            "Epoch[23] loss: 0.007070434925657126 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.021595808810421398\n",
            "val acc: 0.7589285714285714\n",
            "\n",
            "Epoch[24] loss: 0.0065090855763804524 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.022203915353332247\n",
            "val acc: 0.7678571428571429\n",
            "\n",
            "Epoch[25] loss: 0.006033172380299338 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02830874148224081\n",
            "val acc: 0.7220982142857143\n",
            "\n",
            "Epoch[26] loss: 0.006081407123635854 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.0214343752179827\n",
            "val acc: 0.7845982142857143\n",
            "\n",
            "Epoch[27] loss: 0.005984530754147037 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.019947431183287075\n",
            "val acc: 0.7868303571428571\n",
            "\n",
            "Epoch[28] loss: 0.0053450069089810695 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.022219751828483174\n",
            "val acc: 0.7779017857142857\n",
            "\n",
            "Epoch[29] loss: 0.006216914092581119 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.020400022555674826\n",
            "val acc: 0.7890625\n",
            "\n",
            "Epoch[30] loss: 0.006110560884999652 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.027496029223714556\n",
            "val acc: 0.7332589285714286\n",
            "\n",
            "Epoch[31] loss: 0.005531907907777255 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02254923353237765\n",
            "val acc: 0.7622767857142857\n",
            "\n",
            "Epoch[32] loss: 0.00522912967379295 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.018666268193296025\n",
            "val acc: 0.8169642857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[33] loss: 0.005436293127375745 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.022679424179451808\n",
            "val acc: 0.7700892857142857\n",
            "\n",
            "Epoch[34] loss: 0.005352705424170821 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02579110035938876\n",
            "val acc: 0.7388392857142857\n",
            "\n",
            "Epoch[35] loss: 0.004955227546874554 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.020359810973916734\n",
            "val acc: 0.7912946428571429\n",
            "\n",
            "Epoch[36] loss: 0.004192172771229619 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.026212483378393308\n",
            "val acc: 0.7477678571428571\n",
            "\n",
            "Epoch[37] loss: 0.004263631188340725 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.023934345160211836\n",
            "val acc: 0.765625\n",
            "\n",
            "Epoch[38] loss: 0.00433542812243104 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02349227773291724\n",
            "val acc: 0.7611607142857143\n",
            "\n",
            "Epoch[39] loss: 0.004804321797564626 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.03365176117845944\n",
            "val acc: 0.7154017857142857\n",
            "\n",
            "Epoch[40] loss: 0.004427704058827892 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01965841225215367\n",
            "val acc: 0.8024553571428571\n",
            "\n",
            "Epoch[41] loss: 0.004172292076081278 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.022274196946195195\n",
            "val acc: 0.7823660714285714\n",
            "\n",
            "Epoch[42] loss: 0.004555146705599562 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.021578575617500713\n",
            "val acc: 0.7901785714285714\n",
            "\n",
            "Epoch[43] loss: 0.00400081291163881 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02338205517402717\n",
            "val acc: 0.7767857142857143\n",
            "\n",
            "Epoch[44] loss: 0.004651340558343838 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02454342134296894\n",
            "val acc: 0.7678571428571429\n",
            "\n",
            "Epoch[45] loss: 0.004920069691574862 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.023689036390611103\n",
            "val acc: 0.7790178571428571\n",
            "\n",
            "Epoch[46] loss: 0.0044084711511048575 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.02335920956517969\n",
            "val acc: 0.7790178571428571\n",
            "\n",
            "Epoch[47] loss: 0.003576498080585753 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.0226377828844956\n",
            "val acc: 0.796875\n",
            "\n",
            "Epoch[48] loss: 0.0031921505409803603 LR: [2]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01842443086206913\n",
            "val acc: 0.8136160714285714\n",
            "\n",
            "Epoch[49] loss: 0.001880021240081518 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01644883823714086\n",
            "val acc: 0.8348214285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.0012982702708893244 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015987408746566092\n",
            "val acc: 0.8270089285714286\n",
            "\n",
            "Epoch[51] loss: 0.0011160004519737295 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01647367953721966\n",
            "val acc: 0.8303571428571429\n",
            "\n",
            "Epoch[52] loss: 0.000901821123871712 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.016463020417307104\n",
            "val acc: 0.8303571428571429\n",
            "\n",
            "Epoch[53] loss: 0.0009530629341175119 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.016142917264785086\n",
            "val acc: 0.8392857142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[54] loss: 0.0008493171443396639 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01566063173647438\n",
            "val acc: 0.8504464285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[55] loss: 0.000722360375690304 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015494531685752528\n",
            "val acc: 0.8482142857142857\n",
            "\n",
            "Epoch[56] loss: 0.0007273258111860243 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015172999751354967\n",
            "val acc: 0.8627232142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[57] loss: 0.0007788062822299018 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.016118429601192474\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Epoch[58] loss: 0.0006794279249715469 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01733278895595244\n",
            "val acc: 0.8370535714285714\n",
            "\n",
            "Epoch[59] loss: 0.0006881216202952689 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.016909677402249405\n",
            "val acc: 0.8459821428571429\n",
            "\n",
            "Epoch[60] loss: 0.0006249345498227124 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01667899265885353\n",
            "val acc: 0.8504464285714286\n",
            "\n",
            "Epoch[61] loss: 0.000572302567419566 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015807196497917175\n",
            "val acc: 0.8415178571428571\n",
            "\n",
            "Epoch[62] loss: 0.0006577032956204587 LR: [0.4]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015366495320839542\n",
            "val acc: 0.8448660714285714\n",
            "\n",
            "Epoch[63] loss: 0.0006563128347718908 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.014752125899706568\n",
            "val acc: 0.8504464285714286\n",
            "\n",
            "Epoch[64] loss: 0.0005982527913029997 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015917098947933743\n",
            "val acc: 0.8515625\n",
            "\n",
            "Epoch[65] loss: 0.000634926934576323 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.014658184722065926\n",
            "val acc: 0.859375\n",
            "\n",
            "Epoch[66] loss: 0.000423489875468095 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.014543046376534871\n",
            "val acc: 0.8571428571428571\n",
            "\n",
            "Epoch[67] loss: 0.0005288187108348093 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015358775454972471\n",
            "val acc: 0.8571428571428571\n",
            "\n",
            "Epoch[68] loss: 0.0005402361510336519 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.016341103506939753\n",
            "val acc: 0.8526785714285714\n",
            "\n",
            "Epoch[69] loss: 0.0004606032208915079 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.016015366784163883\n",
            "val acc: 0.8537946428571429\n",
            "\n",
            "Epoch[70] loss: 0.000543425845417885 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015162914991378784\n",
            "val acc: 0.8582589285714286\n",
            "\n",
            "Epoch[71] loss: 0.0005039983037521222 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.01601581847561257\n",
            "val acc: 0.8515625\n",
            "\n",
            "Epoch[72] loss: 0.000662861404106802 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.017270563835544244\n",
            "val acc: 0.84375\n",
            "\n",
            "Epoch[73] loss: 0.0005025987488953697 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015449655641402518\n",
            "val acc: 0.8482142857142857\n",
            "\n",
            "Epoch[74] loss: 0.00043079606210437394 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015561070027095931\n",
            "val acc: 0.8482142857142857\n",
            "\n",
            "Epoch[75] loss: 0.0006019310591997759 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.014784618813012327\n",
            "val acc: 0.8638392857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[76] loss: 0.000552861605331512 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.015546317212283611\n",
            "val acc: 0.8616071428571429\n",
            "\n",
            "Epoch[77] loss: 0.00042633774489419715 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.014189465104469232\n",
            "val acc: 0.8649553571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[78] loss: 0.0004094001497217124 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.016090912212218558\n",
            "val acc: 0.8537946428571429\n",
            "\n",
            "Epoch[79] loss: 0.000444501583490731 LR: [0.08000000000000002]\n",
            "Validation on group[5] of 10 classes\n",
            "val loss: 0.016010095232299397\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Group[5]Finished!\n",
            "Best model at epoch 77, best accuracy: 0.86\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.14385190217391305\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.05307400905557217 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.03248484831835542\n",
            "val acc: 0.4140625\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.025874990969896317 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.024206224562866346\n",
            "val acc: 0.609375\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.020354278265468536 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.021330922842025757\n",
            "val acc: 0.6685267857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.017906846598752083 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01868947914668492\n",
            "val acc: 0.7109375\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.01594059770145724 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01836264838597604\n",
            "val acc: 0.6997767857142857\n",
            "\n",
            "Epoch[5] loss: 0.014193382564811938 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.017807663551398685\n",
            "val acc: 0.7354910714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[6] loss: 0.013273313130822873 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01784866555993046\n",
            "val acc: 0.7488839285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[7] loss: 0.012386474968685258 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.017747823148965836\n",
            "val acc: 0.7399553571428571\n",
            "\n",
            "Epoch[8] loss: 0.011521914042532444 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.017060825202081884\n",
            "val acc: 0.7645089285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[9] loss: 0.010299349624303079 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.014405684279544013\n",
            "val acc: 0.7946428571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[10] loss: 0.009334037726324412 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.014676664423729693\n",
            "val acc: 0.7868303571428571\n",
            "\n",
            "Epoch[11] loss: 0.008868118357514181 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.02332282518701894\n",
            "val acc: 0.7388392857142857\n",
            "\n",
            "Epoch[12] loss: 0.00906388541202872 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.014348859100469522\n",
            "val acc: 0.8113839285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[13] loss: 0.007862320890830408 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01679154871297734\n",
            "val acc: 0.7857142857142857\n",
            "\n",
            "Epoch[14] loss: 0.007978172462073064 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.016273516097239087\n",
            "val acc: 0.7935267857142857\n",
            "\n",
            "Epoch[15] loss: 0.007596024357142949 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.015593752531068665\n",
            "val acc: 0.7868303571428571\n",
            "\n",
            "Epoch[16] loss: 0.006592488517203639 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.013391004077025823\n",
            "val acc: 0.8169642857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[17] loss: 0.0065222974536159346 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.017069727714572634\n",
            "val acc: 0.7857142857142857\n",
            "\n",
            "Epoch[18] loss: 0.0066743706983904685 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01727603123124157\n",
            "val acc: 0.7633928571428571\n",
            "\n",
            "Epoch[19] loss: 0.006721193211213235 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.018382973835936615\n",
            "val acc: 0.7700892857142857\n",
            "\n",
            "Epoch[20] loss: 0.005813833281037307 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.016706404675330435\n",
            "val acc: 0.7979910714285714\n",
            "\n",
            "Epoch[21] loss: 0.005602867688022314 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.018887286207505634\n",
            "val acc: 0.7578125\n",
            "\n",
            "Epoch[22] loss: 0.004950537864539412 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.016626057348081043\n",
            "val acc: 0.8035714285714286\n",
            "\n",
            "Epoch[23] loss: 0.004729545532515453 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.016952771560422013\n",
            "val acc: 0.8024553571428571\n",
            "\n",
            "Epoch[24] loss: 0.005138792675889788 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01991470703589065\n",
            "val acc: 0.7712053571428571\n",
            "\n",
            "Epoch[25] loss: 0.0052902606436081474 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.015702643697815283\n",
            "val acc: 0.8091517857142857\n",
            "\n",
            "Epoch[26] loss: 0.004939211344706916 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.013391999793904168\n",
            "val acc: 0.8381696428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[27] loss: 0.0045449200026210276 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.015562934268798147\n",
            "val acc: 0.8147321428571429\n",
            "\n",
            "Epoch[28] loss: 0.004768332128503149 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01878851785191468\n",
            "val acc: 0.7779017857142857\n",
            "\n",
            "Epoch[29] loss: 0.004614056347148313 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.016413165123334954\n",
            "val acc: 0.8102678571428571\n",
            "\n",
            "Epoch[30] loss: 0.003856179225558956 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.018350734109325067\n",
            "val acc: 0.796875\n",
            "\n",
            "Epoch[31] loss: 0.003656893480388868 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01582106069794723\n",
            "val acc: 0.8169642857142857\n",
            "\n",
            "Epoch[32] loss: 0.004283478235705725 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.018567596429160664\n",
            "val acc: 0.7901785714285714\n",
            "\n",
            "Epoch[33] loss: 0.0042402181819441815 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.015128685161471367\n",
            "val acc: 0.8147321428571429\n",
            "\n",
            "Epoch[34] loss: 0.004254756915953851 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01854244912309306\n",
            "val acc: 0.7935267857142857\n",
            "\n",
            "Epoch[35] loss: 0.003749924546648418 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.015588746006999697\n",
            "val acc: 0.8214285714285714\n",
            "\n",
            "Epoch[36] loss: 0.0033409399949314612 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.015305402289543833\n",
            "val acc: 0.8214285714285714\n",
            "\n",
            "Epoch[37] loss: 0.0032376894847519935 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.017760425539953367\n",
            "val acc: 0.7845982142857143\n",
            "\n",
            "Epoch[38] loss: 0.0030634528356454065 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.015937947801181247\n",
            "val acc: 0.8069196428571429\n",
            "\n",
            "Epoch[39] loss: 0.0030630218097940087 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01844994431095464\n",
            "val acc: 0.8013392857142857\n",
            "\n",
            "Epoch[40] loss: 0.00368772053550328 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.019214087298938205\n",
            "val acc: 0.8035714285714286\n",
            "\n",
            "Epoch[41] loss: 0.0035646231507041283 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.013754731310265405\n",
            "val acc: 0.8325892857142857\n",
            "\n",
            "Epoch[42] loss: 0.0036530982883226488 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.019764105124132975\n",
            "val acc: 0.7801339285714286\n",
            "\n",
            "Epoch[43] loss: 0.0033433111084084357 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.017850182285266265\n",
            "val acc: 0.8046875\n",
            "\n",
            "Epoch[44] loss: 0.0030320948703334697 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.019845316452639445\n",
            "val acc: 0.7801339285714286\n",
            "\n",
            "Epoch[45] loss: 0.0032797490900021886 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.019422727237854685\n",
            "val acc: 0.7924107142857143\n",
            "\n",
            "Epoch[46] loss: 0.002899993417574273 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.016026367034230913\n",
            "val acc: 0.8258928571428571\n",
            "\n",
            "Epoch[47] loss: 0.002251922177346123 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.014129612461796828\n",
            "val acc: 0.8459821428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[48] loss: 0.002257626943079935 LR: [2]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.017939307993011817\n",
            "val acc: 0.8236607142857143\n",
            "\n",
            "Epoch[49] loss: 0.0014494519723924778 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.012729913528476442\n",
            "val acc: 0.8504464285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.0008852774917613715 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.010989696718752384\n",
            "val acc: 0.8828125\n",
            "Best model updated\n",
            "\n",
            "Epoch[51] loss: 0.0007836128389763255 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01148421410471201\n",
            "val acc: 0.8683035714285714\n",
            "\n",
            "Epoch[52] loss: 0.0006566694289851453 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011564100161194801\n",
            "val acc: 0.8738839285714286\n",
            "\n",
            "Epoch[53] loss: 0.0006093166218394594 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.010442172842366355\n",
            "val acc: 0.8772321428571429\n",
            "\n",
            "Epoch[54] loss: 0.0005386132533819745 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011093276087194681\n",
            "val acc: 0.8805803571428571\n",
            "\n",
            "Epoch[55] loss: 0.0005422667853699456 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011547192997698272\n",
            "val acc: 0.8727678571428571\n",
            "\n",
            "Epoch[56] loss: 0.0004903315266053523 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011730249705059188\n",
            "val acc: 0.8738839285714286\n",
            "\n",
            "Epoch[57] loss: 0.000437150894281184 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011100179183163814\n",
            "val acc: 0.8772321428571429\n",
            "\n",
            "Epoch[58] loss: 0.00047405133955180645 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.012322911061346531\n",
            "val acc: 0.8683035714285714\n",
            "\n",
            "Epoch[59] loss: 0.0004278863770812149 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.012486788976405348\n",
            "val acc: 0.859375\n",
            "\n",
            "Epoch[60] loss: 0.00044089483966555204 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011572361258523805\n",
            "val acc: 0.8694196428571429\n",
            "\n",
            "Epoch[61] loss: 0.0004611369607324201 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011311616615525313\n",
            "val acc: 0.8939732142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[62] loss: 0.0003989620843992358 LR: [0.4]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011211966297456197\n",
            "val acc: 0.8850446428571429\n",
            "\n",
            "Epoch[63] loss: 0.0003794303225849064 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011427516250738077\n",
            "val acc: 0.8850446428571429\n",
            "\n",
            "Epoch[64] loss: 0.00038596937355900844 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.010742570539670331\n",
            "val acc: 0.8939732142857143\n",
            "\n",
            "Epoch[65] loss: 0.00045952185351897274 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011295725059296404\n",
            "val acc: 0.8761160714285714\n",
            "\n",
            "Epoch[66] loss: 0.00035243721551171713 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.0113966089141156\n",
            "val acc: 0.8816964285714286\n",
            "\n",
            "Epoch[67] loss: 0.000366071644220351 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.010353555104562215\n",
            "val acc: 0.8939732142857143\n",
            "\n",
            "Epoch[68] loss: 0.00034875347421714855 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.010876932846648353\n",
            "val acc: 0.8783482142857143\n",
            "\n",
            "Epoch[69] loss: 0.00039624518502668867 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011202649213373661\n",
            "val acc: 0.890625\n",
            "\n",
            "Epoch[70] loss: 0.0003594363675332598 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011493309600544828\n",
            "val acc: 0.8839285714285714\n",
            "\n",
            "Epoch[71] loss: 0.0003437433713829265 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011047458010060447\n",
            "val acc: 0.8917410714285714\n",
            "\n",
            "Epoch[72] loss: 0.000341801744540252 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011101072920220239\n",
            "val acc: 0.8783482142857143\n",
            "\n",
            "Epoch[73] loss: 0.00031421461091902587 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011665378431124347\n",
            "val acc: 0.8761160714285714\n",
            "\n",
            "Epoch[74] loss: 0.0003008914105932138 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.01103425511558141\n",
            "val acc: 0.8828125\n",
            "\n",
            "Epoch[75] loss: 0.00033031583382492704 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011027842493993896\n",
            "val acc: 0.8772321428571429\n",
            "\n",
            "Epoch[76] loss: 0.0003823539506899373 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011417529146586145\n",
            "val acc: 0.8828125\n",
            "\n",
            "Epoch[77] loss: 0.00034230106816281593 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.010393476712384395\n",
            "val acc: 0.8895089285714286\n",
            "\n",
            "Epoch[78] loss: 0.0003511632807672985 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011884608971221107\n",
            "val acc: 0.8671875\n",
            "\n",
            "Epoch[79] loss: 0.0003391927490273731 LR: [0.08000000000000002]\n",
            "Validation on group[6] of 10 classes\n",
            "val loss: 0.011756997688540391\n",
            "val acc: 0.8738839285714286\n",
            "\n",
            "Group[6]Finished!\n",
            "Best model at epoch 61, best accuracy: 0.89\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.1244212962962963\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.04702416675225381 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.033038235402532985\n",
            "val acc: 0.40513392857142855\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.02537844095739626 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.022831430924790248\n",
            "val acc: 0.5926339285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.020359587465082447 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.020726701776896204\n",
            "val acc: 0.6294642857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.017580911336887266 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.01814713196030685\n",
            "val acc: 0.7020089285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.015478573889741975 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.017610680045826093\n",
            "val acc: 0.7042410714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.01446930237955624 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.01785927824676037\n",
            "val acc: 0.7087053571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[6] loss: 0.01299702132781667 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.019390127222452844\n",
            "val acc: 0.6919642857142857\n",
            "\n",
            "Epoch[7] loss: 0.012106429304807417 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.019423298803823336\n",
            "val acc: 0.7064732142857143\n",
            "\n",
            "Epoch[8] loss: 0.01172789546751207 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.015156186451869351\n",
            "val acc: 0.7689732142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[9] loss: 0.010767291435190746 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.0158749951847962\n",
            "val acc: 0.75\n",
            "\n",
            "Epoch[10] loss: 0.01026898652555481 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.018209123451794897\n",
            "val acc: 0.7287946428571429\n",
            "\n",
            "Epoch[11] loss: 0.00934629212884653 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.016068821107702597\n",
            "val acc: 0.7589285714285714\n",
            "\n",
            "Epoch[12] loss: 0.008805669799086547 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.01766392189477171\n",
            "val acc: 0.7332589285714286\n",
            "\n",
            "Epoch[13] loss: 0.008801567518422681 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014037886368376868\n",
            "val acc: 0.7734375\n",
            "Best model updated\n",
            "\n",
            "Epoch[14] loss: 0.008288372953933093 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.018418348527380397\n",
            "val acc: 0.734375\n",
            "\n",
            "Epoch[15] loss: 0.008000385256544236 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.0160316690536482\n",
            "val acc: 0.7745535714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[16] loss: 0.008194025200341017 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.018561757169663906\n",
            "val acc: 0.7366071428571429\n",
            "\n",
            "Epoch[17] loss: 0.007715004961937666 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.015102385676332883\n",
            "val acc: 0.7633928571428571\n",
            "\n",
            "Epoch[18] loss: 0.0075850657998554165 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.015685186721384525\n",
            "val acc: 0.7622767857142857\n",
            "\n",
            "Epoch[19] loss: 0.0068979211482069185 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.017683034895786216\n",
            "val acc: 0.75\n",
            "\n",
            "Epoch[20] loss: 0.00688533529999756 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.01814851417605366\n",
            "val acc: 0.7377232142857143\n",
            "\n",
            "Epoch[21] loss: 0.006495063763953025 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.018066311521189555\n",
            "val acc: 0.7399553571428571\n",
            "\n",
            "Epoch[22] loss: 0.006214770803888959 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.016464778488235816\n",
            "val acc: 0.7589285714285714\n",
            "\n",
            "Epoch[23] loss: 0.005794339602993381 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.016745574506265775\n",
            "val acc: 0.7756696428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[24] loss: 0.006025589026150203 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.016522053629159927\n",
            "val acc: 0.7633928571428571\n",
            "\n",
            "Epoch[25] loss: 0.005868059575497624 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.016552116588822434\n",
            "val acc: 0.765625\n",
            "\n",
            "Epoch[26] loss: 0.005554511301940487 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.017296657764485905\n",
            "val acc: 0.7734375\n",
            "\n",
            "Epoch[27] loss: 0.005160882828697082 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.02147596249622958\n",
            "val acc: 0.7254464285714286\n",
            "\n",
            "Epoch[28] loss: 0.005398037295127588 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.019278704321810176\n",
            "val acc: 0.75\n",
            "\n",
            "Epoch[29] loss: 0.0054881752002984285 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.019312971670712744\n",
            "val acc: 0.7332589285714286\n",
            "\n",
            "Epoch[30] loss: 0.005486091005525762 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.017688911142093793\n",
            "val acc: 0.7689732142857143\n",
            "\n",
            "Epoch[31] loss: 0.005162019605538057 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.016296897482659136\n",
            "val acc: 0.7767857142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[32] loss: 0.005344581527395114 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.018146146621022905\n",
            "val acc: 0.7622767857142857\n",
            "\n",
            "Epoch[33] loss: 0.004902187111457029 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.019667327936206545\n",
            "val acc: 0.7433035714285714\n",
            "\n",
            "Epoch[34] loss: 0.0046330209475972 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.020793727466038296\n",
            "val acc: 0.7366071428571429\n",
            "\n",
            "Epoch[35] loss: 0.004497375527036286 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.016027175688317845\n",
            "val acc: 0.7790178571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[36] loss: 0.004690454116151217 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.019987649550395354\n",
            "val acc: 0.75\n",
            "\n",
            "Epoch[37] loss: 0.004334804879861974 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.01663004806531327\n",
            "val acc: 0.7790178571428571\n",
            "\n",
            "Epoch[38] loss: 0.003961392430468432 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.019648193514772823\n",
            "val acc: 0.7488839285714286\n",
            "\n",
            "Epoch[39] loss: 0.004056374917948438 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.016322281743798937\n",
            "val acc: 0.7689732142857143\n",
            "\n",
            "Epoch[40] loss: 0.0037057511358251495 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.018660024872847965\n",
            "val acc: 0.7734375\n",
            "\n",
            "Epoch[41] loss: 0.0036876723207833785 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.024418488943151066\n",
            "val acc: 0.7176339285714286\n",
            "\n",
            "Epoch[42] loss: 0.003489901769846197 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.017435117890792235\n",
            "val acc: 0.7935267857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[43] loss: 0.0033905070365196272 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.018145684685025896\n",
            "val acc: 0.7455357142857143\n",
            "\n",
            "Epoch[44] loss: 0.0033775875495085793 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.023577517164605006\n",
            "val acc: 0.7399553571428571\n",
            "\n",
            "Epoch[45] loss: 0.004034729865980485 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.021704663123403276\n",
            "val acc: 0.7511160714285714\n",
            "\n",
            "Epoch[46] loss: 0.003736450851354147 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.020597895607352257\n",
            "val acc: 0.7433035714285714\n",
            "\n",
            "Epoch[47] loss: 0.004062828517729236 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.01866309397986957\n",
            "val acc: 0.7700892857142857\n",
            "\n",
            "Epoch[48] loss: 0.0036796751364524807 LR: [2]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.01948075315782002\n",
            "val acc: 0.7611607142857143\n",
            "\n",
            "Epoch[49] loss: 0.002355054295020959 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.012697060858564717\n",
            "val acc: 0.8158482142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.0014293407796010856 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013247257896832057\n",
            "val acc: 0.8180803571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[51] loss: 0.0010664649899192755 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.012043632034744536\n",
            "val acc: 0.8515625\n",
            "Best model updated\n",
            "\n",
            "Epoch[52] loss: 0.0010603007056840484 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.01270391047000885\n",
            "val acc: 0.8359375\n",
            "\n",
            "Epoch[53] loss: 0.0009633468383277256 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013451434538832732\n",
            "val acc: 0.8337053571428571\n",
            "\n",
            "Epoch[54] loss: 0.0008682684678088633 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013465160370937415\n",
            "val acc: 0.8337053571428571\n",
            "\n",
            "Epoch[55] loss: 0.0007763615614103694 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013296796807221003\n",
            "val acc: 0.8337053571428571\n",
            "\n",
            "Epoch[56] loss: 0.0007968145721186433 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.012890209177775043\n",
            "val acc: 0.8348214285714286\n",
            "\n",
            "Epoch[57] loss: 0.0006764600477782228 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.012548597463007485\n",
            "val acc: 0.8348214285714286\n",
            "\n",
            "Epoch[58] loss: 0.0006464624668531601 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014491395891777106\n",
            "val acc: 0.8214285714285714\n",
            "\n",
            "Epoch[59] loss: 0.000587674917281425 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014020137355795928\n",
            "val acc: 0.8303571428571429\n",
            "\n",
            "Epoch[60] loss: 0.0005369161597392972 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013021736405789852\n",
            "val acc: 0.8426339285714286\n",
            "\n",
            "Epoch[61] loss: 0.000572101979125892 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014631664779569422\n",
            "val acc: 0.8191964285714286\n",
            "\n",
            "Epoch[62] loss: 0.0006027619974995633 LR: [0.4]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013085177035204001\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Epoch[63] loss: 0.0005300470295497366 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.012756996122854096\n",
            "val acc: 0.8470982142857143\n",
            "\n",
            "Epoch[64] loss: 0.0005570271337825445 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014344853881214346\n",
            "val acc: 0.8314732142857143\n",
            "\n",
            "Epoch[65] loss: 0.0004684783395327207 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013115475353385721\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Epoch[66] loss: 0.0004364166370285074 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014629785769752093\n",
            "val acc: 0.8191964285714286\n",
            "\n",
            "Epoch[67] loss: 0.0005171154353452186 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014042123220860958\n",
            "val acc: 0.8392857142857143\n",
            "\n",
            "Epoch[68] loss: 0.00045343743864401814 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013370515379522527\n",
            "val acc: 0.8359375\n",
            "\n",
            "Epoch[69] loss: 0.0004002246052785326 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013730274779456002\n",
            "val acc: 0.8448660714285714\n",
            "\n",
            "Epoch[70] loss: 0.00041906235433529103 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013542245940438338\n",
            "val acc: 0.8292410714285714\n",
            "\n",
            "Epoch[71] loss: 0.0005296474424070648 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014423214032181672\n",
            "val acc: 0.8292410714285714\n",
            "\n",
            "Epoch[72] loss: 0.0004090197218183969 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013535244124276298\n",
            "val acc: 0.8370535714285714\n",
            "\n",
            "Epoch[73] loss: 0.00046087248906147695 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013640080711671285\n",
            "val acc: 0.8470982142857143\n",
            "\n",
            "Epoch[74] loss: 0.0004384502864277531 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013813253625163011\n",
            "val acc: 0.8426339285714286\n",
            "\n",
            "Epoch[75] loss: 0.0004376563541178081 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014740402011999063\n",
            "val acc: 0.8348214285714286\n",
            "\n",
            "Epoch[76] loss: 0.0004336074451848324 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.014665601242865835\n",
            "val acc: 0.8225446428571429\n",
            "\n",
            "Epoch[77] loss: 0.000340147310071775 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013803096355072089\n",
            "val acc: 0.8370535714285714\n",
            "\n",
            "Epoch[78] loss: 0.00042396681026495513 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013566531507032258\n",
            "val acc: 0.8337053571428571\n",
            "\n",
            "Epoch[79] loss: 0.000414764792132642 LR: [0.08000000000000002]\n",
            "Validation on group[7] of 10 classes\n",
            "val loss: 0.013875912608844894\n",
            "val acc: 0.8292410714285714\n",
            "\n",
            "Group[7]Finished!\n",
            "Best model at epoch 51, best accuracy: 0.85\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.10609879032258064\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.046461556527403094 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.03153306299022266\n",
            "val acc: 0.34375\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.024508320155643647 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.022897245894585336\n",
            "val acc: 0.5435267857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.020058237737224947 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.021260347749505724\n",
            "val acc: 0.5915178571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[3] loss: 0.016789333834763494 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.018452350050210953\n",
            "val acc: 0.6774553571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.014262546665005146 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01652753073722124\n",
            "val acc: 0.7053571428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.012432655770211451 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01926727539726666\n",
            "val acc: 0.6283482142857143\n",
            "\n",
            "Epoch[6] loss: 0.011672655541089273 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.015748807894332067\n",
            "val acc: 0.7399553571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[7] loss: 0.010305401027923631 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.020097328882132257\n",
            "val acc: 0.671875\n",
            "\n",
            "Epoch[8] loss: 0.009805418115349547 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.015814917561198984\n",
            "val acc: 0.7421875\n",
            "Best model updated\n",
            "\n",
            "Epoch[9] loss: 0.009025842221754213 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.012781501215483462\n",
            "val acc: 0.7790178571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[10] loss: 0.007987320107678253 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.013005598448216915\n",
            "val acc: 0.7957589285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[11] loss: 0.007806656716932212 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.015923500061035156\n",
            "val acc: 0.7254464285714286\n",
            "\n",
            "Epoch[12] loss: 0.0075325038314106 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.015739731091473783\n",
            "val acc: 0.7433035714285714\n",
            "\n",
            "Epoch[13] loss: 0.006757125814235018 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.012311423463480813\n",
            "val acc: 0.8024553571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[14] loss: 0.006341557499141463 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.017048634056534086\n",
            "val acc: 0.7410714285714286\n",
            "\n",
            "Epoch[15] loss: 0.005842768707342686 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.014259324542113714\n",
            "val acc: 0.7678571428571429\n",
            "\n",
            "Epoch[16] loss: 0.005955562791636874 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01597408644322838\n",
            "val acc: 0.7600446428571429\n",
            "\n",
            "Epoch[17] loss: 0.005361276423378337 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.015220496670476027\n",
            "val acc: 0.7667410714285714\n",
            "\n",
            "Epoch[18] loss: 0.004804815300890515 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.0141960009932518\n",
            "val acc: 0.7756696428571429\n",
            "\n",
            "Epoch[19] loss: 0.00468515993035849 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.014344766869076661\n",
            "val acc: 0.78125\n",
            "\n",
            "Epoch[20] loss: 0.005085767892700049 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.015088983279253756\n",
            "val acc: 0.7823660714285714\n",
            "\n",
            "Epoch[21] loss: 0.004516912361366614 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.014277479611337185\n",
            "val acc: 0.7823660714285714\n",
            "\n",
            "Epoch[22] loss: 0.003971198318345893 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.013796818575688772\n",
            "val acc: 0.7946428571428571\n",
            "\n",
            "Epoch[23] loss: 0.004174308761233284 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.013981769127505166\n",
            "val acc: 0.7924107142857143\n",
            "\n",
            "Epoch[24] loss: 0.004387892797709473 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.019853371062449048\n",
            "val acc: 0.7444196428571429\n",
            "\n",
            "Epoch[25] loss: 0.0038070063887824935 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.013543292480920042\n",
            "val acc: 0.8102678571428571\n",
            "Best model updated\n",
            "\n",
            "Epoch[26] loss: 0.004054336598323238 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.013035524104322706\n",
            "val acc: 0.8002232142857143\n",
            "\n",
            "Epoch[27] loss: 0.0036289531271904707 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.010450654130961214\n",
            "val acc: 0.8504464285714286\n",
            "Best model updated\n",
            "\n",
            "Epoch[28] loss: 0.0034500696553638383 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.013742267154157162\n",
            "val acc: 0.7991071428571429\n",
            "\n",
            "Epoch[29] loss: 0.0035017566650264688 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.021020303879465376\n",
            "val acc: 0.7042410714285714\n",
            "\n",
            "Epoch[30] loss: 0.003916840076506618 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.02402239159813949\n",
            "val acc: 0.6997767857142857\n",
            "\n",
            "Epoch[31] loss: 0.004059225568668016 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.014087981943573271\n",
            "val acc: 0.7924107142857143\n",
            "\n",
            "Epoch[32] loss: 0.0032396873143771964 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01239666888224227\n",
            "val acc: 0.8158482142857143\n",
            "\n",
            "Epoch[33] loss: 0.0028766299590408323 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.014037874793367726\n",
            "val acc: 0.7991071428571429\n",
            "\n",
            "Epoch[34] loss: 0.0025847850051978903 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.011245337847088064\n",
            "val acc: 0.8325892857142857\n",
            "\n",
            "Epoch[35] loss: 0.0025764009727525616 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01920881907322577\n",
            "val acc: 0.765625\n",
            "\n",
            "Epoch[36] loss: 0.002503017831083027 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.015621465630829334\n",
            "val acc: 0.7912946428571429\n",
            "\n",
            "Epoch[37] loss: 0.00256276607979089 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01583905065698283\n",
            "val acc: 0.7946428571428571\n",
            "\n",
            "Epoch[38] loss: 0.002775671456249491 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01347613733794008\n",
            "val acc: 0.8136160714285714\n",
            "\n",
            "Epoch[39] loss: 0.0026986084375230056 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.012553097414118903\n",
            "val acc: 0.8102678571428571\n",
            "\n",
            "Epoch[40] loss: 0.002442922176522834 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.012173481684710299\n",
            "val acc: 0.8214285714285714\n",
            "\n",
            "Epoch[41] loss: 0.002181099256455538 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01624570494251592\n",
            "val acc: 0.7756696428571429\n",
            "\n",
            "Epoch[42] loss: 0.002011315134774533 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.014430813890482699\n",
            "val acc: 0.8091517857142857\n",
            "\n",
            "Epoch[43] loss: 0.0020349865794301995 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.013454512160803591\n",
            "val acc: 0.8225446428571429\n",
            "\n",
            "Epoch[44] loss: 0.002057661093966735 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.014518855405705315\n",
            "val acc: 0.8147321428571429\n",
            "\n",
            "Epoch[45] loss: 0.0023104224106176726 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.018080365577978746\n",
            "val acc: 0.7611607142857143\n",
            "\n",
            "Epoch[46] loss: 0.0027781190433269066 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01447412823992116\n",
            "val acc: 0.8069196428571429\n",
            "\n",
            "Epoch[47] loss: 0.002246949081909993 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.01381476888699191\n",
            "val acc: 0.8046875\n",
            "\n",
            "Epoch[48] loss: 0.0017177473749935388 LR: [2]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.012724786198564939\n",
            "val acc: 0.8337053571428571\n",
            "\n",
            "Epoch[49] loss: 0.00141894074547435 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008877711370587349\n",
            "val acc: 0.8794642857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.0008184469141621864 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.00898414118481534\n",
            "val acc: 0.875\n",
            "\n",
            "Epoch[51] loss: 0.0006914232588080208 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008708257427705186\n",
            "val acc: 0.8783482142857143\n",
            "\n",
            "Epoch[52] loss: 0.000715155899900222 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008475257815527064\n",
            "val acc: 0.8850446428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[53] loss: 0.0005852904230836899 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008815945791346686\n",
            "val acc: 0.8805803571428571\n",
            "\n",
            "Epoch[54] loss: 0.0005700802214578876 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008273184565561158\n",
            "val acc: 0.8984375\n",
            "Best model updated\n",
            "\n",
            "Epoch[55] loss: 0.00048504573163471275 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008332415550415005\n",
            "val acc: 0.8850446428571429\n",
            "\n",
            "Epoch[56] loss: 0.0004332539918381841 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.00814664363861084\n",
            "val acc: 0.8917410714285714\n",
            "\n",
            "Epoch[57] loss: 0.00043561725854693404 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.009154679386743478\n",
            "val acc: 0.875\n",
            "\n",
            "Epoch[58] loss: 0.00039467495779747205 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008926284366420336\n",
            "val acc: 0.8816964285714286\n",
            "\n",
            "Epoch[59] loss: 0.0003791484993980116 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008681793830224447\n",
            "val acc: 0.8683035714285714\n",
            "\n",
            "Epoch[60] loss: 0.00032970679721104043 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008808624598064594\n",
            "val acc: 0.8816964285714286\n",
            "\n",
            "Epoch[61] loss: 0.0003503490363307778 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008638391869940929\n",
            "val acc: 0.8783482142857143\n",
            "\n",
            "Epoch[62] loss: 0.00034260461360381374 LR: [0.4]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008935006401900734\n",
            "val acc: 0.8738839285714286\n",
            "\n",
            "Epoch[63] loss: 0.00029940551124332896 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008367922090526139\n",
            "val acc: 0.8794642857142857\n",
            "\n",
            "Epoch[64] loss: 0.0003255537153416944 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.007736451325139829\n",
            "val acc: 0.8950892857142857\n",
            "\n",
            "Epoch[65] loss: 0.0002989821209226765 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008968322271747249\n",
            "val acc: 0.875\n",
            "\n",
            "Epoch[66] loss: 0.00028733041601240516 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008819117144282376\n",
            "val acc: 0.890625\n",
            "\n",
            "Epoch[67] loss: 0.0003310945443621266 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008850090338715486\n",
            "val acc: 0.8705357142857143\n",
            "\n",
            "Epoch[68] loss: 0.00028046580395781463 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008151900156268052\n",
            "val acc: 0.8816964285714286\n",
            "\n",
            "Epoch[69] loss: 0.00028715254795256884 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008901252610875028\n",
            "val acc: 0.8816964285714286\n",
            "\n",
            "Epoch[70] loss: 0.000311494400751056 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008850309665181808\n",
            "val acc: 0.8895089285714286\n",
            "\n",
            "Epoch[71] loss: 0.0003233124279499715 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.00836590165272355\n",
            "val acc: 0.890625\n",
            "\n",
            "Epoch[72] loss: 0.00030926635747985734 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008499816392681428\n",
            "val acc: 0.8861607142857143\n",
            "\n",
            "Epoch[73] loss: 0.0002457444507238125 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.00851259074573006\n",
            "val acc: 0.8895089285714286\n",
            "\n",
            "Epoch[74] loss: 0.0003019896816582449 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008204735083771604\n",
            "val acc: 0.890625\n",
            "\n",
            "Epoch[75] loss: 0.0002863783292630086 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008945374483508723\n",
            "val acc: 0.8783482142857143\n",
            "\n",
            "Epoch[76] loss: 0.000272554186766126 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008642862218299083\n",
            "val acc: 0.8839285714285714\n",
            "\n",
            "Epoch[77] loss: 0.0002753456435804706 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.00841987957911832\n",
            "val acc: 0.8939732142857143\n",
            "\n",
            "Epoch[78] loss: 0.00030991195179071396 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008962886407971382\n",
            "val acc: 0.8805803571428571\n",
            "\n",
            "Epoch[79] loss: 0.00026252083156460654 LR: [0.08000000000000002]\n",
            "Validation on group[8] of 10 classes\n",
            "val loss: 0.008541243416922433\n",
            "val acc: 0.8850446428571429\n",
            "\n",
            "Group[8]Finished!\n",
            "Best model at epoch 54, best accuracy: 0.90\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.09877232142857142\n",
            "\n",
            "=============================================\n",
            "\n",
            "Epoch[0] loss: 0.042932730829042774 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.02326692853655134\n",
            "val acc: 0.5111607142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[1] loss: 0.017780082540646676 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.015587796057973589\n",
            "val acc: 0.7042410714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[2] loss: 0.012627993049400469 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.015291646921208926\n",
            "val acc: 0.6986607142857143\n",
            "\n",
            "Epoch[3] loss: 0.010281795365435461 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010450262310249465\n",
            "val acc: 0.8058035714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[4] loss: 0.008625682428359024 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009350014251789876\n",
            "val acc: 0.8214285714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[5] loss: 0.0077714151252181295 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010750377151582922\n",
            "val acc: 0.8136160714285714\n",
            "\n",
            "Epoch[6] loss: 0.006962746411802307 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.008811656319137131\n",
            "val acc: 0.828125\n",
            "Best model updated\n",
            "\n",
            "Epoch[7] loss: 0.006330777680681598 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.011300429169620787\n",
            "val acc: 0.7924107142857143\n",
            "\n",
            "Epoch[8] loss: 0.005984349116202324 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.012388939836195536\n",
            "val acc: 0.7734375\n",
            "\n",
            "Epoch[9] loss: 0.005534317404512436 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.008851716627499886\n",
            "val acc: 0.8448660714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[10] loss: 0.005154158807389678 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.008137550338038377\n",
            "val acc: 0.8470982142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[11] loss: 0.00494033100474025 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.008426122566951173\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[12] loss: 0.004408687991540759 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.013152314616101128\n",
            "val acc: 0.7600446428571429\n",
            "\n",
            "Epoch[13] loss: 0.004159608690608893 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009516098403504916\n",
            "val acc: 0.8169642857142857\n",
            "\n",
            "Epoch[14] loss: 0.004276930917835524 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.01046882157347032\n",
            "val acc: 0.8225446428571429\n",
            "\n",
            "Epoch[15] loss: 0.00423006872616468 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.0106395013364298\n",
            "val acc: 0.8136160714285714\n",
            "\n",
            "Epoch[16] loss: 0.003663217784055779 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009300092035638434\n",
            "val acc: 0.8370535714285714\n",
            "\n",
            "Epoch[17] loss: 0.0032067576934012676 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009981796544577395\n",
            "val acc: 0.8415178571428571\n",
            "\n",
            "Epoch[18] loss: 0.0030613444828157944 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009642309775309903\n",
            "val acc: 0.8292410714285714\n",
            "\n",
            "Epoch[19] loss: 0.0028682578347563265 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.008815058839640446\n",
            "val acc: 0.8537946428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[20] loss: 0.002788082242102152 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.012379977852106094\n",
            "val acc: 0.7957589285714286\n",
            "\n",
            "Epoch[21] loss: 0.003494978086241791 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.011633852895881449\n",
            "val acc: 0.8180803571428571\n",
            "\n",
            "Epoch[22] loss: 0.0033473410763807834 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009656326579196113\n",
            "val acc: 0.8270089285714286\n",
            "\n",
            "Epoch[23] loss: 0.002506816102522275 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.008505815373999732\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Epoch[24] loss: 0.0028100410821817576 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010149250073092324\n",
            "val acc: 0.8258928571428571\n",
            "\n",
            "Epoch[25] loss: 0.002492663630795094 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010687352956405707\n",
            "val acc: 0.8203125\n",
            "\n",
            "Epoch[26] loss: 0.0029550635165745214 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.00939354027754494\n",
            "val acc: 0.8537946428571429\n",
            "\n",
            "Epoch[27] loss: 0.002345642044899925 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009174412382500512\n",
            "val acc: 0.8348214285714286\n",
            "\n",
            "Epoch[28] loss: 0.00216349852722018 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010349405530307974\n",
            "val acc: 0.8247767857142857\n",
            "\n",
            "Epoch[29] loss: 0.002046327271889294 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.00936411607212254\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[30] loss: 0.0023864497085131944 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009465511688696486\n",
            "val acc: 0.8415178571428571\n",
            "\n",
            "Epoch[31] loss: 0.002203869098241651 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.011448087436812264\n",
            "val acc: 0.8091517857142857\n",
            "\n",
            "Epoch[32] loss: 0.001965771746566339 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010114710578428847\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[33] loss: 0.0024160105179274276 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.01319558998303754\n",
            "val acc: 0.7946428571428571\n",
            "\n",
            "Epoch[34] loss: 0.00216628955827365 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.01171896792948246\n",
            "val acc: 0.8214285714285714\n",
            "\n",
            "Epoch[35] loss: 0.002051199375156073 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010468079708516598\n",
            "val acc: 0.8258928571428571\n",
            "\n",
            "Epoch[36] loss: 0.0018834944142238988 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.014262619827474867\n",
            "val acc: 0.7924107142857143\n",
            "\n",
            "Epoch[37] loss: 0.0016876848718722262 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.007210966133113418\n",
            "val acc: 0.8772321428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[38] loss: 0.0012266604500191828 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006790640497846263\n",
            "val acc: 0.8761160714285714\n",
            "\n",
            "Epoch[39] loss: 0.0014735572378060992 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010515776462852955\n",
            "val acc: 0.8359375\n",
            "\n",
            "Epoch[40] loss: 0.002103139535569015 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010316626700971807\n",
            "val acc: 0.8404017857142857\n",
            "\n",
            "Epoch[41] loss: 0.0017761939877433883 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.008042742564742054\n",
            "val acc: 0.8616071428571429\n",
            "\n",
            "Epoch[42] loss: 0.00169191847652978 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010271858490471329\n",
            "val acc: 0.8303571428571429\n",
            "\n",
            "Epoch[43] loss: 0.0015825722591891404 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009440728263663394\n",
            "val acc: 0.8571428571428571\n",
            "\n",
            "Epoch[44] loss: 0.0013588230959289977 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.01055298778893692\n",
            "val acc: 0.8459821428571429\n",
            "\n",
            "Epoch[45] loss: 0.0015769811035434326 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.008615229544895036\n",
            "val acc: 0.8649553571428571\n",
            "\n",
            "Epoch[46] loss: 0.0015610539497086598 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009394276354994093\n",
            "val acc: 0.8493303571428571\n",
            "\n",
            "Epoch[47] loss: 0.001816457973027061 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.010251817958695548\n",
            "val acc: 0.8426339285714286\n",
            "\n",
            "Epoch[48] loss: 0.0019269513356829843 LR: [2]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.009386100274111544\n",
            "val acc: 0.8504464285714286\n",
            "\n",
            "Epoch[49] loss: 0.0012147332947220534 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006547011301985809\n",
            "val acc: 0.8850446428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[50] loss: 0.0007244577263331701 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005830546308841024\n",
            "val acc: 0.8995535714285714\n",
            "Best model updated\n",
            "\n",
            "Epoch[51] loss: 0.0005370426186991315 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.0056589847164494654\n",
            "val acc: 0.9084821428571429\n",
            "Best model updated\n",
            "\n",
            "Epoch[52] loss: 0.0004379872219531887 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006023243768140674\n",
            "val acc: 0.8939732142857143\n",
            "\n",
            "Epoch[53] loss: 0.000418494229726944 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005996591777407697\n",
            "val acc: 0.9006696428571429\n",
            "\n",
            "Epoch[54] loss: 0.00040632937593580856 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005944849723683936\n",
            "val acc: 0.8928571428571429\n",
            "\n",
            "Epoch[55] loss: 0.00038199729686077204 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005844319172735725\n",
            "val acc: 0.8962053571428571\n",
            "\n",
            "Epoch[56] loss: 0.0003394354322564698 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.0060398804822138375\n",
            "val acc: 0.8995535714285714\n",
            "\n",
            "Epoch[57] loss: 0.0003066177727774747 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.0054594708407031635\n",
            "val acc: 0.9095982142857143\n",
            "Best model updated\n",
            "\n",
            "Epoch[58] loss: 0.0002960757251017757 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006035439603562866\n",
            "val acc: 0.9051339285714286\n",
            "\n",
            "Epoch[59] loss: 0.00030555726041183655 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005932272744498083\n",
            "val acc: 0.9040178571428571\n",
            "\n",
            "Epoch[60] loss: 0.0002877547789642948 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.00626861523570759\n",
            "val acc: 0.8984375\n",
            "\n",
            "Epoch[61] loss: 0.00026045237187175983 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005846050335094333\n",
            "val acc: 0.9029017857142857\n",
            "\n",
            "Epoch[62] loss: 0.0003292908964325644 LR: [0.4]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.0057447056751698256\n",
            "val acc: 0.9051339285714286\n",
            "\n",
            "Epoch[63] loss: 0.00023595250358114078 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005800744684945259\n",
            "val acc: 0.9073660714285714\n",
            "\n",
            "Epoch[64] loss: 0.0002680506900839147 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006186455288635833\n",
            "val acc: 0.8962053571428571\n",
            "\n",
            "Epoch[65] loss: 0.00024728411658396645 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.00566945131868124\n",
            "val acc: 0.9084821428571429\n",
            "\n",
            "Epoch[66] loss: 0.0002485174115844852 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.0053545507003686255\n",
            "val acc: 0.9107142857142857\n",
            "Best model updated\n",
            "\n",
            "Epoch[67] loss: 0.00023954680927413245 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006114106359226363\n",
            "val acc: 0.8962053571428571\n",
            "\n",
            "Epoch[68] loss: 0.00024234853129112912 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005507809542385595\n",
            "val acc: 0.9040178571428571\n",
            "\n",
            "Epoch[69] loss: 0.00022590344334246531 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006564846894304667\n",
            "val acc: 0.890625\n",
            "\n",
            "Epoch[70] loss: 0.00024241169599155263 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005750859488866159\n",
            "val acc: 0.8973214285714286\n",
            "\n",
            "Epoch[71] loss: 0.0002578282869616223 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006435169904891934\n",
            "val acc: 0.8839285714285714\n",
            "\n",
            "Epoch[72] loss: 0.00021535752438789894 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006230977496930531\n",
            "val acc: 0.8995535714285714\n",
            "\n",
            "Epoch[73] loss: 0.00022787456457022456 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005470261776021549\n",
            "val acc: 0.9084821428571429\n",
            "\n",
            "Epoch[74] loss: 0.00022403893413983525 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005820221201117549\n",
            "val acc: 0.8984375\n",
            "\n",
            "Epoch[75] loss: 0.0002471363193528246 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.006375588875796113\n",
            "val acc: 0.9040178571428571\n",
            "\n",
            "Epoch[76] loss: 0.00021884060134330104 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005925265972369483\n",
            "val acc: 0.90625\n",
            "\n",
            "Epoch[77] loss: 0.00024019418103102174 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.0057894643396139145\n",
            "val acc: 0.8984375\n",
            "\n",
            "Epoch[78] loss: 0.00020600055417631784 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.005380877193861774\n",
            "val acc: 0.9140625\n",
            "Best model updated\n",
            "\n",
            "Epoch[79] loss: 0.00024387066303226617 LR: [0.08000000000000002]\n",
            "Validation on group[9] of 10 classes\n",
            "val loss: 0.0060640541237912005\n",
            "val acc: 0.8939732142857143\n",
            "\n",
            "Group[9]Finished!\n",
            "Best model at epoch 78, best accuracy: 0.91\n",
            "\n",
            "Testing classes seen so far, accuracy: 0.09204727564102565\n",
            "\n",
            "=============================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjXgkRB3-kYU",
        "outputId": "77a793c1-98b4-4069-e997-dd55e1625b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "def plotConfusionMatrix(confusionMatrixData, seed):\n",
        "\tfig,ax=plt.subplots(figsize=(10,10))\n",
        "\tsns.heatmap(confusionMatrixData,cmap='terrain',ax=ax)\n",
        "\tplt.ylabel('True label')\n",
        "\tplt.xlabel('Predicted label')\n",
        "\tplt.title(\"Confusion Matrix - seed: {}\".format(seed))\n",
        "\n",
        "\t#filename = \"cm_{}_{}.jpg\".format(method, seed) # ex. cm_lwf_30\n",
        "\t#plt.savefig(filename, format='png', dpi=300)\n",
        "\tplt.show()\n",
        "t = all_targets.cpu().data.numpy()\n",
        "p = all_preds.cpu().data.numpy()\n",
        "confusionMatrixData = confusion_matrix(t, p)\n",
        "plotConfusionMatrix(confusionMatrixData, RANDOM_SEED[0])\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}